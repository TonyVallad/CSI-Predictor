# W&B Sweep Configuration for CSI-Predictor - CheXNet
# This file defines the hyperparameter search space for CheXNet model optimization
# Updated based on sweep analysis results to focus on high-performing regions

name: "CSI-Predictor CheXNet Hyperparameter Optimization"
program: sweep_train.py
project: "csi-predictor"
entity: "tony-vallad-chru-de-nancy"
method: bayes
metric:
  name: val_f1_weighted
  goal: maximize

parameters:
  # Fixed model parameters
  model_arch:
    value: 'chexnet'
  
  # Fixed preprocessing parameters
  use_official_processor:
    value: false
  
  # Fixed batch size for CheXNet
  batch_size:
    value: 64
  
  # Optimizer settings - removed sgd based on analysis results, keeping only adamw
  optimizer:
    value: 'adamw'
  
  # Learning rate - focused on high-performing range (1e-4 to 2e-4)
  learning_rate:
    distribution: log_uniform_values
    min: 0.0001
    max: 0.0002
  
  # Weight decay - focused on higher values (1e-5 to 1e-4)
  weight_decay:
    distribution: log_uniform_values
    min: 0.00001
    max: 0.0001
  
  # Dropout rate - focused on high-performing range (0.55 to 0.70)
  dropout_rate:
    distribution: uniform
    min: 0.55
    max: 0.70
  
  # Normalization strategy - keeping both based on analysis
  normalization_strategy:
    values: ['imagenet', 'medical']
  
  # Scheduler type - only CosineAnnealingLR based on analysis results
  scheduler_type:
    value: 'CosineAnnealingLR'
  
  # Loss function weights for class imbalance - focused on high-performing range (0.8 to 1.0)
  unknown_weight:
    distribution: uniform
    min: 0.8
    max: 1.0
  
  # Early stopping patience
  patience:
    value: 15

# Early termination for poor performing runs
early_terminate:
  type: hyperband
  min_iter: 5
  eta: 3 