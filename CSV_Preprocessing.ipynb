{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h1 align=\"center\">CSV Preprocessing</h1>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Specific Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV Files\n",
    "CSV_FOLDER = \"../../data/\"\n",
    "# CSV_FOLDER = \"/home/pyuser/data/\"\n",
    "CSV_LABELS_FILE = \"paradise_csi.csv\"\n",
    "CSV_PATIENTS_FILE = \"PatientIds.csv\"\n",
    "CSV_ARCHIMED_DATA = \"ArchiMed_Data.csv\"\n",
    "CSV_TO_EXPLORE_1 = \"paradise_csi_drop_non_nan_w_classes.csv\"\n",
    "CSV_TO_EXPLORE_2 = \"paradise_csi_w_classes_w_non_nan.csv\"\n",
    "CSV_SEPARATOR = \",\"  # Specify the CSV separator, e.g., ',' or '\\t'\n",
    "IMPORT_COLUMNS = []  # If empty, import all columns\n",
    "CHUNK_SIZE = 50000  # Number of rows per chunk\n",
    "\n",
    "# Project Specific Variables\n",
    "EXAM_CODE_START = \"2020-128 01-\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSI escape codes for colored output\n",
    "ANSI = {\n",
    "    'R' : '\\033[91m',  # Red\n",
    "    'G' : '\\033[92m',  # Green\n",
    "    'B' : '\\033[94m',  # Blue\n",
    "    'Y' : '\\033[93m',  # Yellow\n",
    "    'W' : '\\033[0m',  # White\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import CSVs to Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import CSV files into dataframes\n",
    "try:\n",
    "    # Import labels data\n",
    "    df_labels = pd.read_csv(\n",
    "        CSV_FOLDER + CSV_LABELS_FILE,\n",
    "        sep=CSV_SEPARATOR,\n",
    "        usecols=IMPORT_COLUMNS if IMPORT_COLUMNS else None,\n",
    "        chunksize=CHUNK_SIZE\n",
    "    )\n",
    "    df_labels = pd.concat(df_labels, ignore_index=True)\n",
    "    print(f\"{ANSI['G']}Successfully imported{ANSI['W']} {CSV_LABELS_FILE}\")\n",
    "    \n",
    "    # Import patient data  \n",
    "    df_patients = pd.read_csv(\n",
    "        CSV_FOLDER + CSV_PATIENTS_FILE,\n",
    "        sep=CSV_SEPARATOR,\n",
    "        usecols=IMPORT_COLUMNS if IMPORT_COLUMNS else None,\n",
    "        chunksize=CHUNK_SIZE\n",
    "    )\n",
    "    df_patients = pd.concat(df_patients, ignore_index=True)\n",
    "    print(f\"{ANSI['G']}Successfully imported{ANSI['W']} {CSV_PATIENTS_FILE}\")\n",
    "    \n",
    "    # Import ArchiMed CSV\n",
    "    df_archimed = pd.read_csv(\n",
    "        CSV_FOLDER + CSV_ARCHIMED_DATA,\n",
    "        sep=';',  # ArchiMed CSV separator is ';'\n",
    "        usecols=IMPORT_COLUMNS if IMPORT_COLUMNS else None,\n",
    "        chunksize=CHUNK_SIZE\n",
    "    )\n",
    "    df_archimed = pd.concat(df_archimed, ignore_index=True)\n",
    "    print(f\"{ANSI['G']}Successfully imported{ANSI['W']} {CSV_ARCHIMED_DATA}\")\n",
    "    \n",
    "    # Import CSV to explore 1\n",
    "    df_to_explore_1 = pd.read_csv(\n",
    "        CSV_FOLDER + CSV_TO_EXPLORE_1,\n",
    "        sep=CSV_SEPARATOR,\n",
    "        usecols=IMPORT_COLUMNS if IMPORT_COLUMNS else None,\n",
    "        chunksize=CHUNK_SIZE\n",
    "    )\n",
    "    df_to_explore_1 = pd.concat(df_to_explore_1, ignore_index=True)\n",
    "    print(f\"{ANSI['G']}Successfully imported{ANSI['W']} {CSV_TO_EXPLORE_1}\")\n",
    "    \n",
    "    # Import CSV to explore 2\n",
    "    df_to_explore_2 = pd.read_csv(\n",
    "        CSV_FOLDER + CSV_TO_EXPLORE_2,\n",
    "        sep=CSV_SEPARATOR,\n",
    "        usecols=IMPORT_COLUMNS if IMPORT_COLUMNS else None,\n",
    "        chunksize=CHUNK_SIZE\n",
    "    )\n",
    "    df_to_explore_2 = pd.concat(df_to_explore_2, ignore_index=True)\n",
    "    print(f\"{ANSI['G']}Successfully imported{ANSI['W']} {CSV_TO_EXPLORE_2}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"{ANSI['R']}Error importing CSV files: {str(e)}{ANSI['W']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ArchiMed CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns in df_archimed to be more readable\n",
    "df_archimed.rename(columns={\n",
    "    \"Exam\": 'ExamCode',  # Not really the patient's name but the exam code\n",
    "    'Instance Number': 'InstanceNumber',  # ID of the image series\n",
    "    # 'FileID': 'FileID',  # ID of the image file\n",
    "    'Admission ID - (0038,0010)': 'AdmissionID',  # ID of the patient's hospital stay\n",
    "    'Image Type - (0008,0008)': 'ImageType',  # Type of the image (PRIMARY, etc.)\n",
    "    'Series Description - (0008,103E)': 'SeriesDescription',  # Description of the image series\n",
    "    'Derivation Description - (0008,2111)': 'DerivationDescription',  # Description of the image derivation\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled Data CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns in df_labels to be more readable\n",
    "df_labels.rename(columns={\n",
    "    'number': 'ExamCodeEnd',  # Last 4 digits of the exam code\n",
    "    'id_number': 'AdmissionID',  # ID of the patient's hospital stay\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check ArchiMed data to merge with Labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of primary images per exam\n",
    "primary_images_per_exam = df_archimed[df_archimed['ImageType'].str.contains('PRIMARY', na=False)].groupby('ExamCode').size()\n",
    "\n",
    "# Group exams by number of primary images they contain\n",
    "exams_distribution = primary_images_per_exam.value_counts().sort_index()\n",
    "print(f\"{ANSI['G']}Distribution of PRIMARY images per exam:{ANSI['W']}\")\n",
    "for count, num_exams in exams_distribution.items():\n",
    "    print(f\"  {num_exams} exams have {count} PRIMARY images\")\n",
    "\n",
    "# Get total number of unique exams\n",
    "total_exams = df_archimed['ExamCode'].nunique()\n",
    "\n",
    "# Calculate exams with no primary images\n",
    "exams_with_no_primary = total_exams - len(primary_images_per_exam)\n",
    "exams_with_multiple = len(primary_images_per_exam[primary_images_per_exam > 1])\n",
    "\n",
    "print(f\"\\n{ANSI['G']}Summary:{ANSI['W']}\")\n",
    "print(f\"  {len(primary_images_per_exam)} exams have at least one PRIMARY image\")\n",
    "print(f\"  {exams_with_no_primary} exams have no PRIMARY images\")\n",
    "print(f\"  {exams_with_multiple} exams have multiple PRIMARY images\")\n",
    "\n",
    "# Filter ArchiMed data to keep only PRIMARY images\n",
    "df_archimed_primary = df_archimed[df_archimed['ImageType'].str.contains('PRIMARY', na=False)]\n",
    "print(f\"\\n{ANSI['G']}Successfully filtered{ANSI['W']} PRIMARY images from ArchiMed data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find series with multiple primary images\n",
    "series_with_multiple = primary_images_per_exam[primary_images_per_exam > 1].sort_values(ascending=False)\n",
    "print(f\"{ANSI['G']}Series with multiple PRIMARY images:{ANSI['W']}\")\n",
    "for exam_code, num_primary in series_with_multiple.items():\n",
    "    print(f\"  ExamCode: {exam_code} ({num_primary} primary images)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge ArchiMed Data with Labeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_archimed with df_labels on ExamCodeEnd\n",
    "\n",
    "# Extract last 4 digits from ExamCode in df_archimed and convert to int\n",
    "df_archimed['ExamCodeEnd'] = df_archimed['ExamCode'].str[-4:].astype(int)\n",
    "\n",
    "# Merge dataframes on ExamCodeEnd\n",
    "df_merged = pd.merge(df_archimed, df_labels, on='ExamCodeEnd', how='inner')\n",
    "\n",
    "# Get unmerged entries from both dataframes\n",
    "df_unmerged_archimed = df_archimed[~df_archimed['ExamCodeEnd'].isin(df_merged['ExamCodeEnd'])]\n",
    "df_unmerged_labels = df_labels[~df_labels['ExamCodeEnd'].isin(df_merged['ExamCodeEnd'])]\n",
    "\n",
    "print(f\"\\n{ANSI['G']}Successfully merged{ANSI['W']} ArchiMed data with Labeled data\")\n",
    "print(f\"Number of rows in merged dataset: {len(df_merged)}\")\n",
    "print(f\"Number of unmerged rows from ArchiMed: {len(df_unmerged_archimed)}\")\n",
    "print(f\"Number of unmerged rows from Labels: {len(df_unmerged_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_unmerged_labels with df_archimed on AdmissionID\n",
    "df_merged_labels_from_unmerged = pd.merge(df_unmerged_labels, df_archimed, on='AdmissionID', how='inner')\n",
    "\n",
    "print(f\"\\n{ANSI['G']}Successfully merged{ANSI['W']} unmerged Labeled data with ArchiMed data\")\n",
    "print(f\"Number of rows in merged dataset: {len(df_merged_labels_from_unmerged)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Series that are not 'Chest' when there are multiple series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, identify ExamCodes with multiple distinct Series\n",
    "series_per_exam = df_merged.groupby('ExamCode')['Serie'].nunique()\n",
    "exams_with_multiple = series_per_exam[series_per_exam > 1].index\n",
    "\n",
    "# Filter rows where ExamCode has multiple series but Serie is not 'Chest' or 'LIT'\n",
    "mask = (\n",
    "    (df_merged['ExamCode'].isin(exams_with_multiple)) & \n",
    "    (~df_merged['Serie'].str.contains('Chest|LIT', case=False, na=False))\n",
    ")\n",
    "\n",
    "# Save rows that will be removed\n",
    "df_lines_removed = df_merged[mask].copy()\n",
    "\n",
    "# Remove these rows\n",
    "df_merged = df_merged[~mask]\n",
    "\n",
    "print(f\"\\n{ANSI['G']}Successfully removed non-Chest series{ANSI['W']} from exams with multiple series\")\n",
    "print(f\"Number of rows removed: {mask.sum()}\")\n",
    "print(f\"Number of rows remaining: {len(df_merged)}\")\n",
    "print(f\"Removed rows saved in df_lines_removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that there is still at least 1 serie per exam after removing Series that are not 'Chest'\n",
    "# Get unique ExamCodes from removed rows\n",
    "removed_exam_codes = df_lines_removed['ExamCode'].unique()\n",
    "\n",
    "# Check how many distinct series remain for each of these ExamCodes\n",
    "remaining_series = df_merged[df_merged['ExamCode'].isin(removed_exam_codes)].groupby('ExamCode')['Serie'].nunique()\n",
    "\n",
    "# Check if any ExamCode has 0 remaining series\n",
    "empty_exams = removed_exam_codes[~np.isin(removed_exam_codes, remaining_series.index)]\n",
    "\n",
    "if len(empty_exams) > 0:\n",
    "    print(f\"\\n{ANSI['R']}Warning:{ANSI['W']} {len(empty_exams)} exams have no remaining series after removal:\")\n",
    "    print(empty_exams)\n",
    "else:\n",
    "    print(f\"\\n{ANSI['G']}All exams still have at least one series{ANSI['W']} after removing non-Chest series\")\n",
    "    print(\"Minimum series per exam:\", remaining_series.min())\n",
    "    print(\"Maximum series per exam:\", remaining_series.max())\n",
    "    print(\"Average series per exam: {:.2f}\".format(remaining_series.mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
