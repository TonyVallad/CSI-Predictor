{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h1 align=\"center\">CSV Preprocessing</h1>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Specific Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV Files\n",
    "CSV_FOLDER = \"../../data/\"\n",
    "# CSV_FOLDER = \"/home/pyuser/data/\"\n",
    "CSV_LABELS_FILE = \"paradise_csi.csv\"\n",
    "CSV_PATIENTS_FILE = \"PatientIds.csv\"\n",
    "CSV_ARCHIMED_DATA = \"ArchiMed_Data.csv\"\n",
    "CSV_TO_EXPLORE_1 = \"paradise_csi_drop_non_nan_w_classes.csv\"\n",
    "CSV_TO_EXPLORE_2 = \"paradise_csi_w_classes_w_non_nan.csv\"\n",
    "CSV_SEPARATOR = \",\"  # Specify the CSV separator, e.g., ',' or '\\t'\n",
    "IMPORT_COLUMNS = []  # If empty, import all columns\n",
    "CHUNK_SIZE = 50000  # Number of rows per chunk\n",
    "\n",
    "# Project Specific Variables\n",
    "EXAM_CODE_START = \"2020-128 01\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSI escape codes for colored output\n",
    "ANSI = {\n",
    "    'R' : '\\033[91m',  # Red\n",
    "    'G' : '\\033[92m',  # Green\n",
    "    'B' : '\\033[94m',  # Blue\n",
    "    'Y' : '\\033[93m',  # Yellow\n",
    "    'W' : '\\033[0m',  # White\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import CSV to Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import CSV files into dataframes\n",
    "try:\n",
    "    # Import labels data\n",
    "    df_labels = pd.read_csv(\n",
    "        CSV_FOLDER + CSV_LABELS_FILE,\n",
    "        sep=CSV_SEPARATOR,\n",
    "        usecols=IMPORT_COLUMNS if IMPORT_COLUMNS else None,\n",
    "        chunksize=CHUNK_SIZE\n",
    "    )\n",
    "    df_labels = pd.concat(df_labels, ignore_index=True)\n",
    "    print(f\"{ANSI['G']}Successfully imported{ANSI['W']} {CSV_LABELS_FILE}\")\n",
    "    \n",
    "    # Import patient data  \n",
    "    df_patients = pd.read_csv(\n",
    "        CSV_FOLDER + CSV_PATIENTS_FILE,\n",
    "        sep=CSV_SEPARATOR,\n",
    "        usecols=IMPORT_COLUMNS if IMPORT_COLUMNS else None,\n",
    "        chunksize=CHUNK_SIZE\n",
    "    )\n",
    "    df_patients = pd.concat(df_patients, ignore_index=True)\n",
    "    print(f\"{ANSI['G']}Successfully imported{ANSI['W']} {CSV_PATIENTS_FILE}\")\n",
    "    \n",
    "    # Import ArchiMed CSV\n",
    "    df_archimed = pd.read_csv(\n",
    "        CSV_FOLDER + CSV_ARCHIMED_DATA,\n",
    "        sep=';',  # ArchiMed CSV separator is ';'\n",
    "        usecols=IMPORT_COLUMNS if IMPORT_COLUMNS else None,\n",
    "        chunksize=CHUNK_SIZE\n",
    "    )\n",
    "    df_archimed = pd.concat(df_archimed, ignore_index=True)\n",
    "    print(f\"{ANSI['G']}Successfully imported{ANSI['W']} {CSV_ARCHIMED_DATA}\")\n",
    "    \n",
    "    # Import CSV to explore 1\n",
    "    df_to_explore_1 = pd.read_csv(\n",
    "        CSV_FOLDER + CSV_TO_EXPLORE_1,\n",
    "        sep=CSV_SEPARATOR,\n",
    "        usecols=IMPORT_COLUMNS if IMPORT_COLUMNS else None,\n",
    "        chunksize=CHUNK_SIZE\n",
    "    )\n",
    "    df_to_explore_1 = pd.concat(df_to_explore_1, ignore_index=True)\n",
    "    print(f\"{ANSI['G']}Successfully imported{ANSI['W']} {CSV_TO_EXPLORE_1}\")\n",
    "    \n",
    "    # Import CSV to explore 2\n",
    "    df_to_explore_2 = pd.read_csv(\n",
    "        CSV_FOLDER + CSV_TO_EXPLORE_2,\n",
    "        sep=CSV_SEPARATOR,\n",
    "        usecols=IMPORT_COLUMNS if IMPORT_COLUMNS else None,\n",
    "        chunksize=CHUNK_SIZE\n",
    "    )\n",
    "    df_to_explore_2 = pd.concat(df_to_explore_2, ignore_index=True)\n",
    "    print(f\"{ANSI['G']}Successfully imported{ANSI['W']} {CSV_TO_EXPLORE_2}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"{ANSI['R']}Error importing CSV files: {str(e)}{ANSI['W']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns in df_archimed to be more readable\n",
    "df_archimed.rename(columns={\n",
    "    \"Patient's Name - (0010,0010)\": 'ExamCode',\n",
    "    'Instance Number - (0020,0013)': 'InstanceNumber',\n",
    "    'Admission ID - (0038,0010)': 'AdmissionID',\n",
    "    'Image Type - (0008,0008)': 'ImageType',\n",
    "    'Derivation Description - (0008,2111)': 'Derivation',\n",
    "}, inplace=True)\n",
    "\n",
    "# Count number of primary images per series\n",
    "primary_images_per_series = df_archimed[df_archimed['ImageType'].str.contains('PRIMARY', na=False)].groupby('ExamCode').size()\n",
    "\n",
    "# Group series by number of primary images they contain\n",
    "series_distribution = primary_images_per_series.value_counts().sort_index()\n",
    "print(f\"{ANSI['G']}Distribution of PRIMARY images per series:{ANSI['W']}\")\n",
    "for count, num_series in series_distribution.items():\n",
    "    print(f\"  {num_series} series have {count} PRIMARY images\")\n",
    "\n",
    "# Get total number of unique series\n",
    "total_series = df_archimed['ExamCode'].nunique()\n",
    "\n",
    "# Calculate series with no primary images\n",
    "series_with_no_primary = total_series - len(primary_images_per_series)\n",
    "series_with_multiple = len(primary_images_per_series[primary_images_per_series > 1])\n",
    "\n",
    "print(f\"\\n{ANSI['G']}Summary:{ANSI['W']}\")\n",
    "print(f\"  {len(primary_images_per_series)} series have at least one PRIMARY image\")\n",
    "print(f\"  {series_with_no_primary} series have no PRIMARY images\")\n",
    "print(f\"  {series_with_multiple} series have multiple PRIMARY images\")\n",
    "\n",
    "# Filter ArchiMed data to keep only PRIMARY images\n",
    "df_archimed_primary = df_archimed[df_archimed['ImageType'].str.contains('PRIMARY', na=False)]\n",
    "print(f\"{ANSI['G']}Successfully filtered{ANSI['W']} PRIMARY images from ArchiMed data\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
