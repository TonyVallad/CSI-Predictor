{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "**<h1 align=\"center\">Download ArchiMed Images V1.4 - SIMPLIFIED</h1>**\n",
        "\n",
        "## **V1.4: Simplified Lung Segmentation & Cropping**\n",
        "- **Single Model**: Uses best available segmentation model (TorchXRayVision preferred)\n",
        "- **Clear Area Cropping**: Crops to the clear rectangular area (matches overlay bright zone)\n",
        "- **V1.3 Style Overlay**: Cyan rectangle, green corner brackets, red lung filling\n",
        "- **Minimal Configuration**: Only essential parameters\n",
        "\n",
        "## **Key Simplifications from V1.3:**\n",
        "- Removed ensemble methods and multiple thresholds\n",
        "- Removed enhanced preprocessing options\n",
        "- Reduced configuration parameters\n",
        "- Cleaner, more focused code\n",
        "- **Kept V1.3 overlay visualization style**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple Configuration\n",
        "CSV_FOLDER = \"/home/pyuser/data/Paradise_CSV/\"\n",
        "CSV_LABELS_FILE = \"Labeled_Data_RAW_Sample.csv\"\n",
        "CSV_SEPARATOR = \";\"\n",
        "\n",
        "# Paths\n",
        "DOWNLOAD_PATH = '/home/pyuser/data/Paradise_Test_DICOMs'\n",
        "IMAGES_PATH = '/home/pyuser/data/Paradise_Test_Images'\n",
        "MASKS_PATH = '/home/pyuser/data/Paradise_Masks'\n",
        "\n",
        "# Processing settings\n",
        "TARGET_SIZE = (518, 518)\n",
        "LUNG_THRESHOLD = 0.1  # Single threshold for lung detection\n",
        "CROP_MARGIN = 40  # Margin around lungs for final crop\n",
        "\n",
        "# V1.3 Style Overlay Settings\n",
        "LUNG_FILL_OPACITY = 0.25  # Lung fill opacity (like V1.3)\n",
        "LUNG_BORDER_OPACITY = 0.50  # Lung border opacity (like V1.3)\n",
        "\n",
        "# Options\n",
        "CONVERT = True\n",
        "SAVE_MASKS = True\n",
        "\n",
        "print(\"V1.4 Simplified configuration loaded!\")\n",
        "print(f\"Target size: {TARGET_SIZE}\")\n",
        "print(f\"Lung threshold: {LUNG_THRESHOLD}\")\n",
        "print(\"V1.3 style overlay enabled\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core dependencies\n",
        "import ArchiMedConnector.A3_Connector as A3_Conn\n",
        "import pandas as pd\n",
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"Core dependencies loaded\")\n",
        "\n",
        "# Initialize ArchiMed connector\n",
        "a3conn = A3_Conn.A3_Connector()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple segmentation model setup\n",
        "segmentation_model = None\n",
        "model_type = None\n",
        "\n",
        "# Try TorchXRayVision first (best option)\n",
        "try:\n",
        "    import torchxrayvision as xrv\n",
        "    import torch\n",
        "    segmentation_model = xrv.baseline_models.chestx_det.PSPNet()\n",
        "    model_type = 'torchxray'\n",
        "    print(\"‚úÖ TorchXRayVision loaded\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è Installing TorchXRayVision...\")\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"torchxrayvision\"])\n",
        "        import torchxrayvision as xrv\n",
        "        import torch\n",
        "        segmentation_model = xrv.baseline_models.chestx_det.PSPNet()\n",
        "        model_type = 'torchxray'\n",
        "        print(\"‚úÖ TorchXRayVision installed and loaded\")\n",
        "    except:\n",
        "        print(\"‚ùå TorchXRayVision unavailable, using fallback\")\n",
        "        model_type = 'fallback'\n",
        "\n",
        "print(f\"Segmentation method: {model_type}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def segment_lungs(image):\n",
        "    \"\"\"Simple lung segmentation\"\"\"\n",
        "    if model_type == 'torchxray' and segmentation_model is not None:\n",
        "        return segment_with_torchxray(image)\n",
        "    else:\n",
        "        return segment_with_fallback(image)\n",
        "\n",
        "def segment_with_torchxray(image):\n",
        "    \"\"\"Segment using TorchXRayVision\"\"\"\n",
        "    try:\n",
        "        # Convert to grayscale if needed\n",
        "        if len(image.shape) == 3:\n",
        "            image_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "        else:\n",
        "            image_gray = image\n",
        "        \n",
        "        # Normalize for TorchXRayVision\n",
        "        image_norm = xrv.datasets.normalize(image_gray, 255)\n",
        "        image_norm = image_norm[None, ...]\n",
        "        \n",
        "        # Resize to 512x512\n",
        "        transform = xrv.datasets.XRayResizer(512)\n",
        "        image_resized = transform(image_norm)\n",
        "        \n",
        "        # Convert to tensor\n",
        "        image_tensor = torch.from_numpy(image_resized).float().unsqueeze(0)\n",
        "        \n",
        "        # Run inference\n",
        "        with torch.no_grad():\n",
        "            output = segmentation_model(image_tensor)\n",
        "        \n",
        "        # Extract lung masks\n",
        "        lung_targets = ['Left Lung', 'Right Lung']\n",
        "        lung_mask = np.zeros((512, 512))\n",
        "        \n",
        "        for i, target in enumerate(segmentation_model.targets):\n",
        "            if target in lung_targets:\n",
        "                lung_mask += output[0, i].cpu().numpy()\n",
        "        \n",
        "        # Resize back to original size\n",
        "        lung_mask = cv2.resize(lung_mask, (image.shape[1], image.shape[0]))\n",
        "        \n",
        "        # Create binary mask\n",
        "        binary_mask = (lung_mask > LUNG_THRESHOLD).astype(np.uint8)\n",
        "        \n",
        "        # Clean up mask\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))\n",
        "        binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n",
        "        binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
        "        \n",
        "        return binary_mask\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"TorchXRayVision segmentation failed: {e}\")\n",
        "        return segment_with_fallback(image)\n",
        "\n",
        "def segment_with_fallback(image):\n",
        "    \"\"\"Fallback segmentation method\"\"\"\n",
        "    if len(image.shape) == 3:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    else:\n",
        "        gray = image.copy()\n",
        "    \n",
        "    # Apply CLAHE\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    gray = clahe.apply(gray)\n",
        "    \n",
        "    # Otsu thresholding\n",
        "    _, otsu_mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    \n",
        "    # Morphological cleanup\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (20, 20))\n",
        "    mask_clean = cv2.morphologyEx(otsu_mask, cv2.MORPH_CLOSE, kernel)\n",
        "    mask_clean = cv2.morphologyEx(mask_clean, cv2.MORPH_OPEN, kernel)\n",
        "    \n",
        "    return (mask_clean > 0).astype(np.uint8)\n",
        "\n",
        "print(\"Lung segmentation functions loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_v13_overlay(image, binary_mask, resize_crop_bounds):\n",
        "    \"\"\"Create V1.3 style overlay with cyan rectangle, green corners, and red lung filling\"\"\"\n",
        "    overlay = image.copy()\n",
        "    if len(overlay.shape) == 2:\n",
        "        overlay = cv2.cvtColor(overlay, cv2.COLOR_GRAY2RGB)\n",
        "    \n",
        "    resize_y_min, resize_x_min, resize_y_max, resize_x_max = resize_crop_bounds\n",
        "    img_height, img_width = overlay.shape[:2]\n",
        "    \n",
        "    # 1. Darken areas OUTSIDE the resize crop (like V1.3)\n",
        "    outside_resize_mask = np.ones((img_height, img_width), dtype=bool)\n",
        "    outside_resize_mask[resize_y_min:resize_y_max, resize_x_min:resize_x_max] = False\n",
        "    overlay[outside_resize_mask] = (overlay[outside_resize_mask] * 0.5).astype(np.uint8)\n",
        "    \n",
        "    # 2. Red lung visualization with dual opacity (exactly like V1.3) - FIXED\n",
        "    lung_areas = binary_mask > 0\n",
        "    \n",
        "    if np.any(lung_areas):\n",
        "        print(f\"üìç Debug: Found {np.sum(lung_areas)} lung pixels\")\n",
        "        \n",
        "        # Step 1: Apply BRIGHT RED FILL with higher opacity for visibility\n",
        "        lung_fill_colored = np.zeros_like(overlay)\n",
        "        lung_fill_colored[lung_areas] = [0, 0, 255]  # BRIGHT Red in BGR (was [0, 0, 180])\n",
        "        \n",
        "        # Use higher opacity for better visibility\n",
        "        fill_opacity = max(LUNG_FILL_OPACITY, 0.4)  # At least 40% opacity\n",
        "        overlay[lung_areas] = cv2.addWeighted(\n",
        "            overlay[lung_areas], 1.0 - fill_opacity, \n",
        "            lung_fill_colored[lung_areas], fill_opacity, 0\n",
        "        )\n",
        "        print(f\"üìç Debug: Applied bright red fill with {fill_opacity} opacity\")\n",
        "        \n",
        "        # Step 2: Apply BRIGHT RED BORDER with higher opacity\n",
        "        lung_mask_uint8 = (binary_mask * 255).astype(np.uint8)\n",
        "        contours, _ = cv2.findContours(lung_mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        \n",
        "        border_mask = np.zeros_like(binary_mask, dtype=np.uint8)\n",
        "        cv2.drawContours(border_mask, contours, -1, 1, thickness=6)  # Thicker border (was 4px, now 6px)\n",
        "        \n",
        "        border_areas = border_mask > 0\n",
        "        if np.any(border_areas):\n",
        "            lung_border_colored = np.zeros_like(overlay)\n",
        "            lung_border_colored[border_areas] = [0, 0, 255]  # BRIGHT Red in BGR (was [0, 0, 180])\n",
        "            \n",
        "            # Use higher opacity for better visibility\n",
        "            border_opacity = max(LUNG_BORDER_OPACITY, 0.6)  # At least 60% opacity\n",
        "            overlay[border_areas] = cv2.addWeighted(\n",
        "                overlay[border_areas], 1.0 - border_opacity, \n",
        "                lung_border_colored[border_areas], border_opacity, 0\n",
        "            )\n",
        "            print(f\"üìç Debug: Applied bright red border with {border_opacity} opacity\")\n",
        "        else:\n",
        "            print(\"üìç Debug: No border areas found\")\n",
        "    else:\n",
        "        print(\"üìç Debug: No lung areas found\")\n",
        "    \n",
        "    # 3. Green corner brackets for exact segmentation boundaries (exactly like V1.3) - FIXED\n",
        "    def draw_corner_brackets(img, x1, y1, x2, y2, color, thickness=5, length=60):\n",
        "        \"\"\"Draw corner brackets at the corners of a rectangle - ENHANCED VISIBILITY\"\"\"\n",
        "        img_height, img_width = img.shape[:2]\n",
        "        \n",
        "        # Ensure coordinates are within image bounds\n",
        "        x1 = max(0, min(x1, img_width - 1))\n",
        "        y1 = max(0, min(y1, img_height - 1))\n",
        "        x2 = max(0, min(x2, img_width - 1))\n",
        "        y2 = max(0, min(y2, img_height - 1))\n",
        "        \n",
        "        # Ensure length doesn't exceed available space\n",
        "        max_length_x = min(length, (x2 - x1) // 4)  # Don't exceed 1/4 of width\n",
        "        max_length_y = min(length, (y2 - y1) // 4)  # Don't exceed 1/4 of height\n",
        "        length = max(20, min(max_length_x, max_length_y))  # At least 20px\n",
        "        \n",
        "        print(f\"üìç Debug: Drawing brackets at ({x1},{y1}) to ({x2},{y2}) with length={length}, thickness={thickness}\")\n",
        "        \n",
        "        # Top-left corner\n",
        "        cv2.line(img, (x1, y1), (min(x1 + length, img_width-1), y1), color, thickness)  # Horizontal\n",
        "        cv2.line(img, (x1, y1), (x1, min(y1 + length, img_height-1)), color, thickness)  # Vertical\n",
        "        \n",
        "        # Top-right corner\n",
        "        cv2.line(img, (max(x2 - length, 0), y1), (x2, y1), color, thickness)  # Horizontal\n",
        "        cv2.line(img, (x2, y1), (x2, min(y1 + length, img_height-1)), color, thickness)  # Vertical\n",
        "        \n",
        "        # Bottom-left corner\n",
        "        cv2.line(img, (x1, max(y2 - length, 0)), (x1, y2), color, thickness)  # Vertical\n",
        "        cv2.line(img, (x1, y2), (min(x1 + length, img_width-1), y2), color, thickness)  # Horizontal\n",
        "        \n",
        "        # Bottom-right corner\n",
        "        cv2.line(img, (x2, max(y2 - length, 0)), (x2, y2), color, thickness)  # Vertical\n",
        "        cv2.line(img, (max(x2 - length, 0), y2), (x2, y2), color, thickness)  # Horizontal\n",
        "    \n",
        "    # Find actual segmentation boundaries (without padding) for green corners (exactly like V1.3)\n",
        "    lung_coords = np.where(binary_mask > 0)\n",
        "    if len(lung_coords[0]) > 0:\n",
        "        actual_y_min = np.min(lung_coords[0])  # Top edge of lungs\n",
        "        actual_y_max = np.max(lung_coords[0])  # Bottom edge of lungs  \n",
        "        actual_x_min = np.min(lung_coords[1])  # Left edge of lungs\n",
        "        actual_x_max = np.max(lung_coords[1])  # Right edge of lungs\n",
        "        \n",
        "        print(f\"üìç Debug: Segmentation boundaries: ({actual_x_min},{actual_y_min}) to ({actual_x_max},{actual_y_max})\")\n",
        "        print(f\"üìç Debug: Image dimensions: {overlay.shape[1]}x{overlay.shape[0]}\")\n",
        "        \n",
        "        # Validate coordinates are within image bounds\n",
        "        if (actual_x_min >= 0 and actual_y_min >= 0 and \n",
        "            actual_x_max < overlay.shape[1] and actual_y_max < overlay.shape[0] and\n",
        "            actual_x_max > actual_x_min and actual_y_max > actual_y_min):\n",
        "            \n",
        "            # Draw BRIGHT GREEN corner brackets at EXACT segmentation boundaries - ENHANCED VISIBILITY\n",
        "            draw_corner_brackets(overlay, actual_x_min, actual_y_min, actual_x_max, actual_y_max, (0, 255, 0), 5, 60)\n",
        "            print(\"üìç Debug: Drew GREEN corner brackets with enhanced visibility (thickness=5, length=60)\")\n",
        "        else:\n",
        "            print(f\"üìç Debug: Invalid segmentation boundaries - skipping green corners\")\n",
        "            print(f\"   Bounds: x({actual_x_min}-{actual_x_max}), y({actual_y_min}-{actual_y_max})\")\n",
        "    else:\n",
        "        print(\"üìç Debug: No lung areas found for corner brackets\")\n",
        "    \n",
        "    # 4. Draw CYAN resize crop rectangle (contains everything and is much larger) - 1px contour line (exactly like V1.3)\n",
        "    cv2.rectangle(overlay, (resize_x_min, resize_y_min), (resize_x_max, resize_y_max), (255, 255, 0), 1)\n",
        "    print(f\"üìç Debug: Drew cyan rectangle: ({resize_x_min},{resize_y_min}) to ({resize_x_max},{resize_y_max})\")\n",
        "    \n",
        "    # 5. V1.3 style legend with BLACK BACKGROUND\n",
        "    legend_height = 120\n",
        "    legend_width = min(700, img_width - 20)  # Ensure legend fits within image bounds\n",
        "    legend_y_start = img_height - legend_height - 10\n",
        "    \n",
        "    # Create black background with 75% opacity (exactly like V1.3)\n",
        "    legend_background = np.zeros((legend_height, legend_width, 3), dtype=np.uint8)\n",
        "    legend_area = overlay[legend_y_start:legend_y_start + legend_height, 10:10 + legend_width]\n",
        "    \n",
        "    # Blend background with 75% opacity (25% transparency) - exactly like V1.3\n",
        "    overlay[legend_y_start:legend_y_start + legend_height, 10:10 + legend_width] = cv2.addWeighted(\n",
        "        legend_area, 0.25, legend_background, 0.75, 0\n",
        "    )\n",
        "    \n",
        "    # Legend text with larger font (exactly like V1.3)\n",
        "    text_y = legend_y_start + 25\n",
        "    font_scale = 0.7  # Larger font\n",
        "    font_thickness = 2\n",
        "    \n",
        "    cv2.putText(overlay, f\"DARK RED = Lung segmentation (Fill: {int(LUNG_FILL_OPACITY*100)}%, Border: {int(LUNG_BORDER_OPACITY*100)}%)\", \n",
        "               (20, text_y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 180), font_thickness)\n",
        "    \n",
        "    cv2.putText(overlay, \"GREEN = Segmentation corner brackets\", \n",
        "               (20, text_y + 30), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 0), font_thickness)\n",
        "    \n",
        "    cv2.putText(overlay, f\"CYAN = Final resize crop {TARGET_SIZE[0]}x{TARGET_SIZE[1]}\", \n",
        "               (20, text_y + 60), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 0), font_thickness)\n",
        "    \n",
        "    # Add feature information at bottom with smaller font (like V1.3)\n",
        "    cv2.putText(overlay, f\"Threshold: {LUNG_THRESHOLD} | Model: {model_type}\", \n",
        "               (20, text_y + 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
        "    \n",
        "    return overlay\n",
        "\n",
        "def process_image_with_segmentation(image_array, file_id):\n",
        "    \"\"\"Process image with lung segmentation and clear area cropping\"\"\"\n",
        "    try:\n",
        "        print(f\"ü´Å Segmenting lungs for {file_id}...\")\n",
        "        \n",
        "        # Get lung segmentation\n",
        "        binary_mask = segment_lungs(image_array)\n",
        "        \n",
        "        # Validate segmentation\n",
        "        total_pixels = binary_mask.shape[0] * binary_mask.shape[1]\n",
        "        lung_pixels = np.sum(binary_mask)\n",
        "        lung_ratio = lung_pixels / total_pixels\n",
        "        \n",
        "        print(f\"üìä Lung area: {lung_ratio:.3f} of image\")\n",
        "        \n",
        "        # Quality check\n",
        "        if lung_ratio < 0.005 or lung_ratio > 0.95:\n",
        "            print(f\"‚ö†Ô∏è Lung area outside valid range, using original\")\n",
        "            return image_array\n",
        "        \n",
        "        # Find lung boundaries\n",
        "        coords = np.column_stack(np.where(binary_mask > 0))\n",
        "        if len(coords) == 0:\n",
        "            return image_array\n",
        "        \n",
        "        y_min, x_min = coords.min(axis=0)\n",
        "        y_max, x_max = coords.max(axis=0)\n",
        "        \n",
        "        # Calculate resize crop (clear area) - exactly like V1.3 with GENEROUS padding\n",
        "        img_height, img_width = image_array.shape[:2]\n",
        "        \n",
        "        # Add GENEROUS padding around lung boundaries (like V1.3) - THIS IS THE KEY FIX\n",
        "        generous_padding = 180  # Much larger padding like V1.3 (was 20, now 180 like V1.3)\n",
        "        y_min_padded = max(0, y_min - generous_padding)\n",
        "        x_min_padded = max(0, x_min - generous_padding)\n",
        "        y_max_padded = min(img_height, y_max + generous_padding)\n",
        "        x_max_padded = min(img_width, x_max + generous_padding)\n",
        "        \n",
        "        # Find lung center for positioning the resize crop (like V1.3)\n",
        "        lung_center_y = (y_min_padded + y_max_padded) // 2\n",
        "        lung_center_x = (x_min_padded + x_max_padded) // 2\n",
        "        \n",
        "        # Calculate resize crop dimensions based on TARGET_SIZE (like V1.3)\n",
        "        target_aspect_ratio = TARGET_SIZE[0] / TARGET_SIZE[1]  # width/height\n",
        "        \n",
        "        # Make resize crop large enough to contain the lung area, but respect aspect ratio\n",
        "        lung_width = x_max_padded - x_min_padded\n",
        "        lung_height = y_max_padded - y_min_padded\n",
        "        \n",
        "        # Calculate minimum size needed to contain lungs, then expand if needed (like V1.3)\n",
        "        min_width = lung_width + 80  # Even more extra margin (was 40, now 80 like V1.3)\n",
        "        min_height = lung_height + 80\n",
        "        \n",
        "        # Ensure aspect ratio is maintained (like V1.3)\n",
        "        if min_width / min_height > target_aspect_ratio:\n",
        "            # Width is limiting factor\n",
        "            resize_width = min_width\n",
        "            resize_height = int(resize_width / target_aspect_ratio)\n",
        "        else:\n",
        "            # Height is limiting factor  \n",
        "            resize_height = min_height\n",
        "            resize_width = int(resize_height * target_aspect_ratio)\n",
        "        \n",
        "        # Center resize crop on lung center, but keep within image bounds (like V1.3)\n",
        "        resize_x_min = max(0, lung_center_x - resize_width // 2)\n",
        "        resize_y_min = max(0, lung_center_y - resize_height // 2)\n",
        "        resize_x_max = min(img_width, resize_x_min + resize_width)\n",
        "        resize_y_max = min(img_height, resize_y_min + resize_height)\n",
        "        \n",
        "        # Adjust if we hit image boundaries (like V1.3)\n",
        "        if resize_x_max == img_width:\n",
        "            resize_x_min = img_width - resize_width\n",
        "        if resize_y_max == img_height:\n",
        "            resize_y_min = img_height - resize_height\n",
        "            \n",
        "        # Ensure non-negative coordinates (like V1.3)\n",
        "        resize_x_min = max(0, resize_x_min)\n",
        "        resize_y_min = max(0, resize_y_min)\n",
        "        \n",
        "        # VALIDATION: Ensure cyan rectangle is well separated from green corner brackets (like V1.3)\n",
        "        lung_coords = np.column_stack(np.where(binary_mask > 0))\n",
        "        if len(lung_coords) > 0:\n",
        "            actual_y_min, actual_x_min = lung_coords.min(axis=0)\n",
        "            actual_y_max, actual_x_max = lung_coords.max(axis=0)\n",
        "            \n",
        "            # Check minimum separation between green brackets and cyan rectangle\n",
        "            min_separation = 100  # Minimum pixels between green corners and cyan rectangle\n",
        "            \n",
        "            # FIX: Calculate separations correctly (cyan should be OUTSIDE green)\n",
        "            top_sep = actual_y_min - resize_y_min  # How much cyan extends above green\n",
        "            left_sep = actual_x_min - resize_x_min  # How much cyan extends left of green\n",
        "            bottom_sep = resize_y_max - actual_y_max  # How much cyan extends below green\n",
        "            right_sep = resize_x_max - actual_x_max  # How much cyan extends right of green\n",
        "            \n",
        "            if (top_sep < min_separation or left_sep < min_separation or \n",
        "                bottom_sep < min_separation or right_sep < min_separation):\n",
        "                \n",
        "                print(f\"üìç Debug: Expanding cyan rectangle for proper separation from green corners\")\n",
        "                print(f\"üìç Current separations - Top: {top_sep}, Left: {left_sep}, Bottom: {bottom_sep}, Right: {right_sep}\")\n",
        "                \n",
        "                # Expand resize crop to ensure proper separation\n",
        "                expand_amount = min_separation + 50  # Extra buffer\n",
        "                resize_x_min = max(0, actual_x_min - expand_amount)\n",
        "                resize_y_min = max(0, actual_y_min - expand_amount)\n",
        "                resize_x_max = min(img_width, actual_x_max + expand_amount)\n",
        "                resize_y_max = min(img_height, actual_y_max + expand_amount)\n",
        "                \n",
        "                print(f\"üìç Debug: Expanded cyan rectangle to ensure {min_separation}px separation\")\n",
        "            \n",
        "            # Final separation check\n",
        "            final_top_sep = actual_y_min - resize_y_min\n",
        "            final_left_sep = actual_x_min - resize_x_min\n",
        "            final_bottom_sep = resize_y_max - actual_y_max\n",
        "            final_right_sep = resize_x_max - actual_x_max\n",
        "            \n",
        "            print(f\"üìç Final separations - Top: {final_top_sep}, Left: {final_left_sep}, Bottom: {final_bottom_sep}, Right: {final_right_sep}\")\n",
        "        \n",
        "        print(f\"üìê Clear area crop: ({resize_y_min},{resize_x_min}) to ({resize_y_max},{resize_x_max})\")\n",
        "        \n",
        "        # Crop to clear area\n",
        "        if len(image_array.shape) == 3:\n",
        "            cropped = image_array[resize_y_min:resize_y_max, resize_x_min:resize_x_max, :]\n",
        "        else:\n",
        "            cropped = image_array[resize_y_min:resize_y_max, resize_x_min:resize_x_max]\n",
        "        \n",
        "        # Save masks if requested\n",
        "        if SAVE_MASKS:\n",
        "            os.makedirs(MASKS_PATH, exist_ok=True)\n",
        "            \n",
        "            # Save binary mask\n",
        "            mask_path = os.path.join(MASKS_PATH, f\"{file_id}_mask.png\")\n",
        "            mask_image = (binary_mask * 255).astype(np.uint8)\n",
        "            cv2.imwrite(mask_path, mask_image)\n",
        "            \n",
        "            # Save V1.3 style overlay\n",
        "            overlay_path = os.path.join(MASKS_PATH, f\"{file_id}_overlay.png\")\n",
        "            resize_bounds = (resize_y_min, resize_x_min, resize_y_max, resize_x_max)\n",
        "            overlay = create_v13_overlay(image_array, binary_mask, resize_bounds)\n",
        "            cv2.imwrite(overlay_path, overlay)\n",
        "            \n",
        "            print(f\"üíæ Saved V1.3 style masks: {file_id}_mask.png, {file_id}_overlay.png\")\n",
        "        \n",
        "        return cropped\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Processing failed for {file_id}: {e}\")\n",
        "        return image_array\n",
        "\n",
        "print(\"Image processing with V1.3 overlay loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download images from ArchiMed\n",
        "try:\n",
        "    # Load CSV data\n",
        "    user_info = a3conn.getUserInfos()\n",
        "    print(f\"üîê ArchiMed connection: {user_info}\")\n",
        "    \n",
        "    csv_path = os.path.join(CSV_FOLDER, CSV_LABELS_FILE)\n",
        "    df = pd.read_csv(csv_path, sep=CSV_SEPARATOR)\n",
        "    print(f\"‚úÖ Loaded CSV with {len(df)} rows\")\n",
        "    \n",
        "    # Find FileID column\n",
        "    file_id_column = None\n",
        "    for col in ['FileID', 'file_id', 'File_ID']:\n",
        "        if col in df.columns:\n",
        "            file_id_column = col\n",
        "            break\n",
        "    \n",
        "    if file_id_column is None:\n",
        "        raise ValueError(\"FileID column not found\")\n",
        "    \n",
        "    # Get file IDs\n",
        "    file_ids = df[file_id_column].dropna().unique()\n",
        "    total_files = len(file_ids)\n",
        "    \n",
        "    print(f\"üöÄ Starting download of {total_files} files\")\n",
        "    print(f\"Destination: {DOWNLOAD_PATH}\")\n",
        "    \n",
        "    # Download files\n",
        "    downloaded_files = []\n",
        "    \n",
        "    for i, file_id in enumerate(file_ids):\n",
        "        progress = ((i + 1) / total_files) * 100\n",
        "        file_id_str = str(file_id)\n",
        "        print(f\"‚¨áÔ∏è Downloading {file_id_str} ({progress:.1f}% - {i+1}/{total_files})\")\n",
        "        \n",
        "        try:\n",
        "            dicom_file_path = os.path.join(DOWNLOAD_PATH, f\"{file_id}.dcm\")\n",
        "            os.makedirs(DOWNLOAD_PATH, exist_ok=True)\n",
        "            \n",
        "            if os.path.exists(dicom_file_path):\n",
        "                print(f\"File {file_id} already exists, skipping\")\n",
        "                downloaded_files.append(dicom_file_path)\n",
        "                continue\n",
        "            \n",
        "            # Download file\n",
        "            result = a3conn.downloadFile(\n",
        "                int(file_id_str),\n",
        "                asStream=False,\n",
        "                destDir=DOWNLOAD_PATH,\n",
        "                filename=f\"{file_id_str}.dcm\",\n",
        "                inWorklist=False\n",
        "            )\n",
        "            \n",
        "            if result and os.path.exists(dicom_file_path):\n",
        "                downloaded_files.append(dicom_file_path)\n",
        "                print(f\"‚úÖ Downloaded: {dicom_file_path}\")\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Download unclear for {file_id_str}\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Failed to download {file_id_str}: {e}\")\n",
        "    \n",
        "    print(f\"‚úÖ Downloaded {len(downloaded_files)} files successfully\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Download failed: {e}\")\n",
        "    downloaded_files = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert DICOM files to images with segmentation\n",
        "def convert_dicom_to_image(dicom_path, output_path, target_size=TARGET_SIZE):\n",
        "    \"\"\"Convert DICOM to image with lung segmentation and cropping\"\"\"\n",
        "    try:\n",
        "        file_id = os.path.splitext(os.path.basename(dicom_path))[0]\n",
        "        \n",
        "        # Read DICOM\n",
        "        dicom_data = pydicom.dcmread(dicom_path)\n",
        "        image_array = dicom_data.pixel_array\n",
        "        print(f\"üìÅ Processing {file_id}: {image_array.shape}\")\n",
        "        \n",
        "        # Handle MONOCHROME1\n",
        "        if hasattr(dicom_data, 'PhotometricInterpretation'):\n",
        "            if dicom_data.PhotometricInterpretation == 'MONOCHROME1':\n",
        "                image_array = np.max(image_array) - image_array\n",
        "        \n",
        "        # Normalize to 0-255\n",
        "        if image_array.max() > 255:\n",
        "            image_array = ((image_array - image_array.min()) / \n",
        "                          (image_array.max() - image_array.min()) * 255).astype(np.uint8)\n",
        "        else:\n",
        "            image_array = image_array.astype(np.uint8)\n",
        "        \n",
        "        # Apply lung segmentation and cropping\n",
        "        processed_image = process_image_with_segmentation(image_array, file_id)\n",
        "        \n",
        "        # Convert to PIL\n",
        "        if len(processed_image.shape) == 2:\n",
        "            pil_image = Image.fromarray(processed_image, mode='L')\n",
        "        else:\n",
        "            pil_image = Image.fromarray(processed_image)\n",
        "        \n",
        "        # Resize to target size with aspect ratio preservation\n",
        "        current_width, current_height = pil_image.size\n",
        "        target_width, target_height = target_size\n",
        "        \n",
        "        current_ratio = current_width / current_height\n",
        "        target_ratio = target_width / target_height\n",
        "        \n",
        "        print(f\"üìê Current: {current_width}x{current_height} (ratio: {current_ratio:.3f})\")\n",
        "        print(f\"üìê Target: {target_width}x{target_height} (ratio: {target_ratio:.3f})\")\n",
        "        \n",
        "        # Center crop to match aspect ratio\n",
        "        if current_ratio > target_ratio:\n",
        "            # Crop width\n",
        "            new_width = int(current_height * target_ratio)\n",
        "            new_height = current_height\n",
        "            left = (current_width - new_width) // 2\n",
        "            top = 0\n",
        "            right = left + new_width\n",
        "            bottom = current_height\n",
        "            print(f\"üìè Cropping width: {current_width} ‚Üí {new_width}\")\n",
        "        else:\n",
        "            # Crop height\n",
        "            new_width = current_width\n",
        "            new_height = int(current_width / target_ratio)\n",
        "            left = 0\n",
        "            top = (current_height - new_height) // 2\n",
        "            right = current_width\n",
        "            bottom = top + new_height\n",
        "            print(f\"üìè Cropping height: {current_height} ‚Üí {new_height}\")\n",
        "        \n",
        "        # Apply crop and resize\n",
        "        pil_image = pil_image.crop((left, top, right, bottom))\n",
        "        pil_image = pil_image.resize(target_size, Image.Resampling.LANCZOS)\n",
        "        print(f\"‚úÖ Final size: {target_width}x{target_height}\")\n",
        "        \n",
        "        # Save image\n",
        "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "        pil_image.save(output_path)\n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to convert {dicom_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Convert downloaded files\n",
        "if CONVERT and downloaded_files:\n",
        "    print(f\"üîÑ Converting {len(downloaded_files)} DICOM files\")\n",
        "    os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "    \n",
        "    converted_count = 0\n",
        "    \n",
        "    for dicom_path in tqdm(downloaded_files, desc=\"Converting\"):\n",
        "        file_id = os.path.splitext(os.path.basename(dicom_path))[0]\n",
        "        output_path = os.path.join(IMAGES_PATH, f\"{file_id}.png\")\n",
        "        \n",
        "        if convert_dicom_to_image(dicom_path, output_path):\n",
        "            converted_count += 1\n",
        "    \n",
        "    print(f\"‚úÖ Converted {converted_count}/{len(downloaded_files)} files\")\n",
        "    print(f\"üìÇ Images: {IMAGES_PATH}\")\n",
        "    \n",
        "    if SAVE_MASKS:\n",
        "        print(f\"üéØ V1.3 style overlays: {MASKS_PATH}\")\n",
        "    \n",
        "    print(\"üéâ V1.4 Simplified processing complete!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No files to convert or conversion disabled\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "**<h1 align=\"center\">Download ArchiMed Images V1.4 - SIMPLIFIED</h1>**\n",
        "\n",
        "## **V1.4: Simplified Lung Segmentation & Cropping**\n",
        "- **Single Model**: Uses best available segmentation model (TorchXRayVision preferred)\n",
        "- **Clear Area Cropping**: Crops to the clear rectangular area (matches overlay bright zone)\n",
        "- **Simple Output**: Basic mask and overlay generation\n",
        "- **Minimal Configuration**: Only essential parameters\n",
        "\n",
        "## **Key Simplifications from V1.3:**\n",
        "- Removed ensemble methods and multiple thresholds\n",
        "- Removed enhanced preprocessing options\n",
        "- Simplified overlay generation\n",
        "- Reduced configuration parameters\n",
        "- Cleaner, more focused code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple Configuration\n",
        "CSV_FOLDER = \"/home/pyuser/data/Paradise_CSV/\"\n",
        "CSV_LABELS_FILE = \"Labeled_Data_RAW_Sample.csv\"\n",
        "CSV_SEPARATOR = \";\"\n",
        "\n",
        "# Paths\n",
        "DOWNLOAD_PATH = '/home/pyuser/data/Paradise_Test_DICOMs'\n",
        "IMAGES_PATH = '/home/pyuser/data/Paradise_Test_Images'\n",
        "MASKS_PATH = '/home/pyuser/data/Paradise_Masks'\n",
        "\n",
        "# Processing settings\n",
        "TARGET_SIZE = (518, 518)\n",
        "LUNG_THRESHOLD = 0.1  # Single threshold for lung detection\n",
        "CROP_MARGIN = 40  # Margin around lungs for final crop\n",
        "\n",
        "# Options\n",
        "CONVERT = True\n",
        "SAVE_MASKS = True\n",
        "\n",
        "print(\"V1.4 Simplified configuration loaded!\")\n",
        "print(f\"Target size: {TARGET_SIZE}\")\n",
        "print(f\"Lung threshold: {LUNG_THRESHOLD}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core dependencies\n",
        "import ArchiMedConnector.A3_Connector as A3_Conn\n",
        "import pandas as pd\n",
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"Core dependencies loaded\")\n",
        "\n",
        "# Initialize ArchiMed connector\n",
        "a3conn = A3_Conn.A3_Connector()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple segmentation model setup\n",
        "segmentation_model = None\n",
        "model_type = None\n",
        "\n",
        "# Try TorchXRayVision first (best option)\n",
        "try:\n",
        "    import torchxrayvision as xrv\n",
        "    import torch\n",
        "    segmentation_model = xrv.baseline_models.chestx_det.PSPNet()\n",
        "    model_type = 'torchxray'\n",
        "    print(\"‚úÖ TorchXRayVision loaded\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è Installing TorchXRayVision...\")\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"torchxrayvision\"])\n",
        "        import torchxrayvision as xrv\n",
        "        import torch\n",
        "        segmentation_model = xrv.baseline_models.chestx_det.PSPNet()\n",
        "        model_type = 'torchxray'\n",
        "        print(\"‚úÖ TorchXRayVision installed and loaded\")\n",
        "    except:\n",
        "        print(\"‚ùå TorchXRayVision unavailable, using fallback\")\n",
        "        model_type = 'fallback'\n",
        "\n",
        "print(f\"Segmentation method: {model_type}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Duplicate simple processing functions removed - using V1.3 style overlay instead\n",
        "print(\"Using V1.3 style processing - duplicate simple processing removed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Duplicate download section removed - using main download section (cell 6) instead\n",
        "print(\"Using main download and conversion pipeline - duplicate removed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Duplicate conversion section removed - using main V1.3 style conversion (cell 7) instead\n",
        "print(\"üéâ V1.4 Simplified - Single Pipeline Ready!\")\n",
        "print(\"‚úÖ Removed duplicate processing - now using only V1.3 style overlay\")\n",
        "print(\"üìç The overlay images will now show the correct V1.3 style visualization with:\")\n",
        "print(\"   ‚Ä¢ BRIGHT RED lung filling and borders\")\n",
        "print(\"   ‚Ä¢ GREEN corner brackets at exact segmentation boundaries\") \n",
        "print(\"   ‚Ä¢ CYAN rectangle with generous padding (well separated from green)\")\n",
        "print(\"   ‚Ä¢ Proper hierarchy: cyan contains green (not the reverse)\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
