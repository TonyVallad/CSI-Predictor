{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "# ArchiMed Images V1.4 - Separate Lung Detection\n",
        "\n",
        "Enhanced lung segmentation with **left/right lung differentiation** and ultra-sensitive detection.\n",
        "\n",
        "## ü´Å Key Features\n",
        "- **Separate left and right lung masks** - Creates individual PNG files for each lung\n",
        "- **Color-coded visualization** - Blue for left lung, red for right lung\n",
        "- **Ultra-low sensitivity thresholds** (0.0001 default for maximum detection)\n",
        "- **Enhanced preprocessing** (histogram equalization + gaussian blur)\n",
        "- **Multiple threshold strategy** with automatic fallbacks\n",
        "- **Aggressive morphological operations** for better mask cleanup\n",
        "\n",
        "## üìÅ Output Files\n",
        "For each image, creates:\n",
        "- `{file_id}_left_lung_mask.png` - Left lung only\n",
        "- `{file_id}_right_lung_mask.png` - Right lung only  \n",
        "- `{file_id}_combined_mask.png` - Both lungs combined\n",
        "- `{file_id}_overlay.png` - Color-coded visualization\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "CSV_FOLDER = \"/home/pyuser/data/Paradise_CSV/\"\n",
        "CSV_LABELS_FILE = \"Labeled_Data_RAW_Sample.csv\"\n",
        "CSV_SEPARATOR = \";\"\n",
        "\n",
        "DOWNLOAD_PATH = '/home/pyuser/data/Paradise_Test_DICOMs'\n",
        "IMAGES_PATH = '/home/pyuser/data/Paradise_Test_Images'\n",
        "MASKS_PATH = '/home/pyuser/data/Paradise_Masks'\n",
        "\n",
        "# Workflow: ArchiMed first, then local cache\n",
        "USE_ARCHIMED = True  # Try ArchiMed first (recommended)\n",
        "DOWNLOAD_IF_MISSING = True  # Download from ArchiMed if files not found locally\n",
        "\n",
        "TARGET_SIZE = (518, 518)\n",
        "\n",
        "# Ultra-High Sensitivity Control\n",
        "# Lower values = more sensitive (detects smaller/fainter lung areas)\n",
        "# Higher values = less sensitive (only detects clearer lung areas)\n",
        "# Range: 0.0001 (ultra sensitive) to 0.5 (less sensitive)\n",
        "MODEL_SENSITIVITY = 0.0001\n",
        "\n",
        "# Enhanced Detection Options\n",
        "ENABLE_HISTOGRAM_EQUALIZATION = True  # Enhance contrast before segmentation\n",
        "ENABLE_GAUSSIAN_BLUR = True           # Reduce noise before segmentation\n",
        "USE_MULTIPLE_THRESHOLDS = True        # Try multiple sensitivity levels\n",
        "AGGRESSIVE_MORPHOLOGY = True          # More aggressive mask cleanup\n",
        "ENABLE_DEBUG_OUTPUT = False           # Print segmentation debug info\n",
        "\n",
        "LUNG_FILL_OPACITY = 0.25\n",
        "LUNG_BORDER_OPACITY = 0.50\n",
        "\n",
        "CONVERT = True\n",
        "SAVE_MASKS = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dependencies\n",
        "import pandas as pd\n",
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import subprocess\n",
        "import sys\n",
        "import glob\n",
        "\n",
        "# ArchiMed connector initialization (V1.3 working pattern)\n",
        "try:\n",
        "    import ArchiMedConnector.A3_Connector as A3_Conn\n",
        "    a3conn = A3_Conn.A3_Connector()\n",
        "    \n",
        "    # Test the connection - this works in the download_archimed_images.py file\n",
        "    user_info = a3conn.getUserInfos()\n",
        "    print(\"‚úÖ ArchiMed connector initialized and authenticated successfully\")\n",
        "    print(f\"üë§ User: {user_info}\")\n",
        "    archimed_available = True\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è ArchiMed initialization failed: {e}\")\n",
        "    print(\"üìù Note: ArchiMed may require specific configuration or credentials\")\n",
        "    print(\"üîÑ Continuing with local file processing only...\")\n",
        "    a3conn = None\n",
        "    archimed_available = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Segmentation model setup\n",
        "segmentation_model = None\n",
        "model_type = None\n",
        "\n",
        "try:\n",
        "    import torchxrayvision as xrv\n",
        "    import torch\n",
        "    segmentation_model = xrv.baseline_models.chestx_det.PSPNet()\n",
        "    model_type = 'torchxray'\n",
        "except ImportError:\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"torchxrayvision\"])\n",
        "        import torchxrayvision as xrv\n",
        "        import torch\n",
        "        segmentation_model = xrv.baseline_models.chestx_det.PSPNet()\n",
        "        model_type = 'torchxray'\n",
        "    except:\n",
        "        model_type = 'fallback'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enhanced preprocessing and segmentation functions for separate lung detection\n",
        "\n",
        "def enhance_image_preprocessing(image):\n",
        "    \"\"\"Enhanced preprocessing for better segmentation detection\"\"\"\n",
        "    if len(image.shape) == 3:\n",
        "        image_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    else:\n",
        "        image_gray = image.copy()\n",
        "    \n",
        "    # Histogram equalization for better contrast\n",
        "    if ENABLE_HISTOGRAM_EQUALIZATION:\n",
        "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
        "        image_gray = clahe.apply(image_gray)\n",
        "    \n",
        "    # Gaussian blur to reduce noise\n",
        "    if ENABLE_GAUSSIAN_BLUR:\n",
        "        image_gray = cv2.GaussianBlur(image_gray, (3, 3), 0)\n",
        "    \n",
        "    return image_gray\n",
        "\n",
        "def segment_lungs_separate(image):\n",
        "    \"\"\"Returns separate left and right lung masks plus combined mask\"\"\"\n",
        "    if model_type == 'torchxray' and segmentation_model is not None:\n",
        "        return segment_with_torchxray_separate(image)\n",
        "    else:\n",
        "        return segment_with_fallback_separate(image)\n",
        "\n",
        "def segment_with_torchxray_separate(image):\n",
        "    try:\n",
        "        # Enhanced preprocessing\n",
        "        image_preprocessed = enhance_image_preprocessing(image)\n",
        "        \n",
        "        image_norm = xrv.datasets.normalize(image_preprocessed, 255)\n",
        "        image_norm = image_norm[None, ...]\n",
        "        \n",
        "        transform = xrv.datasets.XRayResizer(512)\n",
        "        image_resized = transform(image_norm)\n",
        "        image_tensor = torch.from_numpy(image_resized).float().unsqueeze(0)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output = segmentation_model(image_tensor)\n",
        "        \n",
        "        # Separate left and right lung masks\n",
        "        left_lung_mask = np.zeros((512, 512))\n",
        "        right_lung_mask = np.zeros((512, 512))\n",
        "        \n",
        "        for i, target in enumerate(segmentation_model.targets):\n",
        "            if target == 'Left Lung':\n",
        "                left_lung_mask = output[0, i].cpu().numpy()\n",
        "            elif target == 'Right Lung':\n",
        "                right_lung_mask = output[0, i].cpu().numpy()\n",
        "        \n",
        "        # Debug output\n",
        "        if ENABLE_DEBUG_OUTPUT:\n",
        "            print(f\"Left lung - Min: {left_lung_mask.min():.6f}, Max: {left_lung_mask.max():.6f}, Mean: {left_lung_mask.mean():.6f}\")\n",
        "            print(f\"Right lung - Min: {right_lung_mask.min():.6f}, Max: {right_lung_mask.max():.6f}, Mean: {right_lung_mask.mean():.6f}\")\n",
        "        \n",
        "        # Resize both masks\n",
        "        left_lung_mask = cv2.resize(left_lung_mask, (image.shape[1], image.shape[0]))\n",
        "        right_lung_mask = cv2.resize(right_lung_mask, (image.shape[1], image.shape[0]))\n",
        "        \n",
        "        def process_lung_mask(lung_mask, lung_name):\n",
        "            # Multiple threshold strategy for each lung\n",
        "            if USE_MULTIPLE_THRESHOLDS:\n",
        "                thresholds = [MODEL_SENSITIVITY, MODEL_SENSITIVITY * 0.5, MODEL_SENSITIVITY * 0.1, 0.0001]\n",
        "                best_mask = None\n",
        "                best_ratio = 0\n",
        "                \n",
        "                for threshold in thresholds:\n",
        "                    binary_mask = (lung_mask > threshold).astype(np.uint8)\n",
        "                    lung_ratio = np.sum(binary_mask) / (binary_mask.shape[0] * binary_mask.shape[1])\n",
        "                    \n",
        "                    if ENABLE_DEBUG_OUTPUT:\n",
        "                        print(f\"{lung_name} threshold {threshold:.6f}: Lung ratio = {lung_ratio:.4f}\")\n",
        "                    \n",
        "                    # Target reasonable lung area (1%-25% of image for individual lungs)\n",
        "                    if 0.01 <= lung_ratio <= 0.25:\n",
        "                        best_mask = binary_mask\n",
        "                        best_ratio = lung_ratio\n",
        "                        break\n",
        "                    elif lung_ratio > 0.0005 and best_mask is None:  # Accept very small areas as fallback\n",
        "                        best_mask = binary_mask\n",
        "                        best_ratio = lung_ratio\n",
        "                \n",
        "                if best_mask is not None:\n",
        "                    binary_mask = best_mask\n",
        "                    if ENABLE_DEBUG_OUTPUT:\n",
        "                        print(f\"{lung_name} selected mask with ratio: {best_ratio:.4f}\")\n",
        "                else:\n",
        "                    binary_mask = (lung_mask > 0.0001).astype(np.uint8)  # Ultra-low fallback\n",
        "                    if ENABLE_DEBUG_OUTPUT:\n",
        "                        print(f\"{lung_name} using ultra-low threshold fallback\")\n",
        "            else:\n",
        "                binary_mask = (lung_mask > MODEL_SENSITIVITY).astype(np.uint8)\n",
        "            \n",
        "            # Aggressive morphological operations\n",
        "            if AGGRESSIVE_MORPHOLOGY:\n",
        "                kernel_size = 15 if np.sum(binary_mask) > 500 else 20\n",
        "                kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
        "                binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n",
        "                binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
        "                \n",
        "                # Fill holes\n",
        "                contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "                cv2.fillPoly(binary_mask, contours, 1)\n",
        "            else:\n",
        "                kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))\n",
        "                binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n",
        "                binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
        "            \n",
        "            return binary_mask\n",
        "        \n",
        "        # Process each lung mask separately\n",
        "        left_binary_mask = process_lung_mask(left_lung_mask, \"Left lung\")\n",
        "        right_binary_mask = process_lung_mask(right_lung_mask, \"Right lung\")\n",
        "        \n",
        "        # Also return combined mask for compatibility\n",
        "        combined_mask = np.logical_or(left_binary_mask, right_binary_mask).astype(np.uint8)\n",
        "        \n",
        "        return left_binary_mask, right_binary_mask, combined_mask\n",
        "        \n",
        "    except Exception as e:\n",
        "        if ENABLE_DEBUG_OUTPUT:\n",
        "            print(f\"TorchXRay segmentation failed: {e}\")\n",
        "        return segment_with_fallback_separate(image)\n",
        "\n",
        "def segment_with_fallback_separate(image):\n",
        "    \"\"\"Fallback segmentation - returns same mask for both lungs since we can't differentiate\"\"\"\n",
        "    # Enhanced fallback with same preprocessing\n",
        "    image_preprocessed = enhance_image_preprocessing(image)\n",
        "    \n",
        "    _, otsu_mask = cv2.threshold(image_preprocessed, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    \n",
        "    # More aggressive morphology for fallback\n",
        "    kernel_size = 25 if AGGRESSIVE_MORPHOLOGY else 20\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
        "    mask_clean = cv2.morphologyEx(otsu_mask, cv2.MORPH_CLOSE, kernel)\n",
        "    mask_clean = cv2.morphologyEx(mask_clean, cv2.MORPH_OPEN, kernel)\n",
        "    \n",
        "    combined_mask = (mask_clean > 0).astype(np.uint8)\n",
        "    \n",
        "    # For fallback, we return the same mask for both lungs since we can't differentiate\n",
        "    return combined_mask, combined_mask, combined_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enhanced overlay function with separate lung visualization\n",
        "\n",
        "def create_v13_overlay_separate(image, left_mask, right_mask, combined_mask, resize_crop_bounds):\n",
        "    \"\"\"Create overlay with separate left/right lung visualization\"\"\"\n",
        "    overlay = image.copy()\n",
        "    if len(overlay.shape) == 2:\n",
        "        overlay = cv2.cvtColor(overlay, cv2.COLOR_GRAY2RGB)\n",
        "    \n",
        "    resize_y_min, resize_x_min, resize_y_max, resize_x_max = resize_crop_bounds\n",
        "    img_height, img_width = overlay.shape[:2]\n",
        "    \n",
        "    # Darken areas outside the resize crop\n",
        "    outside_resize_mask = np.ones((img_height, img_width), dtype=bool)\n",
        "    outside_resize_mask[resize_y_min:resize_y_max, resize_x_min:resize_x_max] = False\n",
        "    overlay[outside_resize_mask] = (overlay[outside_resize_mask] * 0.5).astype(np.uint8)\n",
        "    \n",
        "    # Separate lung visualization with different colors\n",
        "    left_areas = left_mask > 0\n",
        "    right_areas = right_mask > 0\n",
        "    \n",
        "    # Left lung = Blue, Right lung = Red\n",
        "    if np.any(left_areas):\n",
        "        # Blue fill for left lung\n",
        "        left_fill_colored = np.zeros_like(overlay)\n",
        "        left_fill_colored[left_areas] = [255, 0, 0]  # Blue\n",
        "        fill_opacity = max(LUNG_FILL_OPACITY, 0.3)\n",
        "        overlay[left_areas] = cv2.addWeighted(\n",
        "            overlay[left_areas], 1.0 - fill_opacity, \n",
        "            left_fill_colored[left_areas], fill_opacity, 0\n",
        "        )\n",
        "        \n",
        "        # Blue border for left lung\n",
        "        left_mask_uint8 = (left_mask * 255).astype(np.uint8)\n",
        "        contours, _ = cv2.findContours(left_mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        border_mask = np.zeros_like(left_mask, dtype=np.uint8)\n",
        "        cv2.drawContours(border_mask, contours, -1, 1, thickness=4)\n",
        "        \n",
        "        border_areas = border_mask > 0\n",
        "        if np.any(border_areas):\n",
        "            left_border_colored = np.zeros_like(overlay)\n",
        "            left_border_colored[border_areas] = [255, 0, 0]  # Blue\n",
        "            border_opacity = max(LUNG_BORDER_OPACITY, 0.7)\n",
        "            overlay[border_areas] = cv2.addWeighted(\n",
        "                overlay[border_areas], 1.0 - border_opacity, \n",
        "                left_border_colored[border_areas], border_opacity, 0\n",
        "            )\n",
        "    \n",
        "    if np.any(right_areas):\n",
        "        # Red fill for right lung\n",
        "        right_fill_colored = np.zeros_like(overlay)\n",
        "        right_fill_colored[right_areas] = [0, 0, 255]  # Red\n",
        "        fill_opacity = max(LUNG_FILL_OPACITY, 0.3)\n",
        "        overlay[right_areas] = cv2.addWeighted(\n",
        "            overlay[right_areas], 1.0 - fill_opacity, \n",
        "            right_fill_colored[right_areas], fill_opacity, 0\n",
        "        )\n",
        "        \n",
        "        # Red border for right lung\n",
        "        right_mask_uint8 = (right_mask * 255).astype(np.uint8)\n",
        "        contours, _ = cv2.findContours(right_mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        border_mask = np.zeros_like(right_mask, dtype=np.uint8)\n",
        "        cv2.drawContours(border_mask, contours, -1, 1, thickness=4)\n",
        "        \n",
        "        border_areas = border_mask > 0\n",
        "        if np.any(border_areas):\n",
        "            right_border_colored = np.zeros_like(overlay)\n",
        "            right_border_colored[border_areas] = [0, 0, 255]  # Red\n",
        "            border_opacity = max(LUNG_BORDER_OPACITY, 0.7)\n",
        "            overlay[border_areas] = cv2.addWeighted(\n",
        "                overlay[border_areas], 1.0 - border_opacity, \n",
        "                right_border_colored[border_areas], border_opacity, 0\n",
        "            )\n",
        "    \n",
        "    # Green corner brackets for combined lung area\n",
        "    def draw_corner_brackets(img, x1, y1, x2, y2, color, thickness=5, length=60):\n",
        "        img_height, img_width = img.shape[:2]\n",
        "        x1 = max(0, min(x1, img_width - 1))\n",
        "        y1 = max(0, min(y1, img_height - 1))\n",
        "        x2 = max(0, min(x2, img_width - 1))\n",
        "        y2 = max(0, min(y2, img_height - 1))\n",
        "        \n",
        "        max_length_x = min(length, (x2 - x1) // 4)\n",
        "        max_length_y = min(length, (y2 - y1) // 4)\n",
        "        length = max(20, min(max_length_x, max_length_y))\n",
        "        \n",
        "        # Corner bracket lines\n",
        "        cv2.line(img, (x1, y1), (min(x1 + length, img_width-1), y1), color, thickness)\n",
        "        cv2.line(img, (x1, y1), (x1, min(y1 + length, img_height-1)), color, thickness)\n",
        "        cv2.line(img, (max(x2 - length, 0), y1), (x2, y1), color, thickness)\n",
        "        cv2.line(img, (x2, y1), (x2, min(y1 + length, img_height-1)), color, thickness)\n",
        "        cv2.line(img, (x1, max(y2 - length, 0)), (x1, y2), color, thickness)\n",
        "        cv2.line(img, (x1, y2), (min(x1 + length, img_width-1), y2), color, thickness)\n",
        "        cv2.line(img, (x2, max(y2 - length, 0)), (x2, y2), color, thickness)\n",
        "        cv2.line(img, (max(x2 - length, 0), y2), (x2, y2), color, thickness)\n",
        "    \n",
        "    # Use combined mask for brackets\n",
        "    lung_coords = np.where(combined_mask > 0)\n",
        "    if len(lung_coords[0]) > 0:\n",
        "        actual_y_min = np.min(lung_coords[0])\n",
        "        actual_y_max = np.max(lung_coords[0])  \n",
        "        actual_x_min = np.min(lung_coords[1])\n",
        "        actual_x_max = np.max(lung_coords[1])\n",
        "        \n",
        "        if (actual_x_min >= 0 and actual_y_min >= 0 and \n",
        "            actual_x_max < overlay.shape[1] and actual_y_max < overlay.shape[0] and\n",
        "            actual_x_max > actual_x_min and actual_y_max > actual_y_min):\n",
        "            draw_corner_brackets(overlay, actual_x_min, actual_y_min, actual_x_max, actual_y_max, (0, 255, 0), 5, 60)\n",
        "    \n",
        "    # Cyan rectangle for crop area\n",
        "    cv2.rectangle(overlay, (resize_x_min, resize_y_min), (resize_x_max, resize_y_max), (255, 255, 0), 1)\n",
        "    \n",
        "    # Enhanced legend with lung differentiation\n",
        "    legend_height = 140\n",
        "    legend_width = min(750, img_width - 20)\n",
        "    legend_y_start = img_height - legend_height - 10\n",
        "    \n",
        "    legend_background = np.zeros((legend_height, legend_width, 3), dtype=np.uint8)\n",
        "    legend_area = overlay[legend_y_start:legend_y_start + legend_height, 10:10 + legend_width]\n",
        "    overlay[legend_y_start:legend_y_start + legend_height, 10:10 + legend_width] = cv2.addWeighted(\n",
        "        legend_area, 0.2, legend_background, 0.8, 0\n",
        "    )\n",
        "    \n",
        "    text_y = legend_y_start + 20\n",
        "    cv2.putText(overlay, \"BLUE = Left lung | RED = Right lung\", \n",
        "               (20, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255, 255, 255), 2)\n",
        "    cv2.putText(overlay, \"GREEN = Combined lung brackets\", \n",
        "               (20, text_y + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (0, 255, 0), 2)\n",
        "    cv2.putText(overlay, f\"CYAN = Crop {TARGET_SIZE[0]}x{TARGET_SIZE[1]}\", \n",
        "               (20, text_y + 50), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255, 255, 0), 2)\n",
        "    \n",
        "    # Enhanced detection features\n",
        "    features = []\n",
        "    if ENABLE_HISTOGRAM_EQUALIZATION: features.append(\"HistEq\")\n",
        "    if ENABLE_GAUSSIAN_BLUR: features.append(\"Blur\")\n",
        "    if USE_MULTIPLE_THRESHOLDS: features.append(\"MultiThresh\")\n",
        "    if AGGRESSIVE_MORPHOLOGY: features.append(\"AggroMorph\")\n",
        "    features_text = \"+\".join(features) if features else \"Basic\"\n",
        "    \n",
        "    cv2.putText(overlay, f\"Sensitivity: {MODEL_SENSITIVITY} | Enhanced: {features_text}\", \n",
        "               (20, text_y + 75), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 255, 255), 1)\n",
        "    cv2.putText(overlay, f\"Model: {model_type} | Separate L/R lung detection\", \n",
        "               (20, text_y + 95), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 255, 255), 1)\n",
        "    \n",
        "    return overlay\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modified processing function to handle separate lung masks\n",
        "\n",
        "def process_image_with_segmentation_separate(image_array, file_id):\n",
        "    \"\"\"Process image with separate left/right lung segmentation\"\"\"\n",
        "    try:\n",
        "        left_binary_mask, right_binary_mask, combined_mask = segment_lungs_separate(image_array)\n",
        "        \n",
        "        # Always save masks and overlays, even for small segmented areas\n",
        "        if SAVE_MASKS:\n",
        "            os.makedirs(MASKS_PATH, exist_ok=True)\n",
        "            \n",
        "            # Save individual lung masks\n",
        "            left_mask_path = os.path.join(MASKS_PATH, f\"{file_id}_left_lung_mask.png\")\n",
        "            right_mask_path = os.path.join(MASKS_PATH, f\"{file_id}_right_lung_mask.png\")\n",
        "            combined_mask_path = os.path.join(MASKS_PATH, f\"{file_id}_combined_mask.png\")\n",
        "            \n",
        "            left_mask_image = (left_binary_mask * 255).astype(np.uint8)\n",
        "            right_mask_image = (right_binary_mask * 255).astype(np.uint8)\n",
        "            combined_mask_image = (combined_mask * 255).astype(np.uint8)\n",
        "            \n",
        "            cv2.imwrite(left_mask_path, left_mask_image)\n",
        "            cv2.imwrite(right_mask_path, right_mask_image)\n",
        "            cv2.imwrite(combined_mask_path, combined_mask_image)\n",
        "        \n",
        "        total_pixels = combined_mask.shape[0] * combined_mask.shape[1]\n",
        "        lung_pixels = np.sum(combined_mask)\n",
        "        lung_ratio = lung_pixels / total_pixels\n",
        "        \n",
        "        # Only skip cropping for very extreme cases (but still save masks/overlays above)\n",
        "        if lung_ratio < 0.001 or lung_ratio > 0.98:\n",
        "            # Create overlay even for extreme cases\n",
        "            if SAVE_MASKS:\n",
        "                img_height, img_width = image_array.shape[:2]\n",
        "                resize_bounds = (0, 0, img_height, img_width)  # Use full image bounds\n",
        "                overlay_path = os.path.join(MASKS_PATH, f\"{file_id}_overlay.png\")\n",
        "                overlay = create_v13_overlay_separate(image_array, left_binary_mask, right_binary_mask, combined_mask, resize_bounds)\n",
        "                cv2.imwrite(overlay_path, overlay)\n",
        "            return image_array\n",
        "        \n",
        "        coords = np.column_stack(np.where(combined_mask > 0))\n",
        "        if len(coords) == 0:\n",
        "            # Create overlay even when no coords found\n",
        "            if SAVE_MASKS:\n",
        "                img_height, img_width = image_array.shape[:2]\n",
        "                resize_bounds = (0, 0, img_height, img_width)\n",
        "                overlay_path = os.path.join(MASKS_PATH, f\"{file_id}_overlay.png\")\n",
        "                overlay = create_v13_overlay_separate(image_array, left_binary_mask, right_binary_mask, combined_mask, resize_bounds)\n",
        "                cv2.imwrite(overlay_path, overlay)\n",
        "            return image_array\n",
        "        \n",
        "        y_min, x_min = coords.min(axis=0)\n",
        "        y_max, x_max = coords.max(axis=0)\n",
        "        \n",
        "        img_height, img_width = image_array.shape[:2]\n",
        "        \n",
        "        # Generous padding around lungs\n",
        "        generous_padding = 180\n",
        "        y_min_padded = max(0, y_min - generous_padding)\n",
        "        x_min_padded = max(0, x_min - generous_padding)\n",
        "        y_max_padded = min(img_height, y_max + generous_padding)\n",
        "        x_max_padded = min(img_width, x_max + generous_padding)\n",
        "        \n",
        "        lung_center_y = (y_min_padded + y_max_padded) // 2\n",
        "        lung_center_x = (x_min_padded + x_max_padded) // 2\n",
        "        \n",
        "        target_aspect_ratio = TARGET_SIZE[0] / TARGET_SIZE[1]\n",
        "        lung_width = x_max_padded - x_min_padded\n",
        "        lung_height = y_max_padded - y_min_padded\n",
        "        \n",
        "        min_width = lung_width + 80\n",
        "        min_height = lung_height + 80\n",
        "        \n",
        "        if min_width / min_height > target_aspect_ratio:\n",
        "            resize_width = min_width\n",
        "            resize_height = int(resize_width / target_aspect_ratio)\n",
        "        else:\n",
        "            resize_height = min_height\n",
        "            resize_width = int(resize_height * target_aspect_ratio)\n",
        "        \n",
        "        resize_x_min = max(0, lung_center_x - resize_width // 2)\n",
        "        resize_y_min = max(0, lung_center_y - resize_height // 2)\n",
        "        resize_x_max = min(img_width, resize_x_min + resize_width)\n",
        "        resize_y_max = min(img_height, resize_y_min + resize_height)\n",
        "        \n",
        "        if resize_x_max == img_width:\n",
        "            resize_x_min = img_width - resize_width\n",
        "        if resize_y_max == img_height:\n",
        "            resize_y_min = img_height - resize_height\n",
        "            \n",
        "        resize_x_min = max(0, resize_x_min)\n",
        "        resize_y_min = max(0, resize_y_min)\n",
        "        \n",
        "        # Ensure proper separation between green brackets and cyan rectangle\n",
        "        lung_coords = np.column_stack(np.where(combined_mask > 0))\n",
        "        if len(lung_coords) > 0:\n",
        "            actual_y_min, actual_x_min = lung_coords.min(axis=0)\n",
        "            actual_y_max, actual_x_max = lung_coords.max(axis=0)\n",
        "            \n",
        "            min_separation = 100\n",
        "            top_sep = actual_y_min - resize_y_min\n",
        "            left_sep = actual_x_min - resize_x_min\n",
        "            bottom_sep = resize_y_max - actual_y_max\n",
        "            right_sep = resize_x_max - actual_x_max\n",
        "            \n",
        "            if (top_sep < min_separation or left_sep < min_separation or \n",
        "                bottom_sep < min_separation or right_sep < min_separation):\n",
        "                \n",
        "                expand_amount = min_separation + 50\n",
        "                resize_x_min = max(0, actual_x_min - expand_amount)\n",
        "                resize_y_min = max(0, actual_y_min - expand_amount)\n",
        "                resize_x_max = min(img_width, actual_x_max + expand_amount)\n",
        "                resize_y_max = min(img_height, actual_y_max + expand_amount)\n",
        "        \n",
        "        # Crop to clear area\n",
        "        if len(image_array.shape) == 3:\n",
        "            cropped = image_array[resize_y_min:resize_y_max, resize_x_min:resize_x_max, :]\n",
        "        else:\n",
        "            cropped = image_array[resize_y_min:resize_y_max, resize_x_min:resize_x_max]\n",
        "        \n",
        "        # Save overlay with proper crop bounds\n",
        "        if SAVE_MASKS:\n",
        "            overlay_path = os.path.join(MASKS_PATH, f\"{file_id}_overlay.png\")\n",
        "            resize_bounds = (resize_y_min, resize_x_min, resize_y_max, resize_x_max)\n",
        "            overlay = create_v13_overlay_separate(image_array, left_binary_mask, right_binary_mask, combined_mask, resize_bounds)\n",
        "            cv2.imwrite(overlay_path, overlay)\n",
        "        \n",
        "        return cropped\n",
        "        \n",
        "    except Exception:\n",
        "        return image_array\n",
        "\n",
        "# Update the main segment_lungs function to use separate segmentation\n",
        "def segment_lungs(image):\n",
        "    \"\"\"Updated to use separate lung segmentation and return combined mask for compatibility\"\"\"\n",
        "    left_mask, right_mask, combined_mask = segment_lungs_separate(image)\n",
        "    return combined_mask  # Return combined for backward compatibility\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def segment_lungs(image):\n",
        "    if model_type == 'torchxray' and segmentation_model is not None:\n",
        "        return segment_with_torchxray(image)\n",
        "    else:\n",
        "        return segment_with_fallback(image)\n",
        "\n",
        "def enhance_image_preprocessing(image):\n",
        "    \"\"\"Enhanced preprocessing for better segmentation detection\"\"\"\n",
        "    if len(image.shape) == 3:\n",
        "        image_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    else:\n",
        "        image_gray = image.copy()\n",
        "    \n",
        "    # Histogram equalization for better contrast\n",
        "    if ENABLE_HISTOGRAM_EQUALIZATION:\n",
        "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
        "        image_gray = clahe.apply(image_gray)\n",
        "    \n",
        "    # Gaussian blur to reduce noise\n",
        "    if ENABLE_GAUSSIAN_BLUR:\n",
        "        image_gray = cv2.GaussianBlur(image_gray, (3, 3), 0)\n",
        "    \n",
        "    return image_gray\n",
        "\n",
        "def segment_with_torchxray(image):\n",
        "    try:\n",
        "        # Enhanced preprocessing\n",
        "        image_preprocessed = enhance_image_preprocessing(image)\n",
        "        \n",
        "        image_norm = xrv.datasets.normalize(image_preprocessed, 255)\n",
        "        image_norm = image_norm[None, ...]\n",
        "        \n",
        "        transform = xrv.datasets.XRayResizer(512)\n",
        "        image_resized = transform(image_norm)\n",
        "        image_tensor = torch.from_numpy(image_resized).float().unsqueeze(0)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output = segmentation_model(image_tensor)\n",
        "        \n",
        "        lung_targets = ['Left Lung', 'Right Lung']\n",
        "        lung_mask = np.zeros((512, 512))\n",
        "        \n",
        "        for i, target in enumerate(segmentation_model.targets):\n",
        "            if target in lung_targets:\n",
        "                lung_mask += output[0, i].cpu().numpy()\n",
        "        \n",
        "        # Debug output\n",
        "        if ENABLE_DEBUG_OUTPUT:\n",
        "            print(f\"Raw mask stats - Min: {lung_mask.min():.6f}, Max: {lung_mask.max():.6f}, Mean: {lung_mask.mean():.6f}\")\n",
        "        \n",
        "        lung_mask = cv2.resize(lung_mask, (image.shape[1], image.shape[0]))\n",
        "        \n",
        "        # Multiple threshold strategy\n",
        "        if USE_MULTIPLE_THRESHOLDS:\n",
        "            thresholds = [MODEL_SENSITIVITY, MODEL_SENSITIVITY * 0.5, MODEL_SENSITIVITY * 0.1, 0.0001]\n",
        "            best_mask = None\n",
        "            best_ratio = 0\n",
        "            \n",
        "            for threshold in thresholds:\n",
        "                binary_mask = (lung_mask > threshold).astype(np.uint8)\n",
        "                lung_ratio = np.sum(binary_mask) / (binary_mask.shape[0] * binary_mask.shape[1])\n",
        "                \n",
        "                if ENABLE_DEBUG_OUTPUT:\n",
        "                    print(f\"Threshold {threshold:.6f}: Lung ratio = {lung_ratio:.4f}\")\n",
        "                \n",
        "                # Target reasonable lung area (2%-40% of image)\n",
        "                if 0.02 <= lung_ratio <= 0.40:\n",
        "                    best_mask = binary_mask\n",
        "                    best_ratio = lung_ratio\n",
        "                    break\n",
        "                elif lung_ratio > 0.001 and best_mask is None:  # Accept very small areas as fallback\n",
        "                    best_mask = binary_mask\n",
        "                    best_ratio = lung_ratio\n",
        "            \n",
        "            if best_mask is not None:\n",
        "                binary_mask = best_mask\n",
        "                if ENABLE_DEBUG_OUTPUT:\n",
        "                    print(f\"Selected mask with ratio: {best_ratio:.4f}\")\n",
        "            else:\n",
        "                binary_mask = (lung_mask > 0.0001).astype(np.uint8)  # Ultra-low fallback\n",
        "                if ENABLE_DEBUG_OUTPUT:\n",
        "                    print(\"Using ultra-low threshold fallback\")\n",
        "        else:\n",
        "            binary_mask = (lung_mask > MODEL_SENSITIVITY).astype(np.uint8)\n",
        "        \n",
        "        # Aggressive morphological operations\n",
        "        if AGGRESSIVE_MORPHOLOGY:\n",
        "            kernel_size = 15 if np.sum(binary_mask) > 1000 else 20\n",
        "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
        "            binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n",
        "            binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
        "            \n",
        "            # Fill holes\n",
        "            contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "            cv2.fillPoly(binary_mask, contours, 1)\n",
        "        else:\n",
        "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))\n",
        "            binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n",
        "            binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
        "        \n",
        "        return binary_mask\n",
        "        \n",
        "    except Exception as e:\n",
        "        if ENABLE_DEBUG_OUTPUT:\n",
        "            print(f\"TorchXRay segmentation failed: {e}\")\n",
        "        return segment_with_fallback(image)\n",
        "\n",
        "def segment_with_fallback(image):\n",
        "    # Enhanced fallback with same preprocessing\n",
        "    image_preprocessed = enhance_image_preprocessing(image)\n",
        "    \n",
        "    _, otsu_mask = cv2.threshold(image_preprocessed, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    \n",
        "    # More aggressive morphology for fallback\n",
        "    kernel_size = 25 if AGGRESSIVE_MORPHOLOGY else 20\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
        "    mask_clean = cv2.morphologyEx(otsu_mask, cv2.MORPH_CLOSE, kernel)\n",
        "    mask_clean = cv2.morphologyEx(mask_clean, cv2.MORPH_OPEN, kernel)\n",
        "    \n",
        "    return (mask_clean > 0).astype(np.uint8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_v13_overlay(image, binary_mask, resize_crop_bounds):\n",
        "    overlay = image.copy()\n",
        "    if len(overlay.shape) == 2:\n",
        "        overlay = cv2.cvtColor(overlay, cv2.COLOR_GRAY2RGB)\n",
        "    \n",
        "    resize_y_min, resize_x_min, resize_y_max, resize_x_max = resize_crop_bounds\n",
        "    img_height, img_width = overlay.shape[:2]\n",
        "    \n",
        "    # Darken areas outside the resize crop\n",
        "    outside_resize_mask = np.ones((img_height, img_width), dtype=bool)\n",
        "    outside_resize_mask[resize_y_min:resize_y_max, resize_x_min:resize_x_max] = False\n",
        "    overlay[outside_resize_mask] = (overlay[outside_resize_mask] * 0.5).astype(np.uint8)\n",
        "    \n",
        "    # Red lung visualization\n",
        "    lung_areas = binary_mask > 0\n",
        "    if np.any(lung_areas):\n",
        "        # Red fill\n",
        "        lung_fill_colored = np.zeros_like(overlay)\n",
        "        lung_fill_colored[lung_areas] = [0, 0, 255]\n",
        "        fill_opacity = max(LUNG_FILL_OPACITY, 0.4)\n",
        "        overlay[lung_areas] = cv2.addWeighted(\n",
        "            overlay[lung_areas], 1.0 - fill_opacity, \n",
        "            lung_fill_colored[lung_areas], fill_opacity, 0\n",
        "        )\n",
        "        \n",
        "        # Red border\n",
        "        lung_mask_uint8 = (binary_mask * 255).astype(np.uint8)\n",
        "        contours, _ = cv2.findContours(lung_mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        border_mask = np.zeros_like(binary_mask, dtype=np.uint8)\n",
        "        cv2.drawContours(border_mask, contours, -1, 1, thickness=6)\n",
        "        \n",
        "        border_areas = border_mask > 0\n",
        "        if np.any(border_areas):\n",
        "            lung_border_colored = np.zeros_like(overlay)\n",
        "            lung_border_colored[border_areas] = [0, 0, 255]\n",
        "            border_opacity = max(LUNG_BORDER_OPACITY, 0.6)\n",
        "            overlay[border_areas] = cv2.addWeighted(\n",
        "                overlay[border_areas], 1.0 - border_opacity, \n",
        "                lung_border_colored[border_areas], border_opacity, 0\n",
        "            )\n",
        "    \n",
        "    # Green corner brackets\n",
        "    def draw_corner_brackets(img, x1, y1, x2, y2, color, thickness=5, length=60):\n",
        "        img_height, img_width = img.shape[:2]\n",
        "        x1 = max(0, min(x1, img_width - 1))\n",
        "        y1 = max(0, min(y1, img_height - 1))\n",
        "        x2 = max(0, min(x2, img_width - 1))\n",
        "        y2 = max(0, min(y2, img_height - 1))\n",
        "        \n",
        "        max_length_x = min(length, (x2 - x1) // 4)\n",
        "        max_length_y = min(length, (y2 - y1) // 4)\n",
        "        length = max(20, min(max_length_x, max_length_y))\n",
        "        \n",
        "        # Top-left\n",
        "        cv2.line(img, (x1, y1), (min(x1 + length, img_width-1), y1), color, thickness)\n",
        "        cv2.line(img, (x1, y1), (x1, min(y1 + length, img_height-1)), color, thickness)\n",
        "        # Top-right\n",
        "        cv2.line(img, (max(x2 - length, 0), y1), (x2, y1), color, thickness)\n",
        "        cv2.line(img, (x2, y1), (x2, min(y1 + length, img_height-1)), color, thickness)\n",
        "        # Bottom-left\n",
        "        cv2.line(img, (x1, max(y2 - length, 0)), (x1, y2), color, thickness)\n",
        "        cv2.line(img, (x1, y2), (min(x1 + length, img_width-1), y2), color, thickness)\n",
        "        # Bottom-right\n",
        "        cv2.line(img, (x2, max(y2 - length, 0)), (x2, y2), color, thickness)\n",
        "        cv2.line(img, (max(x2 - length, 0), y2), (x2, y2), color, thickness)\n",
        "    \n",
        "    lung_coords = np.where(binary_mask > 0)\n",
        "    if len(lung_coords[0]) > 0:\n",
        "        actual_y_min = np.min(lung_coords[0])\n",
        "        actual_y_max = np.max(lung_coords[0])  \n",
        "        actual_x_min = np.min(lung_coords[1])\n",
        "        actual_x_max = np.max(lung_coords[1])\n",
        "        \n",
        "        if (actual_x_min >= 0 and actual_y_min >= 0 and \n",
        "            actual_x_max < overlay.shape[1] and actual_y_max < overlay.shape[0] and\n",
        "            actual_x_max > actual_x_min and actual_y_max > actual_y_min):\n",
        "            draw_corner_brackets(overlay, actual_x_min, actual_y_min, actual_x_max, actual_y_max, (0, 255, 0), 5, 60)\n",
        "    \n",
        "    # Cyan rectangle\n",
        "    cv2.rectangle(overlay, (resize_x_min, resize_y_min), (resize_x_max, resize_y_max), (255, 255, 0), 1)\n",
        "    \n",
        "    # Legend\n",
        "    legend_height = 120\n",
        "    legend_width = min(700, img_width - 20)\n",
        "    legend_y_start = img_height - legend_height - 10\n",
        "    \n",
        "    legend_background = np.zeros((legend_height, legend_width, 3), dtype=np.uint8)\n",
        "    legend_area = overlay[legend_y_start:legend_y_start + legend_height, 10:10 + legend_width]\n",
        "    overlay[legend_y_start:legend_y_start + legend_height, 10:10 + legend_width] = cv2.addWeighted(\n",
        "        legend_area, 0.25, legend_background, 0.75, 0\n",
        "    )\n",
        "    \n",
        "    text_y = legend_y_start + 20\n",
        "    cv2.putText(overlay, f\"RED = Lung segmentation (Fill: {int(LUNG_FILL_OPACITY*100)}%, Border: {int(LUNG_BORDER_OPACITY*100)}%)\", \n",
        "               (20, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 180), 2)\n",
        "    cv2.putText(overlay, \"GREEN = Segmentation corner brackets\", \n",
        "               (20, text_y + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "    cv2.putText(overlay, f\"CYAN = Final resize crop {TARGET_SIZE[0]}x{TARGET_SIZE[1]}\", \n",
        "               (20, text_y + 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n",
        "    \n",
        "    # Enhanced detection features\n",
        "    features = []\n",
        "    if ENABLE_HISTOGRAM_EQUALIZATION: features.append(\"HistEq\")\n",
        "    if ENABLE_GAUSSIAN_BLUR: features.append(\"Blur\")\n",
        "    if USE_MULTIPLE_THRESHOLDS: features.append(\"MultiThresh\")\n",
        "    if AGGRESSIVE_MORPHOLOGY: features.append(\"AggroMorph\")\n",
        "    features_text = \"+\".join(features) if features else \"Basic\"\n",
        "    \n",
        "    cv2.putText(overlay, f\"Sensitivity: {MODEL_SENSITIVITY} | Enhanced: {features_text}\", \n",
        "               (20, text_y + 75), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
        "    cv2.putText(overlay, f\"Model: {model_type}\", \n",
        "               (20, text_y + 95), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
        "    \n",
        "    return overlay\n",
        "\n",
        "def process_image_with_segmentation(image_array, file_id):\n",
        "    try:\n",
        "        binary_mask = segment_lungs(image_array)\n",
        "        \n",
        "        # Always save masks and overlays, even for small segmented areas\n",
        "        if SAVE_MASKS:\n",
        "            os.makedirs(MASKS_PATH, exist_ok=True)\n",
        "            \n",
        "            mask_path = os.path.join(MASKS_PATH, f\"{file_id}_mask.png\")\n",
        "            mask_image = (binary_mask * 255).astype(np.uint8)\n",
        "            cv2.imwrite(mask_path, mask_image)\n",
        "        \n",
        "        total_pixels = binary_mask.shape[0] * binary_mask.shape[1]\n",
        "        lung_pixels = np.sum(binary_mask)\n",
        "        lung_ratio = lung_pixels / total_pixels\n",
        "        \n",
        "        # Only skip cropping for very extreme cases (but still save masks/overlays above)\n",
        "        if lung_ratio < 0.001 or lung_ratio > 0.98:\n",
        "            # Create overlay even for extreme cases\n",
        "            if SAVE_MASKS:\n",
        "                img_height, img_width = image_array.shape[:2]\n",
        "                resize_bounds = (0, 0, img_height, img_width)  # Use full image bounds\n",
        "                overlay_path = os.path.join(MASKS_PATH, f\"{file_id}_overlay.png\")\n",
        "                overlay = create_v13_overlay(image_array, binary_mask, resize_bounds)\n",
        "                cv2.imwrite(overlay_path, overlay)\n",
        "            return image_array\n",
        "        \n",
        "        coords = np.column_stack(np.where(binary_mask > 0))\n",
        "        if len(coords) == 0:\n",
        "            # Create overlay even when no coords found\n",
        "            if SAVE_MASKS:\n",
        "                img_height, img_width = image_array.shape[:2]\n",
        "                resize_bounds = (0, 0, img_height, img_width)\n",
        "                overlay_path = os.path.join(MASKS_PATH, f\"{file_id}_overlay.png\")\n",
        "                overlay = create_v13_overlay(image_array, binary_mask, resize_bounds)\n",
        "                cv2.imwrite(overlay_path, overlay)\n",
        "            return image_array\n",
        "        \n",
        "        y_min, x_min = coords.min(axis=0)\n",
        "        y_max, x_max = coords.max(axis=0)\n",
        "        \n",
        "        img_height, img_width = image_array.shape[:2]\n",
        "        \n",
        "        # Generous padding around lungs\n",
        "        generous_padding = 180\n",
        "        y_min_padded = max(0, y_min - generous_padding)\n",
        "        x_min_padded = max(0, x_min - generous_padding)\n",
        "        y_max_padded = min(img_height, y_max + generous_padding)\n",
        "        x_max_padded = min(img_width, x_max + generous_padding)\n",
        "        \n",
        "        lung_center_y = (y_min_padded + y_max_padded) // 2\n",
        "        lung_center_x = (x_min_padded + x_max_padded) // 2\n",
        "        \n",
        "        target_aspect_ratio = TARGET_SIZE[0] / TARGET_SIZE[1]\n",
        "        lung_width = x_max_padded - x_min_padded\n",
        "        lung_height = y_max_padded - y_min_padded\n",
        "        \n",
        "        min_width = lung_width + 80\n",
        "        min_height = lung_height + 80\n",
        "        \n",
        "        if min_width / min_height > target_aspect_ratio:\n",
        "            resize_width = min_width\n",
        "            resize_height = int(resize_width / target_aspect_ratio)\n",
        "        else:\n",
        "            resize_height = min_height\n",
        "            resize_width = int(resize_height * target_aspect_ratio)\n",
        "        \n",
        "        resize_x_min = max(0, lung_center_x - resize_width // 2)\n",
        "        resize_y_min = max(0, lung_center_y - resize_height // 2)\n",
        "        resize_x_max = min(img_width, resize_x_min + resize_width)\n",
        "        resize_y_max = min(img_height, resize_y_min + resize_height)\n",
        "        \n",
        "        if resize_x_max == img_width:\n",
        "            resize_x_min = img_width - resize_width\n",
        "        if resize_y_max == img_height:\n",
        "            resize_y_min = img_height - resize_height\n",
        "            \n",
        "        resize_x_min = max(0, resize_x_min)\n",
        "        resize_y_min = max(0, resize_y_min)\n",
        "        \n",
        "        # Ensure proper separation between green brackets and cyan rectangle\n",
        "        lung_coords = np.column_stack(np.where(binary_mask > 0))\n",
        "        if len(lung_coords) > 0:\n",
        "            actual_y_min, actual_x_min = lung_coords.min(axis=0)\n",
        "            actual_y_max, actual_x_max = lung_coords.max(axis=0)\n",
        "            \n",
        "            min_separation = 100\n",
        "            top_sep = actual_y_min - resize_y_min\n",
        "            left_sep = actual_x_min - resize_x_min\n",
        "            bottom_sep = resize_y_max - actual_y_max\n",
        "            right_sep = resize_x_max - actual_x_max\n",
        "            \n",
        "            if (top_sep < min_separation or left_sep < min_separation or \n",
        "                bottom_sep < min_separation or right_sep < min_separation):\n",
        "                \n",
        "                expand_amount = min_separation + 50\n",
        "                resize_x_min = max(0, actual_x_min - expand_amount)\n",
        "                resize_y_min = max(0, actual_y_min - expand_amount)\n",
        "                resize_x_max = min(img_width, actual_x_max + expand_amount)\n",
        "                resize_y_max = min(img_height, actual_y_max + expand_amount)\n",
        "        \n",
        "        # Crop to clear area\n",
        "        if len(image_array.shape) == 3:\n",
        "            cropped = image_array[resize_y_min:resize_y_max, resize_x_min:resize_x_max, :]\n",
        "        else:\n",
        "            cropped = image_array[resize_y_min:resize_y_max, resize_x_min:resize_x_max]\n",
        "        \n",
        "        # Save overlay with proper crop bounds\n",
        "        if SAVE_MASKS:\n",
        "            overlay_path = os.path.join(MASKS_PATH, f\"{file_id}_overlay.png\")\n",
        "            resize_bounds = (resize_y_min, resize_x_min, resize_y_max, resize_x_max)\n",
        "            overlay = create_v13_overlay(image_array, binary_mask, resize_bounds)\n",
        "            cv2.imwrite(overlay_path, overlay)\n",
        "        \n",
        "        return cropped\n",
        "        \n",
        "    except Exception:\n",
        "        return image_array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download from ArchiMed\n",
        "try:\n",
        "    user_info = a3conn.getUserInfos()\n",
        "    csv_path = os.path.join(CSV_FOLDER, CSV_LABELS_FILE)\n",
        "    df = pd.read_csv(csv_path, sep=CSV_SEPARATOR)\n",
        "    \n",
        "    file_id_column = None\n",
        "    for col in ['FileID', 'file_id', 'File_ID']:\n",
        "        if col in df.columns:\n",
        "            file_id_column = col\n",
        "            break\n",
        "    \n",
        "    if file_id_column is None:\n",
        "        raise ValueError(\"FileID column not found\")\n",
        "    \n",
        "    file_ids = df[file_id_column].dropna().unique()\n",
        "    downloaded_files = []\n",
        "    \n",
        "    # Create progress bar with total count\n",
        "    pbar = tqdm(total=len(file_ids), desc=\"Downloading files\", unit=\"file\")\n",
        "    \n",
        "    for file_id in file_ids:\n",
        "        file_id_str = str(file_id)\n",
        "        dicom_file_path = os.path.join(DOWNLOAD_PATH, f\"{file_id}.dcm\")\n",
        "        os.makedirs(DOWNLOAD_PATH, exist_ok=True)\n",
        "        \n",
        "        if os.path.exists(dicom_file_path):\n",
        "            downloaded_files.append(dicom_file_path)\n",
        "            pbar.update(1)\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            result = a3conn.downloadFile(\n",
        "                int(file_id_str),\n",
        "                asStream=False,\n",
        "                destDir=DOWNLOAD_PATH,\n",
        "                filename=f\"{file_id_str}.dcm\",\n",
        "                inWorklist=False\n",
        "            )\n",
        "            \n",
        "            if result and os.path.exists(dicom_file_path):\n",
        "                downloaded_files.append(dicom_file_path)\n",
        "            \n",
        "            pbar.update(1)\n",
        "                \n",
        "        except Exception:\n",
        "            pbar.update(1)\n",
        "            pass\n",
        "    \n",
        "    pbar.close()\n",
        "    \n",
        "except Exception:\n",
        "    downloaded_files = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üß™ Test function for single DICOM file processing\n",
        "\n",
        "def process_single_dicom(dicom_path, output_base_name=None):\n",
        "    \"\"\"\n",
        "    Process a single DICOM file for testing purposes\n",
        "    \n",
        "    Args:\n",
        "        dicom_path (str): Path to the DICOM file\n",
        "        output_base_name (str): Base name for output files (optional)\n",
        "    \n",
        "    Returns:\n",
        "        bool: True if processing was successful\n",
        "    \"\"\"\n",
        "    if not os.path.exists(dicom_path):\n",
        "        print(f\"‚ùå DICOM file not found: {dicom_path}\")\n",
        "        return False\n",
        "    \n",
        "    try:\n",
        "        # Use filename as base name if not provided\n",
        "        if output_base_name is None:\n",
        "            output_base_name = os.path.splitext(os.path.basename(dicom_path))[0]\n",
        "        \n",
        "        print(f\"üîÑ Processing: {os.path.basename(dicom_path)}\")\n",
        "        \n",
        "        # Create output directories\n",
        "        os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "        os.makedirs(MASKS_PATH, exist_ok=True)\n",
        "        \n",
        "        # Output paths\n",
        "        output_image_path = os.path.join(IMAGES_PATH, f\"{output_base_name}.png\")\n",
        "        \n",
        "        # Process the DICOM file\n",
        "        success = convert_dicom_to_image(dicom_path, output_image_path)\n",
        "        \n",
        "        if success:\n",
        "            print(f\"‚úÖ Successfully processed {output_base_name}\")\n",
        "            print(f\"üìÅ Check output files:\")\n",
        "            print(f\"   ‚Ä¢ Image: {output_image_path}\")\n",
        "            \n",
        "            if SAVE_MASKS:\n",
        "                expected_masks = [\n",
        "                    f\"{output_base_name}_left_lung_mask.png\",\n",
        "                    f\"{output_base_name}_right_lung_mask.png\", \n",
        "                    f\"{output_base_name}_combined_mask.png\",\n",
        "                    f\"{output_base_name}_overlay.png\"\n",
        "                ]\n",
        "                \n",
        "                for mask_file in expected_masks:\n",
        "                    mask_path = os.path.join(MASKS_PATH, mask_file)\n",
        "                    if os.path.exists(mask_path):\n",
        "                        print(f\"   ‚Ä¢ {mask_file} ‚úÖ\")\n",
        "                    else:\n",
        "                        print(f\"   ‚Ä¢ {mask_file} ‚ùå\")\n",
        "            \n",
        "            return True\n",
        "        else:\n",
        "            print(f\"‚ùå Failed to process {output_base_name}\")\n",
        "            return False\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error processing {dicom_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Example usage:\n",
        "# process_single_dicom(\"/path/to/your/file.dcm\", \"test_image\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert DICOM to images\n",
        "def convert_dicom_to_image(dicom_path, output_path, target_size=TARGET_SIZE):\n",
        "    try:\n",
        "        file_id = os.path.splitext(os.path.basename(dicom_path))[0]\n",
        "        \n",
        "        dicom_data = pydicom.dcmread(dicom_path)\n",
        "        image_array = dicom_data.pixel_array\n",
        "        \n",
        "        if hasattr(dicom_data, 'PhotometricInterpretation'):\n",
        "            if dicom_data.PhotometricInterpretation == 'MONOCHROME1':\n",
        "                image_array = np.max(image_array) - image_array\n",
        "        \n",
        "        if image_array.max() > 255:\n",
        "            image_array = ((image_array - image_array.min()) / \n",
        "                          (image_array.max() - image_array.min()) * 255).astype(np.uint8)\n",
        "        else:\n",
        "            image_array = image_array.astype(np.uint8)\n",
        "        \n",
        "        processed_image = process_image_with_segmentation_separate(image_array, file_id)\n",
        "        \n",
        "        if len(processed_image.shape) == 2:\n",
        "            pil_image = Image.fromarray(processed_image, mode='L')\n",
        "        else:\n",
        "            pil_image = Image.fromarray(processed_image)\n",
        "        \n",
        "        current_width, current_height = pil_image.size\n",
        "        target_width, target_height = target_size\n",
        "        current_ratio = current_width / current_height\n",
        "        target_ratio = target_width / target_height\n",
        "        \n",
        "        if current_ratio > target_ratio:\n",
        "            new_width = int(current_height * target_ratio)\n",
        "            new_height = current_height\n",
        "            left = (current_width - new_width) // 2\n",
        "            top = 0\n",
        "            right = left + new_width\n",
        "            bottom = current_height\n",
        "        else:\n",
        "            new_width = current_width\n",
        "            new_height = int(current_width / target_ratio)\n",
        "            left = 0\n",
        "            top = (current_height - new_height) // 2\n",
        "            right = current_width\n",
        "            bottom = top + new_height\n",
        "        \n",
        "        pil_image = pil_image.crop((left, top, right, bottom))\n",
        "        pil_image = pil_image.resize(target_size, Image.Resampling.LANCZOS)\n",
        "        \n",
        "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "        pil_image.save(output_path)\n",
        "        return True\n",
        "        \n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# Convert files\n",
        "if CONVERT and downloaded_files:\n",
        "    os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "    converted_count = 0\n",
        "    \n",
        "    with tqdm(total=len(downloaded_files), desc=\"Converting DICOM files\", unit=\"file\") as pbar:\n",
        "        for dicom_path in downloaded_files:\n",
        "            file_id = os.path.splitext(os.path.basename(dicom_path))[0]\n",
        "            output_path = os.path.join(IMAGES_PATH, f\"{file_id}.png\")\n",
        "            \n",
        "            if convert_dicom_to_image(dicom_path, output_path):\n",
        "                converted_count += 1\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix({\"Converted\": converted_count})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üöÄ Execute the complete pipeline\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ü´Å ArchiMed Images V1.4 - Separate Lung Detection Pipeline\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Step 1: Connect to ArchiMed and get file list\n",
        "available_files = []\n",
        "authenticated = False\n",
        "\n",
        "if archimed_available:\n",
        "    print(\"\\nüîó Step 1: ArchiMed already connected\")\n",
        "    try:\n",
        "        # ArchiMed connection was established in imports cell\n",
        "        authenticated = True\n",
        "        \n",
        "        # Load CSV file to get file IDs\n",
        "        csv_path = os.path.join(CSV_FOLDER, CSV_LABELS_FILE)\n",
        "        if not os.path.exists(csv_path):\n",
        "            print(f\"‚ùå CSV file not found: {csv_path}\")\n",
        "            print(\"üìÇ Please check the CSV_FOLDER and CSV_LABELS_FILE settings\")\n",
        "        else:\n",
        "            df = pd.read_csv(csv_path, sep=CSV_SEPARATOR)\n",
        "            \n",
        "            # Find the FileID column\n",
        "            file_id_column = None\n",
        "            for col in ['FileID', 'file_id', 'File_ID']:\n",
        "                if col in df.columns:\n",
        "                    file_id_column = col\n",
        "                    break\n",
        "            \n",
        "            if file_id_column is None:\n",
        "                print(f\"‚ùå FileID column not found in CSV. Available columns: {list(df.columns)}\")\n",
        "            else:\n",
        "                file_ids = df[file_id_column].dropna().unique()\n",
        "                print(f\"üìã Found {len(file_ids)} files in CSV: {CSV_LABELS_FILE}\")\n",
        "                available_files = [str(fid) for fid in file_ids]\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå ArchiMed connection failed: {e}\")\n",
        "        print(\"üí° Tip: Check your ArchiMed credentials and network connection\")\n",
        "        authenticated = False\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è ArchiMed not available - cannot search for files\")\n",
        "\n",
        "# Step 2: Check local files and download missing ones\n",
        "print(f\"\\nüìÅ Step 2: Checking local files and downloading if needed...\")\n",
        "\n",
        "# Create download directory\n",
        "os.makedirs(DOWNLOAD_PATH, exist_ok=True)\n",
        "\n",
        "dicom_files = []\n",
        "files_to_download = []\n",
        "local_files_found = 0\n",
        "\n",
        "if available_files:\n",
        "    print(f\"üîç Checking {len(available_files)} files...\")\n",
        "    \n",
        "    for file_id in available_files:\n",
        "        dicom_path = os.path.join(DOWNLOAD_PATH, f\"{file_id}.dcm\")\n",
        "        \n",
        "        if os.path.exists(dicom_path):\n",
        "            dicom_files.append(dicom_path)\n",
        "            local_files_found += 1\n",
        "        else:\n",
        "            if authenticated and DOWNLOAD_IF_MISSING:\n",
        "                files_to_download.append(file_id)\n",
        "    \n",
        "    print(f\"‚úÖ Found {local_files_found} files locally\")\n",
        "    print(f\"üì• Need to download {len(files_to_download)} files\")\n",
        "    \n",
        "    # Download missing files\n",
        "    if files_to_download and authenticated:\n",
        "        print(f\"üåê Downloading {len(files_to_download)} missing files...\")\n",
        "        \n",
        "        download_success = 0\n",
        "        pbar = tqdm(total=len(files_to_download), desc=\"Downloading\", unit=\"file\")\n",
        "        \n",
        "        for file_id in files_to_download:\n",
        "            try:\n",
        "                dicom_path = os.path.join(DOWNLOAD_PATH, f\"{file_id}.dcm\")\n",
        "                \n",
        "                result = a3conn.downloadFile(\n",
        "                    int(file_id),\n",
        "                    asStream=False,\n",
        "                    destDir=DOWNLOAD_PATH,\n",
        "                    filename=f\"{file_id}.dcm\",\n",
        "                    inWorklist=False\n",
        "                )\n",
        "                \n",
        "                if result and os.path.exists(dicom_path):\n",
        "                    dicom_files.append(dicom_path)\n",
        "                    download_success += 1\n",
        "                \n",
        "            except Exception as download_error:\n",
        "                print(f\"‚ö†Ô∏è Failed to download {file_id}: {download_error}\")\n",
        "            \n",
        "            pbar.update(1)\n",
        "        \n",
        "        pbar.close()\n",
        "        print(f\"‚úÖ Successfully downloaded {download_success}/{len(files_to_download)} files\")\n",
        "    \n",
        "    elif files_to_download and not authenticated:\n",
        "        print(f\"‚ùå Cannot download {len(files_to_download)} missing files - ArchiMed not authenticated\")\n",
        "    \n",
        "else:\n",
        "    # No file list available, scan local directory\n",
        "    print(\"üìÇ No file list available, scanning local directory...\")\n",
        "    local_patterns = [\n",
        "        os.path.join(DOWNLOAD_PATH, \"*.dcm\"),\n",
        "        os.path.join(DOWNLOAD_PATH, \"*.DCM\"),\n",
        "        os.path.join(DOWNLOAD_PATH, \"**/*.dcm\"),\n",
        "        os.path.join(DOWNLOAD_PATH, \"**/*.DCM\"),\n",
        "    ]\n",
        "    \n",
        "    for pattern in local_patterns:\n",
        "        dicom_files.extend(glob.glob(pattern, recursive=True))\n",
        "    \n",
        "    dicom_files = list(set(dicom_files))  # Remove duplicates\n",
        "    print(f\"üìÅ Found {len(dicom_files)} local DICOM files\")\n",
        "\n",
        "print(f\"üéØ Total DICOM files ready for processing: {len(dicom_files)}\")\n",
        "\n",
        "# Step 3: Convert DICOM to images with separate lung segmentation\n",
        "print(f\"\\nüîÑ Step 3: Converting DICOM files with separate lung detection...\")\n",
        "\n",
        "if CONVERT and dicom_files:\n",
        "    os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "    converted_count = 0\n",
        "    \n",
        "    print(f\"Processing {len(dicom_files)} DICOM files...\")\n",
        "    print(f\"Output paths:\")\n",
        "    print(f\"  üìÅ Images: {IMAGES_PATH}\")\n",
        "    print(f\"  üìÅ Masks: {MASKS_PATH}\")\n",
        "    \n",
        "    with tqdm(total=len(dicom_files), desc=\"Converting DICOM files\", unit=\"file\") as pbar:\n",
        "        for dicom_path in dicom_files:\n",
        "            file_id = os.path.splitext(os.path.basename(dicom_path))[0]\n",
        "            output_path = os.path.join(IMAGES_PATH, f\"{file_id}.png\")\n",
        "            \n",
        "            if convert_dicom_to_image(dicom_path, output_path):\n",
        "                converted_count += 1\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix({\"Converted\": converted_count})\n",
        "    \n",
        "    print(f\"‚úÖ Successfully converted {converted_count} images\")\n",
        "    \n",
        "    # Summary of outputs\n",
        "    print(f\"\\nüìä Processing Summary:\")\n",
        "    print(f\"  ‚Ä¢ Converted images: {converted_count}\")\n",
        "    print(f\"  ‚Ä¢ Model type: {model_type}\")\n",
        "    print(f\"  ‚Ä¢ Sensitivity: {MODEL_SENSITIVITY}\")\n",
        "    \n",
        "    if SAVE_MASKS:\n",
        "        print(f\"\\nüìÅ Output files for each image:\")\n",
        "        print(f\"  ‚Ä¢ {IMAGES_PATH}/{{file_id}}.png - Processed image\")\n",
        "        print(f\"  ‚Ä¢ {MASKS_PATH}/{{file_id}}_left_lung_mask.png - Left lung mask\")\n",
        "        print(f\"  ‚Ä¢ {MASKS_PATH}/{{file_id}}_right_lung_mask.png - Right lung mask\")\n",
        "        print(f\"  ‚Ä¢ {MASKS_PATH}/{{file_id}}_combined_mask.png - Combined lung mask\")\n",
        "        print(f\"  ‚Ä¢ {MASKS_PATH}/{{file_id}}_overlay.png - Color-coded visualization\")\n",
        "        \n",
        "        # Check if masks were created\n",
        "        mask_files = []\n",
        "        if os.path.exists(MASKS_PATH):\n",
        "            mask_files = [f for f in os.listdir(MASKS_PATH) if f.endswith('_mask.png')]\n",
        "        \n",
        "        print(f\"\\nüéØ Created {len(mask_files)} mask files\")\n",
        "        \n",
        "        if mask_files:\n",
        "            print(f\"‚úÖ Pipeline completed successfully!\")\n",
        "            print(f\"üîç Check {MASKS_PATH} for visualization overlays\")\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è  No mask files found - check segmentation settings\")\n",
        "    \n",
        "else:\n",
        "    print(f\"‚ùå No files to convert or CONVERT=False\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"üèÅ Pipeline execution completed!\")\n",
        "print(f\"{'='*60}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üöÄ Quick Test: Process just one DICOM file to test ArchiMed connection\n",
        "\n",
        "def process_single_dicom():\n",
        "    \"\"\"Quick test function to process just one DICOM file\"\"\"\n",
        "    print(\"=\"*60)\n",
        "    print(\"üß™ Quick Test: Processing Single DICOM File\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Step 1: ArchiMed connection already established\n",
        "    if archimed_available:\n",
        "        print(\"\\nüîó ArchiMed connection available\")\n",
        "        print(f\"‚úÖ Using established connection from imports cell\")\n",
        "    \n",
        "    # Step 2: Find one DICOM file to test\n",
        "    print(f\"\\nüìÅ Looking for test DICOM file...\")\n",
        "    test_file = None\n",
        "    \n",
        "    local_patterns = [\n",
        "        os.path.join(DOWNLOAD_PATH, \"*.dcm\"),\n",
        "        os.path.join(DOWNLOAD_PATH, \"*.DCM\"),\n",
        "    ]\n",
        "    \n",
        "    for pattern in local_patterns:\n",
        "        files = glob.glob(pattern)\n",
        "        if files:\n",
        "            test_file = files[0]  # Take first file\n",
        "            break\n",
        "    \n",
        "    if test_file is None:\n",
        "        print(f\"‚ùå No DICOM files found in {DOWNLOAD_PATH}\")\n",
        "        return\n",
        "    \n",
        "    print(f\"üéØ Test file: {os.path.basename(test_file)}\")\n",
        "    \n",
        "    # Step 3: Process the test file\n",
        "    print(f\"\\nüîÑ Processing test file...\")\n",
        "    file_id = os.path.splitext(os.path.basename(test_file))[0]\n",
        "    output_path = os.path.join(IMAGES_PATH, f\"{file_id}_test.png\")\n",
        "    \n",
        "    os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "    \n",
        "    try:\n",
        "        if convert_dicom_to_image(test_file, output_path):\n",
        "            print(f\"‚úÖ Test conversion successful!\")\n",
        "            print(f\"üìÅ Output: {output_path}\")\n",
        "            \n",
        "            if SAVE_MASKS:\n",
        "                mask_files = [\n",
        "                    f\"{file_id}_left_lung_mask.png\",\n",
        "                    f\"{file_id}_right_lung_mask.png\", \n",
        "                    f\"{file_id}_combined_mask.png\",\n",
        "                    f\"{file_id}_overlay.png\"\n",
        "                ]\n",
        "                \n",
        "                existing_masks = []\n",
        "                for mask_file in mask_files:\n",
        "                    mask_path = os.path.join(MASKS_PATH, mask_file)\n",
        "                    if os.path.exists(mask_path):\n",
        "                        existing_masks.append(mask_file)\n",
        "                \n",
        "                print(f\"üéØ Created masks: {len(existing_masks)}/{len(mask_files)}\")\n",
        "                for mask in existing_masks:\n",
        "                    print(f\"  ‚úÖ {mask}\")\n",
        "        else:\n",
        "            print(f\"‚ùå Test conversion failed\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Test processing failed: {e}\")\n",
        "    \n",
        "    print(\"=\"*60)\n",
        "    print(\"üèÅ Quick test completed!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "# Run the quick test\n",
        "process_single_dicom()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
