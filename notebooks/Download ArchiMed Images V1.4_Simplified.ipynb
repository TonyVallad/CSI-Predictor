{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "**<h1 align=\"center\">Download ArchiMed Images V1.4 - SIMPLIFIED</h1>**\n",
        "\n",
        "## **V1.4: Simplified Lung Segmentation & Cropping**\n",
        "- **Single Model**: Uses best available segmentation model (TorchXRayVision preferred)\n",
        "- **Clear Area Cropping**: Crops to the clear rectangular area (matches overlay bright zone)\n",
        "- **Simple Output**: Basic mask and overlay generation\n",
        "- **Minimal Configuration**: Only essential parameters\n",
        "\n",
        "## **Key Simplifications from V1.3:**\n",
        "- Removed ensemble methods and multiple thresholds\n",
        "- Removed enhanced preprocessing options\n",
        "- Simplified overlay generation\n",
        "- Reduced configuration parameters\n",
        "- Cleaner, more focused code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple Configuration\n",
        "CSV_FOLDER = \"/home/pyuser/data/Paradise_CSV/\"\n",
        "CSV_LABELS_FILE = \"Labeled_Data_RAW_Sample.csv\"\n",
        "CSV_SEPARATOR = \";\"\n",
        "\n",
        "# Paths\n",
        "DOWNLOAD_PATH = '/home/pyuser/data/Paradise_Test_DICOMs'\n",
        "IMAGES_PATH = '/home/pyuser/data/Paradise_Test_Images'\n",
        "MASKS_PATH = '/home/pyuser/data/Paradise_Masks'\n",
        "\n",
        "# Processing settings\n",
        "TARGET_SIZE = (518, 518)\n",
        "LUNG_THRESHOLD = 0.1  # Single threshold for lung detection\n",
        "CROP_MARGIN = 40  # Margin around lungs for final crop\n",
        "\n",
        "# Options\n",
        "CONVERT = True\n",
        "SAVE_MASKS = True\n",
        "\n",
        "print(\"V1.4 Simplified configuration loaded!\")\n",
        "print(f\"Target size: {TARGET_SIZE}\")\n",
        "print(f\"Lung threshold: {LUNG_THRESHOLD}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core dependencies\n",
        "import ArchiMedConnector.A3_Connector as A3_Conn\n",
        "import pandas as pd\n",
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"Core dependencies loaded\")\n",
        "\n",
        "# Initialize ArchiMed connector\n",
        "a3conn = A3_Conn.A3_Connector()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple segmentation model setup\n",
        "segmentation_model = None\n",
        "model_type = None\n",
        "\n",
        "# Try TorchXRayVision first (best option)\n",
        "try:\n",
        "    import torchxrayvision as xrv\n",
        "    import torch\n",
        "    segmentation_model = xrv.baseline_models.chestx_det.PSPNet()\n",
        "    model_type = 'torchxray'\n",
        "    print(\"‚úÖ TorchXRayVision loaded\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è Installing TorchXRayVision...\")\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"torchxrayvision\"])\n",
        "        import torchxrayvision as xrv\n",
        "        import torch\n",
        "        segmentation_model = xrv.baseline_models.chestx_det.PSPNet()\n",
        "        model_type = 'torchxray'\n",
        "        print(\"‚úÖ TorchXRayVision installed and loaded\")\n",
        "    except:\n",
        "        print(\"‚ùå TorchXRayVision unavailable, using fallback\")\n",
        "        model_type = 'fallback'\n",
        "\n",
        "print(f\"Segmentation method: {model_type}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simple_lung_segmentation(image):\n",
        "    \"\"\"Simple lung segmentation using available model\"\"\"\n",
        "    \n",
        "    if model_type == 'torchxray':\n",
        "        # TorchXRayVision segmentation\n",
        "        if len(image.shape) == 3:\n",
        "            image_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "        else:\n",
        "            image_gray = image\n",
        "        \n",
        "        # Normalize and resize for model\n",
        "        image_norm = xrv.datasets.normalize(image_gray, 255)\n",
        "        image_norm = image_norm[None, ...]  \n",
        "        transform = xrv.datasets.XRayResizer(512)\n",
        "        image_resized = transform(image_norm)\n",
        "        image_tensor = torch.from_numpy(image_resized).float().unsqueeze(0)\n",
        "        \n",
        "        # Run inference\n",
        "        with torch.no_grad():\n",
        "            output = segmentation_model(image_tensor)\n",
        "        \n",
        "        # Extract lung masks\n",
        "        lung_mask = np.zeros((512, 512))\n",
        "        for i, target in enumerate(segmentation_model.targets):\n",
        "            if target in ['Left Lung', 'Right Lung']:\n",
        "                lung_mask += output[0, i].cpu().numpy()\n",
        "        \n",
        "        # Resize back and threshold\n",
        "        lung_mask = cv2.resize(lung_mask, (image.shape[1], image.shape[0]))\n",
        "        binary_mask = (lung_mask > LUNG_THRESHOLD).astype(np.uint8)\n",
        "        \n",
        "    else:\n",
        "        # Fallback segmentation\n",
        "        if len(image.shape) == 3:\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "        else:\n",
        "            gray = image.copy()\n",
        "        \n",
        "        # Simple thresholding approach\n",
        "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "        gray = clahe.apply(gray)\n",
        "        \n",
        "        _, otsu_mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        adaptive_mask = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "        \n",
        "        combined = np.maximum(otsu_mask * 0.7, adaptive_mask * 0.3)\n",
        "        binary_mask = (combined > 128).astype(np.uint8)\n",
        "    \n",
        "    # Clean up mask\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))\n",
        "    binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n",
        "    binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
        "    \n",
        "    return binary_mask\n",
        "\n",
        "def crop_to_clear_area(image, binary_mask):\n",
        "    \"\"\"Crop image to clear area (like overlay bright zone)\"\"\"\n",
        "    \n",
        "    # Get lung boundaries\n",
        "    coords = np.column_stack(np.where(binary_mask > 0))\n",
        "    if len(coords) == 0:\n",
        "        return image  # No lungs found, return original\n",
        "    \n",
        "    y_min, x_min = coords.min(axis=0)\n",
        "    y_max, x_max = coords.max(axis=0)\n",
        "    \n",
        "    # Calculate clear area boundaries (like overlay)\n",
        "    h, w = image.shape[:2]\n",
        "    lung_center_y = (y_min + y_max) // 2\n",
        "    lung_center_x = (x_min + x_max) // 2\n",
        "    \n",
        "    # Calculate crop size with target aspect ratio\n",
        "    target_aspect = TARGET_SIZE[0] / TARGET_SIZE[1]\n",
        "    lung_width = x_max - x_min + 2 * CROP_MARGIN\n",
        "    lung_height = y_max - y_min + 2 * CROP_MARGIN\n",
        "    \n",
        "    if lung_width / lung_height > target_aspect:\n",
        "        crop_width = lung_width\n",
        "        crop_height = int(crop_width / target_aspect)\n",
        "    else:\n",
        "        crop_height = lung_height\n",
        "        crop_width = int(crop_height * target_aspect)\n",
        "    \n",
        "    # Center crop on lungs\n",
        "    crop_x_min = max(0, lung_center_x - crop_width // 2)\n",
        "    crop_y_min = max(0, lung_center_y - crop_height // 2)\n",
        "    crop_x_max = min(w, crop_x_min + crop_width)\n",
        "    crop_y_max = min(h, crop_y_min + crop_height)\n",
        "    \n",
        "    # Adjust if hitting boundaries\n",
        "    if crop_x_max == w:\n",
        "        crop_x_min = w - crop_width\n",
        "    if crop_y_max == h:\n",
        "        crop_y_min = h - crop_height\n",
        "    \n",
        "    crop_x_min = max(0, crop_x_min)\n",
        "    crop_y_min = max(0, crop_y_min)\n",
        "    \n",
        "    # Crop image\n",
        "    if len(image.shape) == 3:\n",
        "        cropped = image[crop_y_min:crop_y_max, crop_x_min:crop_x_max, :]\n",
        "    else:\n",
        "        cropped = image[crop_y_min:crop_y_max, crop_x_min:crop_x_max]\n",
        "    \n",
        "    return cropped, (crop_x_min, crop_y_min, crop_x_max, crop_y_max)\n",
        "\n",
        "def save_simple_masks(image, binary_mask, crop_bounds, file_id):\n",
        "    \"\"\"Save simple mask and overlay\"\"\"\n",
        "    if not SAVE_MASKS:\n",
        "        return\n",
        "    \n",
        "    os.makedirs(MASKS_PATH, exist_ok=True)\n",
        "    \n",
        "    # Save binary mask\n",
        "    mask_path = os.path.join(MASKS_PATH, f\"{file_id}_mask.png\")\n",
        "    mask_image = (binary_mask * 255).astype(np.uint8)\n",
        "    cv2.imwrite(mask_path, mask_image)\n",
        "    \n",
        "    # Save simple overlay\n",
        "    overlay_path = os.path.join(MASKS_PATH, f\"{file_id}_overlay.png\")\n",
        "    overlay = image.copy()\n",
        "    if len(overlay.shape) == 2:\n",
        "        overlay = cv2.cvtColor(overlay, cv2.COLOR_GRAY2RGB)\n",
        "    \n",
        "    # Darken areas outside crop\n",
        "    crop_x_min, crop_y_min, crop_x_max, crop_y_max = crop_bounds\n",
        "    mask = np.ones(overlay.shape[:2], dtype=bool)\n",
        "    mask[crop_y_min:crop_y_max, crop_x_min:crop_x_max] = False\n",
        "    overlay[mask] = (overlay[mask] * 0.5).astype(np.uint8)\n",
        "    \n",
        "    # Add lung contours in red\n",
        "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cv2.drawContours(overlay, contours, -1, (0, 0, 255), 2)\n",
        "    \n",
        "    # Add crop rectangle in cyan\n",
        "    cv2.rectangle(overlay, (crop_x_min, crop_y_min), (crop_x_max, crop_y_max), (255, 255, 0), 2)\n",
        "    \n",
        "    cv2.imwrite(overlay_path, overlay)\n",
        "\n",
        "print(\"Simple processing functions loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load CSV and download files\n",
        "try:\n",
        "    user_info = a3conn.getUserInfos()\n",
        "    print(f\"ArchiMed user: {user_info}\")\n",
        "    \n",
        "    # Load CSV\n",
        "    csv_path = os.path.join(CSV_FOLDER, CSV_LABELS_FILE)\n",
        "    df = pd.read_csv(csv_path, sep=CSV_SEPARATOR)\n",
        "    print(f\"Loaded CSV with {len(df)} rows\")\n",
        "    \n",
        "    # Find FileID column\n",
        "    file_id_column = None\n",
        "    for col in ['FileID', 'file_id', 'File_ID']:\n",
        "        if col in df.columns:\n",
        "            file_id_column = col\n",
        "            break\n",
        "    \n",
        "    if file_id_column is None:\n",
        "        raise ValueError(\"FileID column not found\")\n",
        "    \n",
        "    # Get file IDs\n",
        "    file_ids = df[file_id_column].dropna().unique()\n",
        "    total_files = len(file_ids)\n",
        "    \n",
        "    print(f\"Starting download of {total_files} files\")\n",
        "    \n",
        "    # Download files\n",
        "    downloaded_files = []\n",
        "    os.makedirs(DOWNLOAD_PATH, exist_ok=True)\n",
        "    \n",
        "    for i, file_id in enumerate(file_ids):\n",
        "        progress = ((i + 1) / total_files) * 100\n",
        "        file_id_str = str(file_id)\n",
        "        print(f\"Downloading {file_id_str} ({progress:.1f}% - {i+1}/{total_files})\")\n",
        "        \n",
        "        dicom_file_path = os.path.join(DOWNLOAD_PATH, f\"{file_id}.dcm\")\n",
        "        \n",
        "        if os.path.exists(dicom_file_path):\n",
        "            print(f\"File {file_id} already exists, skipping\")\n",
        "            downloaded_files.append(dicom_file_path)\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            result = a3conn.downloadFile(\n",
        "                int(file_id_str),\n",
        "                asStream=False,\n",
        "                destDir=DOWNLOAD_PATH,\n",
        "                filename=f\"{file_id_str}.dcm\",\n",
        "                inWorklist=False\n",
        "            )\n",
        "            \n",
        "            if result and os.path.exists(dicom_file_path):\n",
        "                downloaded_files.append(dicom_file_path)\n",
        "                print(f\"‚úÖ Downloaded: {dicom_file_path}\")\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Download unclear for {file_id_str}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Failed to download {file_id_str}: {e}\")\n",
        "    \n",
        "    print(f\"Downloaded {len(downloaded_files)} files successfully\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Setup failed: {e}\")\n",
        "    downloaded_files = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert DICOM files with simplified processing\n",
        "def convert_dicom_simple(dicom_path, output_path):\n",
        "    \"\"\"Simple DICOM conversion with lung segmentation and clear area cropping\"\"\"\n",
        "    try:\n",
        "        file_id = os.path.splitext(os.path.basename(dicom_path))[0]\n",
        "        \n",
        "        # Read DICOM\n",
        "        dicom_data = pydicom.dcmread(dicom_path)\n",
        "        image_array = dicom_data.pixel_array\n",
        "        \n",
        "        # Handle photometric interpretation\n",
        "        if hasattr(dicom_data, 'PhotometricInterpretation'):\n",
        "            if dicom_data.PhotometricInterpretation == 'MONOCHROME1':\n",
        "                image_array = np.max(image_array) - image_array\n",
        "        \n",
        "        # Normalize to 0-255\n",
        "        if image_array.max() > 255:\n",
        "            image_array = ((image_array - image_array.min()) / \n",
        "                          (image_array.max() - image_array.min()) * 255).astype(np.uint8)\n",
        "        else:\n",
        "            image_array = image_array.astype(np.uint8)\n",
        "        \n",
        "        print(f\"Processing {file_id}: {image_array.shape}\")\n",
        "        \n",
        "        # Lung segmentation\n",
        "        binary_mask = simple_lung_segmentation(image_array)\n",
        "        \n",
        "        # Check if segmentation found reasonable lung area\n",
        "        lung_ratio = np.sum(binary_mask) / binary_mask.size\n",
        "        if lung_ratio < 0.01 or lung_ratio > 0.8:\n",
        "            print(f\"‚ö†Ô∏è Unusual lung ratio {lung_ratio:.3f}, using original image\")\n",
        "            processed_image = image_array\n",
        "            crop_bounds = (0, 0, image_array.shape[1], image_array.shape[0])\n",
        "        else:\n",
        "            # Crop to clear area\n",
        "            processed_image, crop_bounds = crop_to_clear_area(image_array, binary_mask)\n",
        "            print(f\"‚úÖ Cropped to clear area: {processed_image.shape}\")\n",
        "        \n",
        "        # Save masks\n",
        "        save_simple_masks(image_array, binary_mask, crop_bounds, file_id)\n",
        "        \n",
        "        # Convert to PIL and resize\n",
        "        if len(processed_image.shape) == 2:\n",
        "            pil_image = Image.fromarray(processed_image, mode='L')\n",
        "        else:\n",
        "            pil_image = Image.fromarray(processed_image)\n",
        "        \n",
        "        # Maintain aspect ratio by cropping then resizing\n",
        "        current_width, current_height = pil_image.size\n",
        "        target_width, target_height = TARGET_SIZE\n",
        "        \n",
        "        current_ratio = current_width / current_height\n",
        "        target_ratio = target_width / target_height\n",
        "        \n",
        "        if current_ratio > target_ratio:\n",
        "            # Crop width\n",
        "            new_width = int(current_height * target_ratio)\n",
        "            left = (current_width - new_width) // 2\n",
        "            pil_image = pil_image.crop((left, 0, left + new_width, current_height))\n",
        "        else:\n",
        "            # Crop height\n",
        "            new_height = int(current_width / target_ratio)\n",
        "            top = (current_height - new_height) // 2\n",
        "            pil_image = pil_image.crop((0, top, current_width, top + new_height))\n",
        "        \n",
        "        # Final resize\n",
        "        pil_image = pil_image.resize(TARGET_SIZE, Image.Resampling.LANCZOS)\n",
        "        \n",
        "        # Save\n",
        "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "        pil_image.save(output_path)\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to convert {dicom_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Convert all downloaded files\n",
        "if CONVERT and downloaded_files:\n",
        "    print(f\"Converting {len(downloaded_files)} DICOM files\")\n",
        "    \n",
        "    os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "    converted_count = 0\n",
        "    \n",
        "    for dicom_path in tqdm(downloaded_files, desc=\"Converting\"):\n",
        "        file_id = os.path.splitext(os.path.basename(dicom_path))[0]\n",
        "        output_path = os.path.join(IMAGES_PATH, f\"{file_id}.png\")\n",
        "        \n",
        "        if convert_dicom_simple(dicom_path, output_path):\n",
        "            converted_count += 1\n",
        "    \n",
        "    print(f\"‚úÖ Successfully converted {converted_count}/{len(downloaded_files)} files\")\n",
        "    print(f\"Images saved to: {IMAGES_PATH}\")\n",
        "    if SAVE_MASKS:\n",
        "        print(f\"Masks saved to: {MASKS_PATH}\")\n",
        "    print(\"üéâ V1.4 Simplified processing complete!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No files to convert or conversion disabled\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
