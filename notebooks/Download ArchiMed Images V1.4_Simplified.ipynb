{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "**<h1 align=\"center\">Download ArchiMed Images V1.4 - SIMPLIFIED</h1>**\n",
        "\n",
        "## **V1.4: Simplified Lung Segmentation & Cropping**\n",
        "- **Single Model**: Uses best available segmentation model (TorchXRayVision preferred)\n",
        "- **Clear Area Cropping**: Crops to the clear rectangular area (matches overlay bright zone)\n",
        "- **V1.3 Style Overlay**: Cyan rectangle, green corner brackets, red lung filling\n",
        "- **Minimal Configuration**: Only essential parameters\n",
        "\n",
        "## **Key Simplifications from V1.3:**\n",
        "- Removed ensemble methods and multiple thresholds\n",
        "- Removed enhanced preprocessing options\n",
        "- Reduced configuration parameters\n",
        "- Cleaner, more focused code\n",
        "- **Kept V1.3 overlay visualization style**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple Configuration\n",
        "CSV_FOLDER = \"/home/pyuser/data/Paradise_CSV/\"\n",
        "CSV_LABELS_FILE = \"Labeled_Data_RAW_Sample.csv\"\n",
        "CSV_SEPARATOR = \";\"\n",
        "\n",
        "# Paths\n",
        "DOWNLOAD_PATH = '/home/pyuser/data/Paradise_Test_DICOMs'\n",
        "IMAGES_PATH = '/home/pyuser/data/Paradise_Test_Images'\n",
        "MASKS_PATH = '/home/pyuser/data/Paradise_Masks'\n",
        "\n",
        "# Processing settings\n",
        "TARGET_SIZE = (518, 518)\n",
        "LUNG_THRESHOLD = 0.1  # Single threshold for lung detection\n",
        "CROP_MARGIN = 40  # Margin around lungs for final crop\n",
        "\n",
        "# V1.3 Style Overlay Settings\n",
        "LUNG_FILL_OPACITY = 0.25  # Lung fill opacity (like V1.3)\n",
        "LUNG_BORDER_OPACITY = 0.50  # Lung border opacity (like V1.3)\n",
        "\n",
        "# Options\n",
        "CONVERT = True\n",
        "SAVE_MASKS = True\n",
        "\n",
        "print(\"V1.4 Simplified configuration loaded!\")\n",
        "print(f\"Target size: {TARGET_SIZE}\")\n",
        "print(f\"Lung threshold: {LUNG_THRESHOLD}\")\n",
        "print(\"V1.3 style overlay enabled\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core dependencies\n",
        "import ArchiMedConnector.A3_Connector as A3_Conn\n",
        "import pandas as pd\n",
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"Core dependencies loaded\")\n",
        "\n",
        "# Initialize ArchiMed connector\n",
        "a3conn = A3_Conn.A3_Connector()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple segmentation model setup\n",
        "segmentation_model = None\n",
        "model_type = None\n",
        "\n",
        "# Try TorchXRayVision first (best option)\n",
        "try:\n",
        "    import torchxrayvision as xrv\n",
        "    import torch\n",
        "    segmentation_model = xrv.baseline_models.chestx_det.PSPNet()\n",
        "    model_type = 'torchxray'\n",
        "    print(\"‚úÖ TorchXRayVision loaded\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è Installing TorchXRayVision...\")\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"torchxrayvision\"])\n",
        "        import torchxrayvision as xrv\n",
        "        import torch\n",
        "        segmentation_model = xrv.baseline_models.chestx_det.PSPNet()\n",
        "        model_type = 'torchxray'\n",
        "        print(\"‚úÖ TorchXRayVision installed and loaded\")\n",
        "    except:\n",
        "        print(\"‚ùå TorchXRayVision unavailable, using fallback\")\n",
        "        model_type = 'fallback'\n",
        "\n",
        "print(f\"Segmentation method: {model_type}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def segment_lungs(image):\n",
        "    \"\"\"Simple lung segmentation\"\"\"\n",
        "    if model_type == 'torchxray' and segmentation_model is not None:\n",
        "        return segment_with_torchxray(image)\n",
        "    else:\n",
        "        return segment_with_fallback(image)\n",
        "\n",
        "def segment_with_torchxray(image):\n",
        "    \"\"\"Segment using TorchXRayVision\"\"\"\n",
        "    try:\n",
        "        # Convert to grayscale if needed\n",
        "        if len(image.shape) == 3:\n",
        "            image_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "        else:\n",
        "            image_gray = image\n",
        "        \n",
        "        # Normalize for TorchXRayVision\n",
        "        image_norm = xrv.datasets.normalize(image_gray, 255)\n",
        "        image_norm = image_norm[None, ...]\n",
        "        \n",
        "        # Resize to 512x512\n",
        "        transform = xrv.datasets.XRayResizer(512)\n",
        "        image_resized = transform(image_norm)\n",
        "        \n",
        "        # Convert to tensor\n",
        "        image_tensor = torch.from_numpy(image_resized).float().unsqueeze(0)\n",
        "        \n",
        "        # Run inference\n",
        "        with torch.no_grad():\n",
        "            output = segmentation_model(image_tensor)\n",
        "        \n",
        "        # Extract lung masks\n",
        "        lung_targets = ['Left Lung', 'Right Lung']\n",
        "        lung_mask = np.zeros((512, 512))\n",
        "        \n",
        "        for i, target in enumerate(segmentation_model.targets):\n",
        "            if target in lung_targets:\n",
        "                lung_mask += output[0, i].cpu().numpy()\n",
        "        \n",
        "        # Resize back to original size\n",
        "        lung_mask = cv2.resize(lung_mask, (image.shape[1], image.shape[0]))\n",
        "        \n",
        "        # Create binary mask\n",
        "        binary_mask = (lung_mask > LUNG_THRESHOLD).astype(np.uint8)\n",
        "        \n",
        "        # Clean up mask\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))\n",
        "        binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n",
        "        binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
        "        \n",
        "        return binary_mask\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"TorchXRayVision segmentation failed: {e}\")\n",
        "        return segment_with_fallback(image)\n",
        "\n",
        "def segment_with_fallback(image):\n",
        "    \"\"\"Fallback segmentation method\"\"\"\n",
        "    if len(image.shape) == 3:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    else:\n",
        "        gray = image.copy()\n",
        "    \n",
        "    # Apply CLAHE\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    gray = clahe.apply(gray)\n",
        "    \n",
        "    # Otsu thresholding\n",
        "    _, otsu_mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    \n",
        "    # Morphological cleanup\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (20, 20))\n",
        "    mask_clean = cv2.morphologyEx(otsu_mask, cv2.MORPH_CLOSE, kernel)\n",
        "    mask_clean = cv2.morphologyEx(mask_clean, cv2.MORPH_OPEN, kernel)\n",
        "    \n",
        "    return (mask_clean > 0).astype(np.uint8)\n",
        "\n",
        "print(\"Lung segmentation functions loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_v13_overlay(image, binary_mask, resize_crop_bounds):\n",
        "    \"\"\"Create V1.3 style overlay with cyan rectangle, green corners, and red lung filling\"\"\"\n",
        "    overlay = image.copy()\n",
        "    if len(overlay.shape) == 2:\n",
        "        overlay = cv2.cvtColor(overlay, cv2.COLOR_GRAY2RGB)\n",
        "    \n",
        "    resize_y_min, resize_x_min, resize_y_max, resize_x_max = resize_crop_bounds\n",
        "    img_height, img_width = overlay.shape[:2]\n",
        "    \n",
        "    # 1. Darken areas OUTSIDE the resize crop (like V1.3)\n",
        "    outside_resize_mask = np.ones((img_height, img_width), dtype=bool)\n",
        "    outside_resize_mask[resize_y_min:resize_y_max, resize_x_min:resize_x_max] = False\n",
        "    overlay[outside_resize_mask] = (overlay[outside_resize_mask] * 0.5).astype(np.uint8)\n",
        "    \n",
        "    # 2. Red lung visualization with dual opacity (exactly like V1.3)\n",
        "    lung_areas = binary_mask > 0\n",
        "    \n",
        "    if np.any(lung_areas):\n",
        "        print(f\"üìç Debug: Found {np.sum(lung_areas)} lung pixels\")\n",
        "        \n",
        "        # Step 1: Apply DARK RED FILL with 25% opacity (LUNG_FILL_OPACITY)\n",
        "        lung_fill_colored = np.zeros_like(overlay)\n",
        "        lung_fill_colored[lung_areas] = [0, 0, 180]  # Dark Red in BGR\n",
        "        \n",
        "        overlay[lung_areas] = cv2.addWeighted(\n",
        "            overlay[lung_areas], 1.0 - LUNG_FILL_OPACITY, \n",
        "            lung_fill_colored[lung_areas], LUNG_FILL_OPACITY, 0\n",
        "        )\n",
        "        print(f\"üìç Debug: Applied red fill with {LUNG_FILL_OPACITY} opacity\")\n",
        "        \n",
        "        # Step 2: Apply DARK RED BORDER with 50% opacity (LUNG_BORDER_OPACITY)\n",
        "        lung_mask_uint8 = (binary_mask * 255).astype(np.uint8)\n",
        "        contours, _ = cv2.findContours(lung_mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        \n",
        "        border_mask = np.zeros_like(binary_mask, dtype=np.uint8)\n",
        "        cv2.drawContours(border_mask, contours, -1, 1, thickness=4)  # 4px thick border\n",
        "        \n",
        "        border_areas = border_mask > 0\n",
        "        if np.any(border_areas):\n",
        "            lung_border_colored = np.zeros_like(overlay)\n",
        "            lung_border_colored[border_areas] = [0, 0, 180]  # Dark Red in BGR\n",
        "            \n",
        "            overlay[border_areas] = cv2.addWeighted(\n",
        "                overlay[border_areas], 1.0 - LUNG_BORDER_OPACITY, \n",
        "                lung_border_colored[border_areas], LUNG_BORDER_OPACITY, 0\n",
        "            )\n",
        "            print(f\"üìç Debug: Applied red border with {LUNG_BORDER_OPACITY} opacity\")\n",
        "        else:\n",
        "            print(\"üìç Debug: No border areas found\")\n",
        "    else:\n",
        "        print(\"üìç Debug: No lung areas found\")\n",
        "    \n",
        "    # 3. Green corner brackets for exact segmentation boundaries (exactly like V1.3)\n",
        "    def draw_corner_brackets(img, x1, y1, x2, y2, color, thickness=3, length=40):\n",
        "        \"\"\"Draw corner brackets at the corners of a rectangle (exactly like V1.3)\"\"\"\n",
        "        # Top-left corner\n",
        "        cv2.line(img, (x1, y1), (x1 + length, y1), color, thickness)  # Horizontal\n",
        "        cv2.line(img, (x1, y1), (x1, y1 + length), color, thickness)  # Vertical\n",
        "        \n",
        "        # Top-right corner\n",
        "        cv2.line(img, (x2 - length, y1), (x2, y1), color, thickness)  # Horizontal\n",
        "        cv2.line(img, (x2, y1), (x2, y1 + length), color, thickness)  # Vertical\n",
        "        \n",
        "        # Bottom-left corner\n",
        "        cv2.line(img, (x1, y2 - length), (x1, y2), color, thickness)  # Vertical\n",
        "        cv2.line(img, (x1, y2), (x1 + length, y2), color, thickness)  # Horizontal\n",
        "        \n",
        "        # Bottom-right corner\n",
        "        cv2.line(img, (x2, y2 - length), (x2, y2), color, thickness)  # Vertical\n",
        "        cv2.line(img, (x2 - length, y2), (x2, y2), color, thickness)  # Horizontal\n",
        "    \n",
        "    # Find actual segmentation boundaries (without padding) for green corners (exactly like V1.3)\n",
        "    lung_coords = np.where(binary_mask > 0)\n",
        "    if len(lung_coords[0]) > 0:\n",
        "        actual_y_min = np.min(lung_coords[0])  # Top edge of lungs\n",
        "        actual_y_max = np.max(lung_coords[0])  # Bottom edge of lungs  \n",
        "        actual_x_min = np.min(lung_coords[1])  # Left edge of lungs\n",
        "        actual_x_max = np.max(lung_coords[1])  # Right edge of lungs\n",
        "        \n",
        "        print(f\"üìç Debug: Segmentation boundaries: ({actual_x_min},{actual_y_min}) to ({actual_x_max},{actual_y_max})\")\n",
        "        \n",
        "        # Draw GREEN corner brackets at EXACT segmentation boundaries (no padding) - exactly like V1.3\n",
        "        draw_corner_brackets(overlay, actual_x_min, actual_y_min, actual_x_max, actual_y_max, (0, 255, 0), 3, 40)\n",
        "        print(\"üìç Debug: Drew green corner brackets with length=40\")\n",
        "    else:\n",
        "        print(\"üìç Debug: No lung areas found for corner brackets\")\n",
        "    \n",
        "    # 4. Draw CYAN resize crop rectangle (contains everything) - 1px contour line (exactly like V1.3)\n",
        "    cv2.rectangle(overlay, (resize_x_min, resize_y_min), (resize_x_max, resize_y_max), (255, 255, 0), 1)\n",
        "    print(f\"üìç Debug: Drew cyan rectangle: ({resize_x_min},{resize_y_min}) to ({resize_x_max},{resize_y_max})\")\n",
        "    \n",
        "    # 5. V1.3 style legend with BLACK BACKGROUND\n",
        "    legend_height = 120\n",
        "    legend_width = min(700, img_width - 20)  # Ensure legend fits within image bounds\n",
        "    legend_y_start = img_height - legend_height - 10\n",
        "    \n",
        "    # Create black background with 75% opacity (exactly like V1.3)\n",
        "    legend_background = np.zeros((legend_height, legend_width, 3), dtype=np.uint8)\n",
        "    legend_area = overlay[legend_y_start:legend_y_start + legend_height, 10:10 + legend_width]\n",
        "    \n",
        "    # Blend background with 75% opacity (25% transparency) - exactly like V1.3\n",
        "    overlay[legend_y_start:legend_y_start + legend_height, 10:10 + legend_width] = cv2.addWeighted(\n",
        "        legend_area, 0.25, legend_background, 0.75, 0\n",
        "    )\n",
        "    \n",
        "    # Legend text with larger font (exactly like V1.3)\n",
        "    text_y = legend_y_start + 25\n",
        "    font_scale = 0.7  # Larger font\n",
        "    font_thickness = 2\n",
        "    \n",
        "    cv2.putText(overlay, f\"DARK RED = Lung segmentation (Fill: {int(LUNG_FILL_OPACITY*100)}%, Border: {int(LUNG_BORDER_OPACITY*100)}%)\", \n",
        "               (20, text_y), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 180), font_thickness)\n",
        "    \n",
        "    cv2.putText(overlay, \"GREEN = Segmentation corner brackets\", \n",
        "               (20, text_y + 30), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 0), font_thickness)\n",
        "    \n",
        "    cv2.putText(overlay, f\"CYAN = Final resize crop {TARGET_SIZE[0]}x{TARGET_SIZE[1]}\", \n",
        "               (20, text_y + 60), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 0), font_thickness)\n",
        "    \n",
        "    # Add feature information at bottom with smaller font (like V1.3)\n",
        "    cv2.putText(overlay, f\"Threshold: {LUNG_THRESHOLD} | Model: {model_type}\", \n",
        "               (20, text_y + 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
        "    \n",
        "    return overlay\n",
        "\n",
        "def process_image_with_segmentation(image_array, file_id):\n",
        "    \"\"\"Process image with lung segmentation and clear area cropping\"\"\"\n",
        "    try:\n",
        "        print(f\"ü´Å Segmenting lungs for {file_id}...\")\n",
        "        \n",
        "        # Get lung segmentation\n",
        "        binary_mask = segment_lungs(image_array)\n",
        "        \n",
        "        # Validate segmentation\n",
        "        total_pixels = binary_mask.shape[0] * binary_mask.shape[1]\n",
        "        lung_pixels = np.sum(binary_mask)\n",
        "        lung_ratio = lung_pixels / total_pixels\n",
        "        \n",
        "        print(f\"üìä Lung area: {lung_ratio:.3f} of image\")\n",
        "        \n",
        "        # Quality check\n",
        "        if lung_ratio < 0.005 or lung_ratio > 0.95:\n",
        "            print(f\"‚ö†Ô∏è Lung area outside valid range, using original\")\n",
        "            return image_array\n",
        "        \n",
        "        # Find lung boundaries\n",
        "        coords = np.column_stack(np.where(binary_mask > 0))\n",
        "        if len(coords) == 0:\n",
        "            return image_array\n",
        "        \n",
        "        y_min, x_min = coords.min(axis=0)\n",
        "        y_max, x_max = coords.max(axis=0)\n",
        "        \n",
        "        # Calculate resize crop (clear area) - exactly like V1.3\n",
        "        img_height, img_width = image_array.shape[:2]\n",
        "        \n",
        "        # Add padding around lung boundaries (like V1.3)\n",
        "        safety_margin = 20\n",
        "        y_min_padded = max(0, y_min - safety_margin)\n",
        "        x_min_padded = max(0, x_min - safety_margin)\n",
        "        y_max_padded = min(img_height, y_max + safety_margin)\n",
        "        x_max_padded = min(img_width, x_max + safety_margin)\n",
        "        \n",
        "        # Find lung center for positioning the resize crop (like V1.3)\n",
        "        lung_center_y = (y_min_padded + y_max_padded) // 2\n",
        "        lung_center_x = (x_min_padded + x_max_padded) // 2\n",
        "        \n",
        "        # Calculate resize crop dimensions based on TARGET_SIZE (like V1.3)\n",
        "        target_aspect_ratio = TARGET_SIZE[0] / TARGET_SIZE[1]  # width/height\n",
        "        \n",
        "        # Make resize crop large enough to contain the lung area, but respect aspect ratio\n",
        "        lung_width = x_max_padded - x_min_padded\n",
        "        lung_height = y_max_padded - y_min_padded\n",
        "        \n",
        "        # Calculate minimum size needed to contain lungs, then expand if needed (like V1.3)\n",
        "        min_width = lung_width + 40  # Extra margin (like V1.3)\n",
        "        min_height = lung_height + 40\n",
        "        \n",
        "        # Ensure aspect ratio is maintained (like V1.3)\n",
        "        if min_width / min_height > target_aspect_ratio:\n",
        "            # Width is limiting factor\n",
        "            resize_width = min_width\n",
        "            resize_height = int(resize_width / target_aspect_ratio)\n",
        "        else:\n",
        "            # Height is limiting factor  \n",
        "            resize_height = min_height\n",
        "            resize_width = int(resize_height * target_aspect_ratio)\n",
        "        \n",
        "        # Center resize crop on lung center, but keep within image bounds (like V1.3)\n",
        "        resize_x_min = max(0, lung_center_x - resize_width // 2)\n",
        "        resize_y_min = max(0, lung_center_y - resize_height // 2)\n",
        "        resize_x_max = min(img_width, resize_x_min + resize_width)\n",
        "        resize_y_max = min(img_height, resize_y_min + resize_height)\n",
        "        \n",
        "        # Adjust if we hit image boundaries (like V1.3)\n",
        "        if resize_x_max == img_width:\n",
        "            resize_x_min = img_width - resize_width\n",
        "        if resize_y_max == img_height:\n",
        "            resize_y_min = img_height - resize_height\n",
        "            \n",
        "        # Ensure non-negative coordinates (like V1.3)\n",
        "        resize_x_min = max(0, resize_x_min)\n",
        "        resize_y_min = max(0, resize_y_min)\n",
        "        \n",
        "        print(f\"üìê Clear area crop: ({resize_y_min},{resize_x_min}) to ({resize_y_max},{resize_x_max})\")\n",
        "        \n",
        "        # Crop to clear area\n",
        "        if len(image_array.shape) == 3:\n",
        "            cropped = image_array[resize_y_min:resize_y_max, resize_x_min:resize_x_max, :]\n",
        "        else:\n",
        "            cropped = image_array[resize_y_min:resize_y_max, resize_x_min:resize_x_max]\n",
        "        \n",
        "        # Save masks if requested\n",
        "        if SAVE_MASKS:\n",
        "            os.makedirs(MASKS_PATH, exist_ok=True)\n",
        "            \n",
        "            # Save binary mask\n",
        "            mask_path = os.path.join(MASKS_PATH, f\"{file_id}_mask.png\")\n",
        "            mask_image = (binary_mask * 255).astype(np.uint8)\n",
        "            cv2.imwrite(mask_path, mask_image)\n",
        "            \n",
        "            # Save V1.3 style overlay\n",
        "            overlay_path = os.path.join(MASKS_PATH, f\"{file_id}_overlay.png\")\n",
        "            resize_bounds = (resize_y_min, resize_x_min, resize_y_max, resize_x_max)\n",
        "            overlay = create_v13_overlay(image_array, binary_mask, resize_bounds)\n",
        "            cv2.imwrite(overlay_path, overlay)\n",
        "            \n",
        "            print(f\"üíæ Saved V1.3 style masks: {file_id}_mask.png, {file_id}_overlay.png\")\n",
        "        \n",
        "        return cropped\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Processing failed for {file_id}: {e}\")\n",
        "        return image_array\n",
        "\n",
        "print(\"Image processing with V1.3 overlay loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download images from ArchiMed\n",
        "try:\n",
        "    # Load CSV data\n",
        "    user_info = a3conn.getUserInfos()\n",
        "    print(f\"üîê ArchiMed connection: {user_info}\")\n",
        "    \n",
        "    csv_path = os.path.join(CSV_FOLDER, CSV_LABELS_FILE)\n",
        "    df = pd.read_csv(csv_path, sep=CSV_SEPARATOR)\n",
        "    print(f\"‚úÖ Loaded CSV with {len(df)} rows\")\n",
        "    \n",
        "    # Find FileID column\n",
        "    file_id_column = None\n",
        "    for col in ['FileID', 'file_id', 'File_ID']:\n",
        "        if col in df.columns:\n",
        "            file_id_column = col\n",
        "            break\n",
        "    \n",
        "    if file_id_column is None:\n",
        "        raise ValueError(\"FileID column not found\")\n",
        "    \n",
        "    # Get file IDs\n",
        "    file_ids = df[file_id_column].dropna().unique()\n",
        "    total_files = len(file_ids)\n",
        "    \n",
        "    print(f\"üöÄ Starting download of {total_files} files\")\n",
        "    print(f\"Destination: {DOWNLOAD_PATH}\")\n",
        "    \n",
        "    # Download files\n",
        "    downloaded_files = []\n",
        "    \n",
        "    for i, file_id in enumerate(file_ids):\n",
        "        progress = ((i + 1) / total_files) * 100\n",
        "        file_id_str = str(file_id)\n",
        "        print(f\"‚¨áÔ∏è Downloading {file_id_str} ({progress:.1f}% - {i+1}/{total_files})\")\n",
        "        \n",
        "        try:\n",
        "            dicom_file_path = os.path.join(DOWNLOAD_PATH, f\"{file_id}.dcm\")\n",
        "            os.makedirs(DOWNLOAD_PATH, exist_ok=True)\n",
        "            \n",
        "            if os.path.exists(dicom_file_path):\n",
        "                print(f\"File {file_id} already exists, skipping\")\n",
        "                downloaded_files.append(dicom_file_path)\n",
        "                continue\n",
        "            \n",
        "            # Download file\n",
        "            result = a3conn.downloadFile(\n",
        "                int(file_id_str),\n",
        "                asStream=False,\n",
        "                destDir=DOWNLOAD_PATH,\n",
        "                filename=f\"{file_id_str}.dcm\",\n",
        "                inWorklist=False\n",
        "            )\n",
        "            \n",
        "            if result and os.path.exists(dicom_file_path):\n",
        "                downloaded_files.append(dicom_file_path)\n",
        "                print(f\"‚úÖ Downloaded: {dicom_file_path}\")\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Download unclear for {file_id_str}\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Failed to download {file_id_str}: {e}\")\n",
        "    \n",
        "    print(f\"‚úÖ Downloaded {len(downloaded_files)} files successfully\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Download failed: {e}\")\n",
        "    downloaded_files = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert DICOM files to images with segmentation\n",
        "def convert_dicom_to_image(dicom_path, output_path, target_size=TARGET_SIZE):\n",
        "    \"\"\"Convert DICOM to image with lung segmentation and cropping\"\"\"\n",
        "    try:\n",
        "        file_id = os.path.splitext(os.path.basename(dicom_path))[0]\n",
        "        \n",
        "        # Read DICOM\n",
        "        dicom_data = pydicom.dcmread(dicom_path)\n",
        "        image_array = dicom_data.pixel_array\n",
        "        print(f\"üìÅ Processing {file_id}: {image_array.shape}\")\n",
        "        \n",
        "        # Handle MONOCHROME1\n",
        "        if hasattr(dicom_data, 'PhotometricInterpretation'):\n",
        "            if dicom_data.PhotometricInterpretation == 'MONOCHROME1':\n",
        "                image_array = np.max(image_array) - image_array\n",
        "        \n",
        "        # Normalize to 0-255\n",
        "        if image_array.max() > 255:\n",
        "            image_array = ((image_array - image_array.min()) / \n",
        "                          (image_array.max() - image_array.min()) * 255).astype(np.uint8)\n",
        "        else:\n",
        "            image_array = image_array.astype(np.uint8)\n",
        "        \n",
        "        # Apply lung segmentation and cropping\n",
        "        processed_image = process_image_with_segmentation(image_array, file_id)\n",
        "        \n",
        "        # Convert to PIL\n",
        "        if len(processed_image.shape) == 2:\n",
        "            pil_image = Image.fromarray(processed_image, mode='L')\n",
        "        else:\n",
        "            pil_image = Image.fromarray(processed_image)\n",
        "        \n",
        "        # Resize to target size with aspect ratio preservation\n",
        "        current_width, current_height = pil_image.size\n",
        "        target_width, target_height = target_size\n",
        "        \n",
        "        current_ratio = current_width / current_height\n",
        "        target_ratio = target_width / target_height\n",
        "        \n",
        "        print(f\"üìê Current: {current_width}x{current_height} (ratio: {current_ratio:.3f})\")\n",
        "        print(f\"üìê Target: {target_width}x{target_height} (ratio: {target_ratio:.3f})\")\n",
        "        \n",
        "        # Center crop to match aspect ratio\n",
        "        if current_ratio > target_ratio:\n",
        "            # Crop width\n",
        "            new_width = int(current_height * target_ratio)\n",
        "            new_height = current_height\n",
        "            left = (current_width - new_width) // 2\n",
        "            top = 0\n",
        "            right = left + new_width\n",
        "            bottom = current_height\n",
        "            print(f\"üìè Cropping width: {current_width} ‚Üí {new_width}\")\n",
        "        else:\n",
        "            # Crop height\n",
        "            new_width = current_width\n",
        "            new_height = int(current_width / target_ratio)\n",
        "            left = 0\n",
        "            top = (current_height - new_height) // 2\n",
        "            right = current_width\n",
        "            bottom = top + new_height\n",
        "            print(f\"üìè Cropping height: {current_height} ‚Üí {new_height}\")\n",
        "        \n",
        "        # Apply crop and resize\n",
        "        pil_image = pil_image.crop((left, top, right, bottom))\n",
        "        pil_image = pil_image.resize(target_size, Image.Resampling.LANCZOS)\n",
        "        print(f\"‚úÖ Final size: {target_width}x{target_height}\")\n",
        "        \n",
        "        # Save image\n",
        "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "        pil_image.save(output_path)\n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to convert {dicom_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Convert downloaded files\n",
        "if CONVERT and downloaded_files:\n",
        "    print(f\"üîÑ Converting {len(downloaded_files)} DICOM files\")\n",
        "    os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "    \n",
        "    converted_count = 0\n",
        "    \n",
        "    for dicom_path in tqdm(downloaded_files, desc=\"Converting\"):\n",
        "        file_id = os.path.splitext(os.path.basename(dicom_path))[0]\n",
        "        output_path = os.path.join(IMAGES_PATH, f\"{file_id}.png\")\n",
        "        \n",
        "        if convert_dicom_to_image(dicom_path, output_path):\n",
        "            converted_count += 1\n",
        "    \n",
        "    print(f\"‚úÖ Converted {converted_count}/{len(downloaded_files)} files\")\n",
        "    print(f\"üìÇ Images: {IMAGES_PATH}\")\n",
        "    \n",
        "    if SAVE_MASKS:\n",
        "        print(f\"üéØ V1.3 style overlays: {MASKS_PATH}\")\n",
        "    \n",
        "    print(\"üéâ V1.4 Simplified processing complete!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No files to convert or conversion disabled\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "**<h1 align=\"center\">Download ArchiMed Images V1.4 - SIMPLIFIED</h1>**\n",
        "\n",
        "## **V1.4: Simplified Lung Segmentation & Cropping**\n",
        "- **Single Model**: Uses best available segmentation model (TorchXRayVision preferred)\n",
        "- **Clear Area Cropping**: Crops to the clear rectangular area (matches overlay bright zone)\n",
        "- **Simple Output**: Basic mask and overlay generation\n",
        "- **Minimal Configuration**: Only essential parameters\n",
        "\n",
        "## **Key Simplifications from V1.3:**\n",
        "- Removed ensemble methods and multiple thresholds\n",
        "- Removed enhanced preprocessing options\n",
        "- Simplified overlay generation\n",
        "- Reduced configuration parameters\n",
        "- Cleaner, more focused code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple Configuration\n",
        "CSV_FOLDER = \"/home/pyuser/data/Paradise_CSV/\"\n",
        "CSV_LABELS_FILE = \"Labeled_Data_RAW_Sample.csv\"\n",
        "CSV_SEPARATOR = \";\"\n",
        "\n",
        "# Paths\n",
        "DOWNLOAD_PATH = '/home/pyuser/data/Paradise_Test_DICOMs'\n",
        "IMAGES_PATH = '/home/pyuser/data/Paradise_Test_Images'\n",
        "MASKS_PATH = '/home/pyuser/data/Paradise_Masks'\n",
        "\n",
        "# Processing settings\n",
        "TARGET_SIZE = (518, 518)\n",
        "LUNG_THRESHOLD = 0.1  # Single threshold for lung detection\n",
        "CROP_MARGIN = 40  # Margin around lungs for final crop\n",
        "\n",
        "# Options\n",
        "CONVERT = True\n",
        "SAVE_MASKS = True\n",
        "\n",
        "print(\"V1.4 Simplified configuration loaded!\")\n",
        "print(f\"Target size: {TARGET_SIZE}\")\n",
        "print(f\"Lung threshold: {LUNG_THRESHOLD}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core dependencies\n",
        "import ArchiMedConnector.A3_Connector as A3_Conn\n",
        "import pandas as pd\n",
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"Core dependencies loaded\")\n",
        "\n",
        "# Initialize ArchiMed connector\n",
        "a3conn = A3_Conn.A3_Connector()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple segmentation model setup\n",
        "segmentation_model = None\n",
        "model_type = None\n",
        "\n",
        "# Try TorchXRayVision first (best option)\n",
        "try:\n",
        "    import torchxrayvision as xrv\n",
        "    import torch\n",
        "    segmentation_model = xrv.baseline_models.chestx_det.PSPNet()\n",
        "    model_type = 'torchxray'\n",
        "    print(\"‚úÖ TorchXRayVision loaded\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è Installing TorchXRayVision...\")\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"torchxrayvision\"])\n",
        "        import torchxrayvision as xrv\n",
        "        import torch\n",
        "        segmentation_model = xrv.baseline_models.chestx_det.PSPNet()\n",
        "        model_type = 'torchxray'\n",
        "        print(\"‚úÖ TorchXRayVision installed and loaded\")\n",
        "    except:\n",
        "        print(\"‚ùå TorchXRayVision unavailable, using fallback\")\n",
        "        model_type = 'fallback'\n",
        "\n",
        "print(f\"Segmentation method: {model_type}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simple_lung_segmentation(image):\n",
        "    \"\"\"Simple lung segmentation using available model\"\"\"\n",
        "    \n",
        "    if model_type == 'torchxray':\n",
        "        # TorchXRayVision segmentation\n",
        "        if len(image.shape) == 3:\n",
        "            image_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "        else:\n",
        "            image_gray = image\n",
        "        \n",
        "        # Normalize and resize for model\n",
        "        image_norm = xrv.datasets.normalize(image_gray, 255)\n",
        "        image_norm = image_norm[None, ...]  \n",
        "        transform = xrv.datasets.XRayResizer(512)\n",
        "        image_resized = transform(image_norm)\n",
        "        image_tensor = torch.from_numpy(image_resized).float().unsqueeze(0)\n",
        "        \n",
        "        # Run inference\n",
        "        with torch.no_grad():\n",
        "            output = segmentation_model(image_tensor)\n",
        "        \n",
        "        # Extract lung masks\n",
        "        lung_mask = np.zeros((512, 512))\n",
        "        for i, target in enumerate(segmentation_model.targets):\n",
        "            if target in ['Left Lung', 'Right Lung']:\n",
        "                lung_mask += output[0, i].cpu().numpy()\n",
        "        \n",
        "        # Resize back and threshold\n",
        "        lung_mask = cv2.resize(lung_mask, (image.shape[1], image.shape[0]))\n",
        "        binary_mask = (lung_mask > LUNG_THRESHOLD).astype(np.uint8)\n",
        "        \n",
        "    else:\n",
        "        # Fallback segmentation\n",
        "        if len(image.shape) == 3:\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "        else:\n",
        "            gray = image.copy()\n",
        "        \n",
        "        # Simple thresholding approach\n",
        "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "        gray = clahe.apply(gray)\n",
        "        \n",
        "        _, otsu_mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        adaptive_mask = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "        \n",
        "        combined = np.maximum(otsu_mask * 0.7, adaptive_mask * 0.3)\n",
        "        binary_mask = (combined > 128).astype(np.uint8)\n",
        "    \n",
        "    # Clean up mask\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))\n",
        "    binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n",
        "    binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel)\n",
        "    \n",
        "    return binary_mask\n",
        "\n",
        "def crop_to_clear_area(image, binary_mask):\n",
        "    \"\"\"Crop image to clear area (like overlay bright zone)\"\"\"\n",
        "    \n",
        "    # Get lung boundaries\n",
        "    coords = np.column_stack(np.where(binary_mask > 0))\n",
        "    if len(coords) == 0:\n",
        "        return image  # No lungs found, return original\n",
        "    \n",
        "    y_min, x_min = coords.min(axis=0)\n",
        "    y_max, x_max = coords.max(axis=0)\n",
        "    \n",
        "    # Calculate clear area boundaries (like overlay)\n",
        "    h, w = image.shape[:2]\n",
        "    lung_center_y = (y_min + y_max) // 2\n",
        "    lung_center_x = (x_min + x_max) // 2\n",
        "    \n",
        "    # Calculate crop size with target aspect ratio\n",
        "    target_aspect = TARGET_SIZE[0] / TARGET_SIZE[1]\n",
        "    lung_width = x_max - x_min + 2 * CROP_MARGIN\n",
        "    lung_height = y_max - y_min + 2 * CROP_MARGIN\n",
        "    \n",
        "    if lung_width / lung_height > target_aspect:\n",
        "        crop_width = lung_width\n",
        "        crop_height = int(crop_width / target_aspect)\n",
        "    else:\n",
        "        crop_height = lung_height\n",
        "        crop_width = int(crop_height * target_aspect)\n",
        "    \n",
        "    # Center crop on lungs\n",
        "    crop_x_min = max(0, lung_center_x - crop_width // 2)\n",
        "    crop_y_min = max(0, lung_center_y - crop_height // 2)\n",
        "    crop_x_max = min(w, crop_x_min + crop_width)\n",
        "    crop_y_max = min(h, crop_y_min + crop_height)\n",
        "    \n",
        "    # Adjust if hitting boundaries\n",
        "    if crop_x_max == w:\n",
        "        crop_x_min = w - crop_width\n",
        "    if crop_y_max == h:\n",
        "        crop_y_min = h - crop_height\n",
        "    \n",
        "    crop_x_min = max(0, crop_x_min)\n",
        "    crop_y_min = max(0, crop_y_min)\n",
        "    \n",
        "    # Crop image\n",
        "    if len(image.shape) == 3:\n",
        "        cropped = image[crop_y_min:crop_y_max, crop_x_min:crop_x_max, :]\n",
        "    else:\n",
        "        cropped = image[crop_y_min:crop_y_max, crop_x_min:crop_x_max]\n",
        "    \n",
        "    return cropped, (crop_x_min, crop_y_min, crop_x_max, crop_y_max)\n",
        "\n",
        "def save_simple_masks(image, binary_mask, crop_bounds, file_id):\n",
        "    \"\"\"Save simple mask and overlay\"\"\"\n",
        "    if not SAVE_MASKS:\n",
        "        return\n",
        "    \n",
        "    os.makedirs(MASKS_PATH, exist_ok=True)\n",
        "    \n",
        "    # Save binary mask\n",
        "    mask_path = os.path.join(MASKS_PATH, f\"{file_id}_mask.png\")\n",
        "    mask_image = (binary_mask * 255).astype(np.uint8)\n",
        "    cv2.imwrite(mask_path, mask_image)\n",
        "    \n",
        "    # Save simple overlay\n",
        "    overlay_path = os.path.join(MASKS_PATH, f\"{file_id}_overlay.png\")\n",
        "    overlay = image.copy()\n",
        "    if len(overlay.shape) == 2:\n",
        "        overlay = cv2.cvtColor(overlay, cv2.COLOR_GRAY2RGB)\n",
        "    \n",
        "    # Darken areas outside crop\n",
        "    crop_x_min, crop_y_min, crop_x_max, crop_y_max = crop_bounds\n",
        "    mask = np.ones(overlay.shape[:2], dtype=bool)\n",
        "    mask[crop_y_min:crop_y_max, crop_x_min:crop_x_max] = False\n",
        "    overlay[mask] = (overlay[mask] * 0.5).astype(np.uint8)\n",
        "    \n",
        "    # Add lung contours in red\n",
        "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cv2.drawContours(overlay, contours, -1, (0, 0, 255), 2)\n",
        "    \n",
        "    # Add crop rectangle in cyan\n",
        "    cv2.rectangle(overlay, (crop_x_min, crop_y_min), (crop_x_max, crop_y_max), (255, 255, 0), 2)\n",
        "    \n",
        "    cv2.imwrite(overlay_path, overlay)\n",
        "\n",
        "print(\"Simple processing functions loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load CSV and download files\n",
        "try:\n",
        "    user_info = a3conn.getUserInfos()\n",
        "    print(f\"ArchiMed user: {user_info}\")\n",
        "    \n",
        "    # Load CSV\n",
        "    csv_path = os.path.join(CSV_FOLDER, CSV_LABELS_FILE)\n",
        "    df = pd.read_csv(csv_path, sep=CSV_SEPARATOR)\n",
        "    print(f\"Loaded CSV with {len(df)} rows\")\n",
        "    \n",
        "    # Find FileID column\n",
        "    file_id_column = None\n",
        "    for col in ['FileID', 'file_id', 'File_ID']:\n",
        "        if col in df.columns:\n",
        "            file_id_column = col\n",
        "            break\n",
        "    \n",
        "    if file_id_column is None:\n",
        "        raise ValueError(\"FileID column not found\")\n",
        "    \n",
        "    # Get file IDs\n",
        "    file_ids = df[file_id_column].dropna().unique()\n",
        "    total_files = len(file_ids)\n",
        "    \n",
        "    print(f\"Starting download of {total_files} files\")\n",
        "    \n",
        "    # Download files\n",
        "    downloaded_files = []\n",
        "    os.makedirs(DOWNLOAD_PATH, exist_ok=True)\n",
        "    \n",
        "    for i, file_id in enumerate(file_ids):\n",
        "        progress = ((i + 1) / total_files) * 100\n",
        "        file_id_str = str(file_id)\n",
        "        print(f\"Downloading {file_id_str} ({progress:.1f}% - {i+1}/{total_files})\")\n",
        "        \n",
        "        dicom_file_path = os.path.join(DOWNLOAD_PATH, f\"{file_id}.dcm\")\n",
        "        \n",
        "        if os.path.exists(dicom_file_path):\n",
        "            print(f\"File {file_id} already exists, skipping\")\n",
        "            downloaded_files.append(dicom_file_path)\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            result = a3conn.downloadFile(\n",
        "                int(file_id_str),\n",
        "                asStream=False,\n",
        "                destDir=DOWNLOAD_PATH,\n",
        "                filename=f\"{file_id_str}.dcm\",\n",
        "                inWorklist=False\n",
        "            )\n",
        "            \n",
        "            if result and os.path.exists(dicom_file_path):\n",
        "                downloaded_files.append(dicom_file_path)\n",
        "                print(f\"‚úÖ Downloaded: {dicom_file_path}\")\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Download unclear for {file_id_str}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Failed to download {file_id_str}: {e}\")\n",
        "    \n",
        "    print(f\"Downloaded {len(downloaded_files)} files successfully\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Setup failed: {e}\")\n",
        "    downloaded_files = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert DICOM files with simplified processing\n",
        "def convert_dicom_simple(dicom_path, output_path):\n",
        "    \"\"\"Simple DICOM conversion with lung segmentation and clear area cropping\"\"\"\n",
        "    try:\n",
        "        file_id = os.path.splitext(os.path.basename(dicom_path))[0]\n",
        "        \n",
        "        # Read DICOM\n",
        "        dicom_data = pydicom.dcmread(dicom_path)\n",
        "        image_array = dicom_data.pixel_array\n",
        "        \n",
        "        # Handle photometric interpretation\n",
        "        if hasattr(dicom_data, 'PhotometricInterpretation'):\n",
        "            if dicom_data.PhotometricInterpretation == 'MONOCHROME1':\n",
        "                image_array = np.max(image_array) - image_array\n",
        "        \n",
        "        # Normalize to 0-255\n",
        "        if image_array.max() > 255:\n",
        "            image_array = ((image_array - image_array.min()) / \n",
        "                          (image_array.max() - image_array.min()) * 255).astype(np.uint8)\n",
        "        else:\n",
        "            image_array = image_array.astype(np.uint8)\n",
        "        \n",
        "        print(f\"Processing {file_id}: {image_array.shape}\")\n",
        "        \n",
        "        # Lung segmentation\n",
        "        binary_mask = simple_lung_segmentation(image_array)\n",
        "        \n",
        "        # Check if segmentation found reasonable lung area\n",
        "        lung_ratio = np.sum(binary_mask) / binary_mask.size\n",
        "        if lung_ratio < 0.01 or lung_ratio > 0.8:\n",
        "            print(f\"‚ö†Ô∏è Unusual lung ratio {lung_ratio:.3f}, using original image\")\n",
        "            processed_image = image_array\n",
        "            crop_bounds = (0, 0, image_array.shape[1], image_array.shape[0])\n",
        "        else:\n",
        "            # Crop to clear area\n",
        "            processed_image, crop_bounds = crop_to_clear_area(image_array, binary_mask)\n",
        "            print(f\"‚úÖ Cropped to clear area: {processed_image.shape}\")\n",
        "        \n",
        "        # Save masks\n",
        "        save_simple_masks(image_array, binary_mask, crop_bounds, file_id)\n",
        "        \n",
        "        # Convert to PIL and resize\n",
        "        if len(processed_image.shape) == 2:\n",
        "            pil_image = Image.fromarray(processed_image, mode='L')\n",
        "        else:\n",
        "            pil_image = Image.fromarray(processed_image)\n",
        "        \n",
        "        # Maintain aspect ratio by cropping then resizing\n",
        "        current_width, current_height = pil_image.size\n",
        "        target_width, target_height = TARGET_SIZE\n",
        "        \n",
        "        current_ratio = current_width / current_height\n",
        "        target_ratio = target_width / target_height\n",
        "        \n",
        "        if current_ratio > target_ratio:\n",
        "            # Crop width\n",
        "            new_width = int(current_height * target_ratio)\n",
        "            left = (current_width - new_width) // 2\n",
        "            pil_image = pil_image.crop((left, 0, left + new_width, current_height))\n",
        "        else:\n",
        "            # Crop height\n",
        "            new_height = int(current_width / target_ratio)\n",
        "            top = (current_height - new_height) // 2\n",
        "            pil_image = pil_image.crop((0, top, current_width, top + new_height))\n",
        "        \n",
        "        # Final resize\n",
        "        pil_image = pil_image.resize(TARGET_SIZE, Image.Resampling.LANCZOS)\n",
        "        \n",
        "        # Save\n",
        "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "        pil_image.save(output_path)\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to convert {dicom_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Convert all downloaded files\n",
        "if CONVERT and downloaded_files:\n",
        "    print(f\"Converting {len(downloaded_files)} DICOM files\")\n",
        "    \n",
        "    os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "    converted_count = 0\n",
        "    \n",
        "    for dicom_path in tqdm(downloaded_files, desc=\"Converting\"):\n",
        "        file_id = os.path.splitext(os.path.basename(dicom_path))[0]\n",
        "        output_path = os.path.join(IMAGES_PATH, f\"{file_id}.png\")\n",
        "        \n",
        "        if convert_dicom_simple(dicom_path, output_path):\n",
        "            converted_count += 1\n",
        "    \n",
        "    print(f\"‚úÖ Successfully converted {converted_count}/{len(downloaded_files)} files\")\n",
        "    print(f\"Images saved to: {IMAGES_PATH}\")\n",
        "    if SAVE_MASKS:\n",
        "        print(f\"Masks saved to: {MASKS_PATH}\")\n",
        "    print(\"üéâ V1.4 Simplified processing complete!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No files to convert or conversion disabled\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
