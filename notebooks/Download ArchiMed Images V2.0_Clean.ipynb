{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "# ArchiMed Images V2.0 - Clean & Modular\n",
        "\n",
        "**Enhanced lung segmentation with separate left/right detection**  \n",
        "*Organized with external function files for better maintainability*\n",
        "\n",
        "</div>\n",
        "\n",
        "## ‚ú® Key Improvements in V2.0\n",
        "- **üóÇÔ∏è Modular Design** - Functions organized in external `.py` files\n",
        "- **üìù Format Selection** - Choose between PNG or NIFTI output formats  \n",
        "- **ü´Å Advanced Segmentation** - Separate left/right lung detection\n",
        "- **üîß Enhanced Processing** - Ultra-sensitive detection with multiple fallbacks\n",
        "- **üìä Better Visualization** - Color-coded overlays and comprehensive reporting\n",
        "\n",
        "## üìÅ Output Files\n",
        "For each image, creates:\n",
        "- `{file_id}.png/.nii.gz` - Processed image in selected format\n",
        "- `{file_id}_left_lung_mask.png` - Left lung only  \n",
        "- `{file_id}_right_lung_mask.png` - Right lung only\n",
        "- `{file_id}_combined_mask.png` - Both lungs combined\n",
        "- `{file_id}_overlay.png` - Color-coded visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== CONFIGURATION PARAMETERS =====\n",
        "\n",
        "# Data Paths\n",
        "CSV_FOLDER = \"/home/pyuser/data/Paradise_CSV/\"\n",
        "CSV_LABELS_FILE = \"Labeled_Data_RAW.csv\"\n",
        "CSV_SEPARATOR = \";\"\n",
        "\n",
        "DOWNLOAD_PATH = '/home/pyuser/data/Paradise_DICOMs'\n",
        "# IMAGES_PATH = '/home/pyuser/data/Paradise_Images'\n",
        "# MASKS_PATH = '/home/pyuser/data/Paradise_Masks'\n",
        "IMAGES_PATH = '/home/pyuser/data/Tests_Images'\n",
        "MASKS_PATH = '/home/pyuser/data/Tests_Masks'\n",
        "\n",
        "# ===== NEW V2.0 FEATURE: OUTPUT FORMAT SELECTION =====\n",
        "# Choose output format: 'png' or 'nifti'\n",
        "OUTPUT_FORMAT = 'nifti'  # Options: 'png', 'nifti'\n",
        "\n",
        "# Processing Settings\n",
        "TARGET_SIZE = (518, 518)  # Final image size (width, height)\n",
        "CROP_MARGIN = 25          # Margin around lung segmentation for cropping (pixels)\n",
        "\n",
        "# ArchiMed Integration\n",
        "USE_ARCHIMED = True       # Try ArchiMed first (recommended)\n",
        "DOWNLOAD_IF_MISSING = True  # Download from ArchiMed if files not found locally\n",
        "\n",
        "# Segmentation Parameters\n",
        "MODEL_SENSITIVITY = 0.0001           # Lower = more sensitive (0.0001 to 0.5)\n",
        "ENABLE_HISTOGRAM_EQUALIZATION = True # Enhance contrast before segmentation\n",
        "ENABLE_GAUSSIAN_BLUR = True          # Reduce noise before segmentation\n",
        "USE_MULTIPLE_THRESHOLDS = True       # Try multiple sensitivity levels\n",
        "AGGRESSIVE_MORPHOLOGY = True         # More aggressive mask cleanup\n",
        "KEEP_LARGEST_COMPONENT_ONLY = True   # Keep only largest component per lung\n",
        "ENABLE_DEBUG_OUTPUT = False          # Print segmentation debug info\n",
        "\n",
        "# Visualization Settings\n",
        "SAVE_MASKS = True        # Save segmentation masks and overlays\n",
        "LUNG_FILL_OPACITY = 0.25    # Lung mask fill opacity (0.0 to 1.0)\n",
        "LUNG_BORDER_OPACITY = 0.50  # Lung mask border opacity (0.0 to 1.0)\n",
        "\n",
        "print(\"‚úÖ Configuration loaded successfully!\")\n",
        "print(f\"üìù Output format: {OUTPUT_FORMAT.upper()}\")\n",
        "print(f\"üéØ Target size: {TARGET_SIZE[0]}x{TARGET_SIZE[1]}\")\n",
        "print(f\"ü´Å Model sensitivity: {MODEL_SENSITIVITY}\")\n",
        "print(f\"üíæ Save masks: {SAVE_MASKS}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== IMPORTS AND INITIALIZATION =====\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from typing import Dict, Any, List\n",
        "\n",
        "# Import our modular functions from the functions package\n",
        "from functions import *\n",
        "\n",
        "print(\"üì¶ All function modules imported successfully from functions package!\")\n",
        "\n",
        "# Create configuration dictionary for easy passing\n",
        "config = {\n",
        "    # Data paths\n",
        "    'CSV_FOLDER': CSV_FOLDER,\n",
        "    'CSV_LABELS_FILE': CSV_LABELS_FILE,\n",
        "    'CSV_SEPARATOR': CSV_SEPARATOR,\n",
        "    'DOWNLOAD_PATH': DOWNLOAD_PATH,\n",
        "    'IMAGES_PATH': IMAGES_PATH,\n",
        "    'MASKS_PATH': MASKS_PATH,\n",
        "    \n",
        "    # Processing settings\n",
        "    'OUTPUT_FORMAT': OUTPUT_FORMAT,\n",
        "    'TARGET_SIZE': TARGET_SIZE,\n",
        "    'CROP_MARGIN': CROP_MARGIN,\n",
        "    \n",
        "    # ArchiMed integration\n",
        "    'USE_ARCHIMED': USE_ARCHIMED,\n",
        "    'DOWNLOAD_IF_MISSING': DOWNLOAD_IF_MISSING,\n",
        "    \n",
        "    # Segmentation parameters\n",
        "    'MODEL_SENSITIVITY': MODEL_SENSITIVITY,\n",
        "    'ENABLE_HISTOGRAM_EQUALIZATION': ENABLE_HISTOGRAM_EQUALIZATION,\n",
        "    'ENABLE_GAUSSIAN_BLUR': ENABLE_GAUSSIAN_BLUR,\n",
        "    'USE_MULTIPLE_THRESHOLDS': USE_MULTIPLE_THRESHOLDS,\n",
        "    'AGGRESSIVE_MORPHOLOGY': AGGRESSIVE_MORPHOLOGY,\n",
        "    'KEEP_LARGEST_COMPONENT_ONLY': KEEP_LARGEST_COMPONENT_ONLY,\n",
        "    'ENABLE_DEBUG_OUTPUT': ENABLE_DEBUG_OUTPUT,\n",
        "    \n",
        "    # Visualization settings\n",
        "    'SAVE_MASKS': SAVE_MASKS,\n",
        "    'LUNG_FILL_OPACITY': LUNG_FILL_OPACITY,\n",
        "    'LUNG_BORDER_OPACITY': LUNG_BORDER_OPACITY,\n",
        "}\n",
        "\n",
        "# Validate configuration\n",
        "is_valid, errors = validate_configuration(config)\n",
        "if not is_valid:\n",
        "    print(\"‚ùå Configuration validation failed:\")\n",
        "    for error in errors:\n",
        "        print(f\"   ‚Ä¢ {error}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "print(\"‚úÖ Configuration validated successfully!\")\n",
        "\n",
        "# Print configuration summary\n",
        "print_configuration_summary(config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== SEGMENTATION MODEL INITIALIZATION =====\n",
        "\n",
        "print(\"üîÑ Initializing lung segmentation model...\")\n",
        "\n",
        "# Initialize the segmentation model (TorchXRayVision or fallback)\n",
        "segmentation_model, model_type = initialize_segmentation_model()\n",
        "\n",
        "# Store model type in config for use by other functions\n",
        "config['model_type'] = model_type\n",
        "\n",
        "print(f\"‚úÖ Segmentation model ready: {model_type}\")\n",
        "\n",
        "if model_type == 'torchxray':\n",
        "    print(\"üéØ Using TorchXRayVision for advanced left/right lung detection\")\n",
        "elif model_type == 'fallback':\n",
        "    print(\"‚ö° Using fallback method (combined lung detection only)\")\n",
        "    print(\"üí° Install TorchXRayVision for separate left/right lung detection\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== FILE DISCOVERY AND DOWNLOAD =====\n",
        "\n",
        "print(\"üîç Starting file discovery and download process...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Use the comprehensive file discovery and download management\n",
        "dicom_files, discovery_stats = manage_file_discovery(config)\n",
        "\n",
        "# Print discovery summary\n",
        "print_file_discovery_summary(\n",
        "    discovery_stats['local_files_found'],\n",
        "    discovery_stats['downloaded_files'], \n",
        "    discovery_stats['failed_downloads']\n",
        ")\n",
        "\n",
        "# Check if we have files to process\n",
        "if not dicom_files:\n",
        "    print(\"‚ùå No DICOM files found!\")\n",
        "    print(\"üí° Check your configuration:\")\n",
        "    print(f\"   ‚Ä¢ CSV path: {config.get('CSV_FOLDER')}/{config.get('CSV_LABELS_FILE')}\")\n",
        "    print(f\"   ‚Ä¢ Download path: {config.get('DOWNLOAD_PATH')}\")\n",
        "    print(\"   ‚Ä¢ ArchiMed connection status\")\n",
        "else:\n",
        "    print(f\"\\nüéâ Ready to process {len(dicom_files)} DICOM files!\")\n",
        "    \n",
        "    # Show sample file paths for verification\n",
        "    if len(dicom_files) <= 5:\n",
        "        print(\"üìã Files to process:\")\n",
        "        for dicom_file in dicom_files:\n",
        "            print(f\"   ‚Ä¢ {os.path.basename(dicom_file)}\")\n",
        "    else:\n",
        "        print(\"üìã Sample files to process:\")\n",
        "        for dicom_file in dicom_files[:3]:\n",
        "            print(f\"   ‚Ä¢ {os.path.basename(dicom_file)}\")\n",
        "        print(f\"   ‚Ä¢ ... and {len(dicom_files) - 3} more files\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== MAIN PROCESSING PIPELINE =====\n",
        "\n",
        "if dicom_files:\n",
        "    print(\"\\nüöÄ Starting main processing pipeline...\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Create output directories\n",
        "    os.makedirs(config['IMAGES_PATH'], exist_ok=True)\n",
        "    if config['SAVE_MASKS']:\n",
        "        os.makedirs(config['MASKS_PATH'], exist_ok=True)\n",
        "    \n",
        "    # Initialize results tracking\n",
        "    results = {\n",
        "        'total_files_found': len(dicom_files),\n",
        "        'successfully_processed': 0,\n",
        "        'segmentation_successes': 0,\n",
        "        'failed_conversions': 0,\n",
        "        'skipped_existing': 0,\n",
        "        'mask_files_created': 0,\n",
        "        'processed_files': [],\n",
        "        'errors': [],\n",
        "        'model_type': model_type\n",
        "    }\n",
        "    \n",
        "    # Create progress tracker\n",
        "    pbar = create_progress_tracker(len(dicom_files), \"Processing DICOM files\")\n",
        "    \n",
        "    for dicom_path in dicom_files:\n",
        "        try:\n",
        "            file_id = os.path.splitext(os.path.basename(dicom_path))[0]\n",
        "            \n",
        "            # Generate output path based on format\n",
        "            output_path = get_output_path(dicom_path, config['IMAGES_PATH'], config['OUTPUT_FORMAT'])\n",
        "            \n",
        "            # Skip if output already exists (optional)\n",
        "            if os.path.exists(output_path):\n",
        "                results['skipped_existing'] += 1\n",
        "                pbar.set_postfix({\n",
        "                    \"Processed\": results['successfully_processed'],\n",
        "                    \"Skipped\": results['skipped_existing']\n",
        "                })\n",
        "                pbar.update(1)\n",
        "                continue\n",
        "            \n",
        "            # Step 1: Read and normalize DICOM\n",
        "            image_array, dicom_data, status = read_dicom_file(dicom_path)\n",
        "            if image_array is None:\n",
        "                results['errors'].append(f\"{file_id}: {status}\")\n",
        "                results['failed_conversions'] += 1\n",
        "                pbar.update(1)\n",
        "                continue\n",
        "            \n",
        "            # Normalize to uint8 for processing\n",
        "            image_array = normalize_image_array(image_array, 'uint8')\n",
        "            \n",
        "            # Step 2: Apply segmentation and processing\n",
        "            processed_image, processing_info = process_image_with_segmentation(image_array, file_id, config)\n",
        "            \n",
        "            # Step 3: Save visualization files if segmentation succeeded\n",
        "            visualization_success = False\n",
        "            if config['SAVE_MASKS'] and processing_info['segmentation_success']:\n",
        "                visualization_success = save_visualization_files(\n",
        "                    processing_info, config['MASKS_PATH'], image_array, config\n",
        "                )\n",
        "                if visualization_success:\n",
        "                    results['mask_files_created'] += 4  # L/R/Combined/Overlay\n",
        "            \n",
        "            # Step 4: Convert and save in final format\n",
        "            conversion_success = convert_dicom_to_format(\n",
        "                dicom_path, output_path, config['OUTPUT_FORMAT'], \n",
        "                config['TARGET_SIZE'], processed_image, processing_info\n",
        "            )\n",
        "            \n",
        "            if conversion_success:\n",
        "                results['successfully_processed'] += 1\n",
        "                \n",
        "                # Track segmentation success\n",
        "                if processing_info['segmentation_success']:\n",
        "                    results['segmentation_successes'] += 1\n",
        "                \n",
        "                # Record file processing info\n",
        "                results['processed_files'].append({\n",
        "                    'file_id': file_id,\n",
        "                    'success': True,\n",
        "                    'segmentation_success': processing_info['segmentation_success'],\n",
        "                    'visualization_success': visualization_success,\n",
        "                    'output_path': output_path\n",
        "                })\n",
        "            else:\n",
        "                results['failed_conversions'] += 1\n",
        "                results['errors'].append(f\"{file_id}: Conversion failed\")\n",
        "            \n",
        "            # Update progress bar\n",
        "            pbar.set_postfix({\n",
        "                \"Processed\": results['successfully_processed'],\n",
        "                \"Segmented\": results['segmentation_successes']\n",
        "            })\n",
        "            \n",
        "        except Exception as e:\n",
        "            file_id = os.path.splitext(os.path.basename(dicom_path))[0]\n",
        "            results['errors'].append(f\"{file_id}: {str(e)}\")\n",
        "            results['failed_conversions'] += 1\n",
        "        \n",
        "        pbar.update(1)\n",
        "    \n",
        "    pbar.close()\n",
        "    \n",
        "    # Print comprehensive results summary\n",
        "    print_processing_summary(results, config)\n",
        "    \n",
        "    # Display sample results\n",
        "    display_sample_results(results, config, num_samples=5)\n",
        "    \n",
        "    # Save processing log\n",
        "    log_path = os.path.join(config['IMAGES_PATH'], 'processing_log.json')\n",
        "    save_processing_log(results, config, log_path)\n",
        "\n",
        "else:\n",
        "    print(\"‚è≠Ô∏è No files to process - skipping processing pipeline\")\n",
        "    results = {\n",
        "        'total_files_found': 0,\n",
        "        'successfully_processed': 0,\n",
        "        'segmentation_successes': 0,\n",
        "        'failed_conversions': 0,\n",
        "        'errors': [\"No DICOM files found\"],\n",
        "        'model_type': model_type\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===== NIFTI DEBUGGING AND TESTING =====\n",
        "\n",
        "if config['OUTPUT_FORMAT'].lower() == 'nifti' and dicom_files:\n",
        "    print(\"\\nüß™ NIFTI Debugging Section\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Test with the first available DICOM file\n",
        "    test_dicom = dicom_files[0]\n",
        "    print(f\"Testing NIFTI conversion with: {os.path.basename(test_dicom)}\")\n",
        "    \n",
        "    # Run the isolated NIFTI test\n",
        "    test_result = test_nifti_conversion(test_dicom, config['IMAGES_PATH'])\n",
        "    \n",
        "    if test_result:\n",
        "        print(\"‚úÖ Basic NIFTI conversion working!\")\n",
        "    else:\n",
        "        print(\"‚ùå Basic NIFTI conversion failed - check dependencies\")\n",
        "        print(\"üí° Make sure nibabel is installed: pip install nibabel\")\n",
        "    \n",
        "    print(\"=\" * 50)\n",
        "\n",
        "# ===== SINGLE FILE TESTING (OPTIONAL) =====\n",
        "# Uncomment and modify this section to test with a single DICOM file\n",
        "\n",
        "\"\"\"\n",
        "# Test with a single DICOM file\n",
        "test_dicom_path = \"/path/to/your/test_file.dcm\"  # Modify this path\n",
        "\n",
        "if os.path.exists(test_dicom_path):\n",
        "    print(f\"üß™ Testing with single file: {os.path.basename(test_dicom_path)}\")\n",
        "    \n",
        "    file_id = os.path.splitext(os.path.basename(test_dicom_path))[0]\n",
        "    \n",
        "    # Read DICOM\n",
        "    image_array, dicom_data, status = read_dicom_file(test_dicom_path)\n",
        "    \n",
        "    if image_array is not None:\n",
        "        print(f\"‚úÖ DICOM read successfully - Shape: {image_array.shape}\")\n",
        "        \n",
        "        # Normalize\n",
        "        image_array = normalize_image_array(image_array, 'uint8')\n",
        "        \n",
        "        # Process with segmentation\n",
        "        processed_image, processing_info = process_image_with_segmentation(image_array, file_id, config)\n",
        "        \n",
        "        print(f\"ü´Å Segmentation: {'‚úÖ Success' if processing_info['segmentation_success'] else '‚ùå Failed'}\")\n",
        "        \n",
        "        # Save test outputs\n",
        "        test_output_dir = os.path.join(config['IMAGES_PATH'], 'test_output')\n",
        "        os.makedirs(test_output_dir, exist_ok=True)\n",
        "        \n",
        "        # Save processed image\n",
        "        output_path = get_output_path(test_dicom_path, test_output_dir, config['OUTPUT_FORMAT'], f\"{file_id}_test\")\n",
        "        conversion_success = convert_dicom_to_format(\n",
        "            test_dicom_path, output_path, config['OUTPUT_FORMAT'], \n",
        "            config['TARGET_SIZE'], processed_image, processing_info\n",
        "        )\n",
        "        \n",
        "        if conversion_success:\n",
        "            print(f\"‚úÖ Test image saved: {output_path}\")\n",
        "        \n",
        "        # Save test masks\n",
        "        if config['SAVE_MASKS'] and processing_info['segmentation_success']:\n",
        "            test_masks_dir = os.path.join(config['MASKS_PATH'], 'test_output')\n",
        "            save_visualization_files(processing_info, test_masks_dir, image_array, config)\n",
        "            print(f\"‚úÖ Test masks saved to: {test_masks_dir}\")\n",
        "    \n",
        "    else:\n",
        "        print(f\"‚ùå Failed to read DICOM: {status}\")\n",
        "        \n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è Single file testing section - modify test_dicom_path to use\")\n",
        "\"\"\"\n",
        "\n",
        "print(\"‚ÑπÔ∏è Single file testing section available - uncomment and modify to use\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üéâ Pipeline Completed!\n",
        "\n",
        "### üìÅ Output Structure\n",
        "\n",
        "Your processed files are organized as follows:\n",
        "\n",
        "```\n",
        "{IMAGES_PATH}/\n",
        "‚îú‚îÄ‚îÄ {file_id}.png/.nii.gz          # Processed images in selected format\n",
        "‚îî‚îÄ‚îÄ processing_log.json            # Detailed processing log\n",
        "\n",
        "{MASKS_PATH}/                       # (if SAVE_MASKS = True)\n",
        "‚îú‚îÄ‚îÄ {file_id}_left_lung_mask.png    # Left lung masks\n",
        "‚îú‚îÄ‚îÄ {file_id}_right_lung_mask.png   # Right lung masks  \n",
        "‚îú‚îÄ‚îÄ {file_id}_combined_mask.png     # Combined lung masks\n",
        "‚îî‚îÄ‚îÄ {file_id}_overlay.png           # Color-coded visualizations\n",
        "```\n",
        "\n",
        "### üîß Key V2.0 Improvements\n",
        "\n",
        "1. **üóÇÔ∏è Modular Architecture**: Functions organized in separate files for better maintainability\n",
        "2. **üìù Format Flexibility**: Easy switching between PNG and NIFTI output formats\n",
        "3. **ü´Å Advanced Segmentation**: Separate left/right lung detection with TorchXRayVision\n",
        "4. **üìä Enhanced Reporting**: Comprehensive progress tracking and result summaries\n",
        "5. **üîç Better Error Handling**: Detailed error reporting and validation\n",
        "6. **‚ö° Optimized Processing**: Streamlined pipeline with better memory management\n",
        "\n",
        "### üõ†Ô∏è Function Files\n",
        "\n",
        "- **`functions_conversion.py`**: DICOM reading, format conversion, file I/O\n",
        "- **`functions_pre-processing.py`**: Image enhancement, segmentation, morphological operations  \n",
        "- **`functions_visualisation.py`**: Overlay creation, progress tracking, result display\n",
        "- **`functions_archimed.py`**: ArchiMed integration, file discovery, CSV management\n",
        "\n",
        "### üí° Next Steps\n",
        "\n",
        "- Check the output directories for your processed images\n",
        "- Review the `processing_log.json` for detailed processing information\n",
        "- Use the overlay images to verify segmentation quality\n",
        "- Adjust configuration parameters as needed for your specific use case\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
